# Comparing `tmp/torchdrug-0.2.0.post1-py3-none-any.whl.zip` & `tmp/torchdrug-0.2.1-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,146 +1,146 @@
-Zip file size: 267259 bytes, number of entries: 144
--rw-r-----  2.0 unx      330 b- defN 22-Oct-13 22:26 torchdrug/__init__.py
--rw-r-----  2.0 unx     6263 b- defN 22-Oct-13 22:26 torchdrug/patch.py
--rw-r-----  2.0 unx      320 b- defN 22-Oct-13 22:26 torchdrug/core/__init__.py
--rw-r-----  2.0 unx    12721 b- defN 22-Oct-13 22:26 torchdrug/core/core.py
--rw-r-----  2.0 unx    11218 b- defN 22-Oct-13 22:26 torchdrug/core/engine.py
--rw-r-----  2.0 unx     4180 b- defN 22-Oct-13 22:26 torchdrug/core/logger.py
--rw-r-----  2.0 unx     3894 b- defN 22-Oct-13 22:26 torchdrug/core/meter.py
--rw-r-----  2.0 unx      989 b- defN 22-Oct-13 22:26 torchdrug/data/__init__.py
--rw-r-----  2.0 unx     3295 b- defN 22-Oct-13 22:26 torchdrug/data/constant.py
--rw-r-----  2.0 unx     3729 b- defN 22-Oct-13 22:26 torchdrug/data/dataloader.py
--rw-r-----  2.0 unx    49243 b- defN 22-Oct-13 22:26 torchdrug/data/dataset.py
--rw-r-----  2.0 unx    10947 b- defN 22-Oct-13 22:26 torchdrug/data/dictionary.py
--rw-r-----  2.0 unx    12469 b- defN 22-Oct-13 22:26 torchdrug/data/feature.py
--rw-r-----  2.0 unx    76505 b- defN 22-Oct-13 22:26 torchdrug/data/graph.py
--rw-r-----  2.0 unx    42169 b- defN 22-Oct-13 22:26 torchdrug/data/molecule.py
--rw-r-----  2.0 unx    65097 b- defN 22-Oct-13 22:26 torchdrug/data/protein.py
--rw-r-----  2.0 unx        0 b- defN 22-Oct-13 22:26 torchdrug/data/rdkit/__init__.py
--rw-r-----  2.0 unx     1771 b- defN 22-Oct-13 22:26 torchdrug/data/rdkit/draw.py
--rw-r-----  2.0 unx     2115 b- defN 22-Oct-13 22:26 torchdrug/datasets/__init__.py
--rw-r-----  2.0 unx     9114 b- defN 22-Oct-13 22:26 torchdrug/datasets/alphafolddb.py
--rw-r-----  2.0 unx     1111 b- defN 22-Oct-13 22:26 torchdrug/datasets/bace.py
--rw-r-----  2.0 unx     1071 b- defN 22-Oct-13 22:26 torchdrug/datasets/bbbp.py
--rw-r-----  2.0 unx     1652 b- defN 22-Oct-13 22:26 torchdrug/datasets/beta_lactamase.py
--rw-r-----  2.0 unx     1750 b- defN 22-Oct-13 22:26 torchdrug/datasets/binary_localization.py
--rw-r-----  2.0 unx     2566 b- defN 22-Oct-13 22:26 torchdrug/datasets/bindingdb.py
--rw-r-----  2.0 unx     1122 b- defN 22-Oct-13 22:26 torchdrug/datasets/cep.py
--rw-r-----  2.0 unx     1126 b- defN 22-Oct-13 22:26 torchdrug/datasets/chembl_filtered.py
--rw-r-----  2.0 unx     1020 b- defN 22-Oct-13 22:26 torchdrug/datasets/citeseer.py
--rw-r-----  2.0 unx     1207 b- defN 22-Oct-13 22:26 torchdrug/datasets/clintox.py
--rw-r-----  2.0 unx      992 b- defN 22-Oct-13 22:26 torchdrug/datasets/cora.py
--rw-r-----  2.0 unx     1119 b- defN 22-Oct-13 22:26 torchdrug/datasets/delaney.py
--rw-r-----  2.0 unx     5152 b- defN 22-Oct-13 22:26 torchdrug/datasets/enzyme_commission.py
--rw-r-----  2.0 unx     3362 b- defN 22-Oct-13 22:26 torchdrug/datasets/fb15k.py
--rw-r-----  2.0 unx     1622 b- defN 22-Oct-13 22:26 torchdrug/datasets/fluorescence.py
--rw-r-----  2.0 unx     1801 b- defN 22-Oct-13 22:26 torchdrug/datasets/fold.py
--rw-r-----  2.0 unx     1173 b- defN 22-Oct-13 22:26 torchdrug/datasets/freesolv.py
--rw-r-----  2.0 unx     5740 b- defN 22-Oct-13 22:26 torchdrug/datasets/gene_ontology.py
--rw-r-----  2.0 unx     1641 b- defN 22-Oct-13 22:26 torchdrug/datasets/hetionet.py
--rw-r-----  2.0 unx     1087 b- defN 22-Oct-13 22:26 torchdrug/datasets/hiv.py
--rw-r-----  2.0 unx     2377 b- defN 22-Oct-13 22:26 torchdrug/datasets/human_ppi.py
--rw-r-----  2.0 unx     1130 b- defN 22-Oct-13 22:26 torchdrug/datasets/lipophilicity.py
--rw-r-----  2.0 unx     1171 b- defN 22-Oct-13 22:26 torchdrug/datasets/malaria.py
--rw-r-----  2.0 unx     1590 b- defN 22-Oct-13 22:26 torchdrug/datasets/moses.py
--rw-r-----  2.0 unx     1340 b- defN 22-Oct-13 22:26 torchdrug/datasets/muv.py
--rw-r-----  2.0 unx     4242 b- defN 22-Oct-13 22:26 torchdrug/datasets/opv.py
--rw-r-----  2.0 unx     1270 b- defN 22-Oct-13 22:26 torchdrug/datasets/pcqm4m.py
--rw-r-----  2.0 unx     2559 b- defN 22-Oct-13 22:26 torchdrug/datasets/pdbbind.py
--rw-r-----  2.0 unx     2380 b- defN 22-Oct-13 22:26 torchdrug/datasets/ppi_affinity.py
--rw-r-----  2.0 unx     2370 b- defN 22-Oct-13 22:26 torchdrug/datasets/proteinnet.py
--rw-r-----  2.0 unx     1314 b- defN 22-Oct-13 22:26 torchdrug/datasets/pubchem110m.py
--rw-r-----  2.0 unx     3658 b- defN 22-Oct-13 22:26 torchdrug/datasets/pubmed.py
--rw-r-----  2.0 unx     3259 b- defN 22-Oct-13 22:26 torchdrug/datasets/qm8.py
--rw-r-----  2.0 unx     2553 b- defN 22-Oct-13 22:26 torchdrug/datasets/qm9.py
--rw-r-----  2.0 unx     2459 b- defN 22-Oct-13 22:26 torchdrug/datasets/secondary_structure.py
--rw-r-----  2.0 unx     1179 b- defN 22-Oct-13 22:26 torchdrug/datasets/sider.py
--rw-r-----  2.0 unx     1612 b- defN 22-Oct-13 22:26 torchdrug/datasets/solubility.py
--rw-r-----  2.0 unx     1600 b- defN 22-Oct-13 22:26 torchdrug/datasets/stability.py
--rw-r-----  2.0 unx     1693 b- defN 22-Oct-13 22:26 torchdrug/datasets/subcellular_localization.py
--rw-r-----  2.0 unx     1343 b- defN 22-Oct-13 22:26 torchdrug/datasets/tox21.py
--rw-r-----  2.0 unx     1158 b- defN 22-Oct-13 22:26 torchdrug/datasets/toxcast.py
--rw-r-----  2.0 unx    11457 b- defN 22-Oct-13 22:26 torchdrug/datasets/uspto50k.py
--rw-r-----  2.0 unx     3294 b- defN 22-Oct-13 22:26 torchdrug/datasets/wn18.py
--rw-r-----  2.0 unx     2377 b- defN 22-Oct-13 22:26 torchdrug/datasets/yeast_ppi.py
--rw-r-----  2.0 unx     1162 b- defN 22-Oct-13 22:26 torchdrug/datasets/zinc250k.py
--rw-r-----  2.0 unx     1743 b- defN 22-Oct-13 22:26 torchdrug/datasets/zinc2m.py
--rw-r-----  2.0 unx     1793 b- defN 22-Oct-13 22:26 torchdrug/layers/__init__.py
--rw-r-----  2.0 unx     5812 b- defN 22-Oct-13 22:26 torchdrug/layers/block.py
--rw-r-----  2.0 unx    12211 b- defN 22-Oct-13 22:26 torchdrug/layers/common.py
--rw-r-----  2.0 unx    33424 b- defN 22-Oct-13 22:26 torchdrug/layers/conv.py
--rw-r-----  2.0 unx     1525 b- defN 22-Oct-13 22:26 torchdrug/layers/distribution.py
--rw-r-----  2.0 unx     2145 b- defN 22-Oct-13 22:26 torchdrug/layers/flow.py
--rw-r-----  2.0 unx     9381 b- defN 22-Oct-13 22:26 torchdrug/layers/pool.py
--rw-r-----  2.0 unx     6144 b- defN 22-Oct-13 22:26 torchdrug/layers/readout.py
--rw-r-----  2.0 unx     3062 b- defN 22-Oct-13 22:26 torchdrug/layers/sampler.py
--rw-r-----  2.0 unx     1258 b- defN 22-Oct-13 22:26 torchdrug/layers/functional/__init__.py
--rw-r-----  2.0 unx     9943 b- defN 22-Oct-13 22:26 torchdrug/layers/functional/embedding.py
--rw-r-----  2.0 unx    18348 b- defN 22-Oct-13 22:26 torchdrug/layers/functional/functional.py
--rw-r-----  2.0 unx    13670 b- defN 22-Oct-13 22:26 torchdrug/layers/functional/spmm.py
--rw-r-----  2.0 unx        0 b- defN 22-Oct-13 22:26 torchdrug/layers/functional/extension/__init__.py
--rw-r-----  2.0 unx    25464 b- defN 22-Oct-13 22:26 torchdrug/layers/functional/extension/embedding.cpp
--rw-r-----  2.0 unx    25353 b- defN 22-Oct-13 22:26 torchdrug/layers/functional/extension/embedding.cu
--rw-r-----  2.0 unx     4529 b- defN 22-Oct-13 22:26 torchdrug/layers/functional/extension/embedding.h
--rw-r-----  2.0 unx     1841 b- defN 22-Oct-13 22:26 torchdrug/layers/functional/extension/operator.cuh
--rw-r-----  2.0 unx    12434 b- defN 22-Oct-13 22:26 torchdrug/layers/functional/extension/rspmm.cpp
--rw-r-----  2.0 unx    16670 b- defN 22-Oct-13 22:26 torchdrug/layers/functional/extension/rspmm.cu
--rw-r-----  2.0 unx     4506 b- defN 22-Oct-13 22:26 torchdrug/layers/functional/extension/rspmm.h
--rw-r-----  2.0 unx    13877 b- defN 22-Oct-13 22:26 torchdrug/layers/functional/extension/spmm.cpp
--rw-r-----  2.0 unx    14092 b- defN 22-Oct-13 22:26 torchdrug/layers/functional/extension/spmm.cu
--rw-r-----  2.0 unx     3693 b- defN 22-Oct-13 22:26 torchdrug/layers/functional/extension/spmm.h
--rw-r-----  2.0 unx      623 b- defN 22-Oct-13 22:26 torchdrug/layers/functional/extension/util.cuh
--rw-r-----  2.0 unx      418 b- defN 22-Oct-13 22:26 torchdrug/layers/geometry/__init__.py
--rw-r-----  2.0 unx    12428 b- defN 22-Oct-13 22:26 torchdrug/layers/geometry/function.py
--rw-r-----  2.0 unx     7661 b- defN 22-Oct-13 22:26 torchdrug/layers/geometry/graph.py
--rw-r-----  2.0 unx      643 b- defN 22-Oct-13 22:26 torchdrug/metrics/__init__.py
--rw-r-----  2.0 unx    13534 b- defN 22-Oct-13 22:26 torchdrug/metrics/metric.py
--rw-r-----  2.0 unx        0 b- defN 22-Oct-13 22:26 torchdrug/metrics/rdkit/__init__.py
--rw-r-----  2.0 unx     2471 b- defN 22-Oct-13 22:26 torchdrug/metrics/rdkit/sascorer.py
--rw-r-----  2.0 unx     2121 b- defN 22-Oct-13 22:26 torchdrug/models/__init__.py
--rw-r-----  2.0 unx     4348 b- defN 22-Oct-13 22:26 torchdrug/models/bert.py
--rw-r-----  2.0 unx     3549 b- defN 22-Oct-13 22:26 torchdrug/models/chebnet.py
--rw-r-----  2.0 unx     8817 b- defN 22-Oct-13 22:26 torchdrug/models/cnn.py
--rw-r-----  2.0 unx    10023 b- defN 22-Oct-13 22:26 torchdrug/models/embedding.py
--rw-r-----  2.0 unx     5949 b- defN 22-Oct-13 22:26 torchdrug/models/esm.py
--rw-r-----  2.0 unx     5039 b- defN 22-Oct-13 22:26 torchdrug/models/flow.py
--rw-r-----  2.0 unx     3503 b- defN 22-Oct-13 22:26 torchdrug/models/gat.py
--rw-r-----  2.0 unx     6806 b- defN 22-Oct-13 22:26 torchdrug/models/gcn.py
--rw-r-----  2.0 unx     5562 b- defN 22-Oct-13 22:26 torchdrug/models/gearnet.py
--rw-r-----  2.0 unx     3669 b- defN 22-Oct-13 22:26 torchdrug/models/gin.py
--rw-r-----  2.0 unx     7103 b- defN 22-Oct-13 22:26 torchdrug/models/infograph.py
--rw-r-----  2.0 unx     2628 b- defN 22-Oct-13 22:26 torchdrug/models/kbgat.py
--rw-r-----  2.0 unx     3447 b- defN 22-Oct-13 22:26 torchdrug/models/lstm.py
--rw-r-----  2.0 unx     3711 b- defN 22-Oct-13 22:26 torchdrug/models/mpnn.py
--rw-r-----  2.0 unx     3848 b- defN 22-Oct-13 22:26 torchdrug/models/neuralfp.py
--rw-r-----  2.0 unx     4832 b- defN 22-Oct-13 22:26 torchdrug/models/neurallp.py
--rw-r-----  2.0 unx     6851 b- defN 22-Oct-13 22:26 torchdrug/models/physicochemical.py
--rw-r-----  2.0 unx     3356 b- defN 22-Oct-13 22:26 torchdrug/models/schnet.py
--rw-r-----  2.0 unx     3308 b- defN 22-Oct-13 22:26 torchdrug/models/statistic.py
--rw-r-----  2.0 unx     1621 b- defN 22-Oct-13 22:26 torchdrug/tasks/__init__.py
--rw-r-----  2.0 unx     7324 b- defN 22-Oct-13 22:26 torchdrug/tasks/contact_prediction.py
--rw-r-----  2.0 unx    74693 b- defN 22-Oct-13 22:26 torchdrug/tasks/generation.py
--rw-r-----  2.0 unx    23162 b- defN 22-Oct-13 22:26 torchdrug/tasks/pretrain.py
--rw-r-----  2.0 unx    24026 b- defN 22-Oct-13 22:26 torchdrug/tasks/property_prediction.py
--rw-r-----  2.0 unx    11625 b- defN 22-Oct-13 22:26 torchdrug/tasks/reasoning.py
--rw-r-----  2.0 unx    55909 b- defN 22-Oct-13 22:26 torchdrug/tasks/retrosynthesis.py
--rw-r-----  2.0 unx     1107 b- defN 22-Oct-13 22:26 torchdrug/tasks/task.py
--rw-r-----  2.0 unx      317 b- defN 22-Oct-13 22:26 torchdrug/transforms/__init__.py
--rw-r-----  2.0 unx    11043 b- defN 22-Oct-13 22:26 torchdrug/transforms/transform.py
--rw-r-----  2.0 unx      717 b- defN 22-Oct-13 22:26 torchdrug/utils/__init__.py
--rw-r-----  2.0 unx     8428 b- defN 22-Oct-13 22:26 torchdrug/utils/comm.py
--rw-r-----  2.0 unx    10252 b- defN 22-Oct-13 22:26 torchdrug/utils/decorator.py
--rw-r-----  2.0 unx     5452 b- defN 22-Oct-13 22:26 torchdrug/utils/doc.py
--rw-r-----  2.0 unx     5973 b- defN 22-Oct-13 22:26 torchdrug/utils/file.py
--rw-r-----  2.0 unx     2165 b- defN 22-Oct-13 22:26 torchdrug/utils/io.py
--rw-r-----  2.0 unx     6852 b- defN 22-Oct-13 22:26 torchdrug/utils/plot.py
--rw-r-----  2.0 unx     1044 b- defN 22-Oct-13 22:26 torchdrug/utils/pretty.py
--rw-r-----  2.0 unx     6464 b- defN 22-Oct-13 22:26 torchdrug/utils/torch.py
--rw-r-----  2.0 unx        0 b- defN 22-Oct-13 22:26 torchdrug/utils/extension/__init__.py
--rw-r-----  2.0 unx      419 b- defN 22-Oct-13 22:26 torchdrug/utils/extension/torch_ext.cpp
--rw-r-----  2.0 unx     2267 b- defN 22-Oct-13 22:26 torchdrug/utils/template/echarts.html
--rw-r-----  2.0 unx    11342 b- defN 22-Oct-13 22:27 torchdrug-0.2.0.post1.dist-info/LICENSE
--rw-r-----  2.0 unx     7109 b- defN 22-Oct-13 22:27 torchdrug-0.2.0.post1.dist-info/METADATA
--rw-r-----  2.0 unx       92 b- defN 22-Oct-13 22:27 torchdrug-0.2.0.post1.dist-info/WHEEL
--rw-r-----  2.0 unx       10 b- defN 22-Oct-13 22:27 torchdrug-0.2.0.post1.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx    12588 b- defN 22-Oct-13 22:27 torchdrug-0.2.0.post1.dist-info/RECORD
-144 files, 1084397 bytes uncompressed, 247433 bytes compressed:  77.2%
+Zip file size: 268505 bytes, number of entries: 144
+-rw-r-----  2.0 unx      331 b- defN 23-Jul-16 21:57 torchdrug/__init__.py
+-rw-r-----  2.0 unx     5625 b- defN 23-Jul-16 21:57 torchdrug/patch.py
+-rw-r-----  2.0 unx      320 b- defN 23-Jul-16 21:57 torchdrug/core/__init__.py
+-rw-r-----  2.0 unx    13092 b- defN 23-Jul-16 21:57 torchdrug/core/core.py
+-rw-r-----  2.0 unx    11684 b- defN 23-Jul-16 21:57 torchdrug/core/engine.py
+-rw-r-----  2.0 unx     4197 b- defN 23-Jul-16 21:57 torchdrug/core/logger.py
+-rw-r-----  2.0 unx     3894 b- defN 23-Jul-16 21:57 torchdrug/core/meter.py
+-rw-r-----  2.0 unx      989 b- defN 23-Jul-16 21:57 torchdrug/data/__init__.py
+-rw-r-----  2.0 unx     3295 b- defN 23-Jul-16 21:57 torchdrug/data/constant.py
+-rw-r-----  2.0 unx     3729 b- defN 23-Jul-16 21:57 torchdrug/data/dataloader.py
+-rw-r-----  2.0 unx    49270 b- defN 23-Jul-16 21:57 torchdrug/data/dataset.py
+-rw-r-----  2.0 unx    10947 b- defN 23-Jul-16 21:57 torchdrug/data/dictionary.py
+-rw-r-----  2.0 unx    12499 b- defN 23-Jul-16 21:57 torchdrug/data/feature.py
+-rw-r-----  2.0 unx    76585 b- defN 23-Jul-16 21:57 torchdrug/data/graph.py
+-rw-r-----  2.0 unx    42173 b- defN 23-Jul-16 21:57 torchdrug/data/molecule.py
+-rw-r-----  2.0 unx    65238 b- defN 23-Jul-16 21:57 torchdrug/data/protein.py
+-rw-r-----  2.0 unx        0 b- defN 23-Jul-16 21:57 torchdrug/data/rdkit/__init__.py
+-rw-r-----  2.0 unx     1771 b- defN 23-Jul-16 21:57 torchdrug/data/rdkit/draw.py
+-rw-r-----  2.0 unx     2144 b- defN 23-Jul-16 21:57 torchdrug/datasets/__init__.py
+-rw-r-----  2.0 unx    10130 b- defN 23-Jul-16 21:57 torchdrug/datasets/alphafolddb.py
+-rw-r-----  2.0 unx     1111 b- defN 23-Jul-16 21:57 torchdrug/datasets/bace.py
+-rw-r-----  2.0 unx     1071 b- defN 23-Jul-16 21:57 torchdrug/datasets/bbbp.py
+-rw-r-----  2.0 unx     1652 b- defN 23-Jul-16 21:57 torchdrug/datasets/beta_lactamase.py
+-rw-r-----  2.0 unx     1750 b- defN 23-Jul-16 21:57 torchdrug/datasets/binary_localization.py
+-rw-r-----  2.0 unx     2566 b- defN 23-Jul-16 21:57 torchdrug/datasets/bindingdb.py
+-rw-r-----  2.0 unx     1122 b- defN 23-Jul-16 21:57 torchdrug/datasets/cep.py
+-rw-r-----  2.0 unx     1126 b- defN 23-Jul-16 21:57 torchdrug/datasets/chembl_filtered.py
+-rw-r-----  2.0 unx     1020 b- defN 23-Jul-16 21:57 torchdrug/datasets/citeseer.py
+-rw-r-----  2.0 unx     1207 b- defN 23-Jul-16 21:57 torchdrug/datasets/clintox.py
+-rw-r-----  2.0 unx      992 b- defN 23-Jul-16 21:57 torchdrug/datasets/cora.py
+-rw-r-----  2.0 unx     1119 b- defN 23-Jul-16 21:57 torchdrug/datasets/delaney.py
+-rw-r-----  2.0 unx     5152 b- defN 23-Jul-16 21:57 torchdrug/datasets/enzyme_commission.py
+-rw-r-----  2.0 unx     3362 b- defN 23-Jul-16 21:57 torchdrug/datasets/fb15k.py
+-rw-r-----  2.0 unx     1622 b- defN 23-Jul-16 21:57 torchdrug/datasets/fluorescence.py
+-rw-r-----  2.0 unx     1801 b- defN 23-Jul-16 21:57 torchdrug/datasets/fold.py
+-rw-r-----  2.0 unx     1173 b- defN 23-Jul-16 21:57 torchdrug/datasets/freesolv.py
+-rw-r-----  2.0 unx     5730 b- defN 23-Jul-16 21:57 torchdrug/datasets/gene_ontology.py
+-rw-r-----  2.0 unx     1641 b- defN 23-Jul-16 21:57 torchdrug/datasets/hetionet.py
+-rw-r-----  2.0 unx     1087 b- defN 23-Jul-16 21:57 torchdrug/datasets/hiv.py
+-rw-r-----  2.0 unx     2377 b- defN 23-Jul-16 21:57 torchdrug/datasets/human_ppi.py
+-rw-r-----  2.0 unx     1130 b- defN 23-Jul-16 21:57 torchdrug/datasets/lipophilicity.py
+-rw-r-----  2.0 unx     1171 b- defN 23-Jul-16 21:57 torchdrug/datasets/malaria.py
+-rw-r-----  2.0 unx     1590 b- defN 23-Jul-16 21:57 torchdrug/datasets/moses.py
+-rw-r-----  2.0 unx     1340 b- defN 23-Jul-16 21:57 torchdrug/datasets/muv.py
+-rw-r-----  2.0 unx     4242 b- defN 23-Jul-16 21:57 torchdrug/datasets/opv.py
+-rw-r-----  2.0 unx     1270 b- defN 23-Jul-16 21:57 torchdrug/datasets/pcqm4m.py
+-rw-r-----  2.0 unx     2559 b- defN 23-Jul-16 21:57 torchdrug/datasets/pdbbind.py
+-rw-r-----  2.0 unx     2380 b- defN 23-Jul-16 21:57 torchdrug/datasets/ppi_affinity.py
+-rw-r-----  2.0 unx     2370 b- defN 23-Jul-16 21:57 torchdrug/datasets/proteinnet.py
+-rw-r-----  2.0 unx     1314 b- defN 23-Jul-16 21:57 torchdrug/datasets/pubchem110m.py
+-rw-r-----  2.0 unx     3658 b- defN 23-Jul-16 21:57 torchdrug/datasets/pubmed.py
+-rw-r-----  2.0 unx     3259 b- defN 23-Jul-16 21:57 torchdrug/datasets/qm8.py
+-rw-r-----  2.0 unx     2553 b- defN 23-Jul-16 21:57 torchdrug/datasets/qm9.py
+-rw-r-----  2.0 unx     2459 b- defN 23-Jul-16 21:57 torchdrug/datasets/secondary_structure.py
+-rw-r-----  2.0 unx     1179 b- defN 23-Jul-16 21:57 torchdrug/datasets/sider.py
+-rw-r-----  2.0 unx     1612 b- defN 23-Jul-16 21:57 torchdrug/datasets/solubility.py
+-rw-r-----  2.0 unx     1600 b- defN 23-Jul-16 21:57 torchdrug/datasets/stability.py
+-rw-r-----  2.0 unx     1693 b- defN 23-Jul-16 21:57 torchdrug/datasets/subcellular_localization.py
+-rw-r-----  2.0 unx     1343 b- defN 23-Jul-16 21:57 torchdrug/datasets/tox21.py
+-rw-r-----  2.0 unx     1158 b- defN 23-Jul-16 21:57 torchdrug/datasets/toxcast.py
+-rw-r-----  2.0 unx    11457 b- defN 23-Jul-16 21:57 torchdrug/datasets/uspto50k.py
+-rw-r-----  2.0 unx     3294 b- defN 23-Jul-16 21:57 torchdrug/datasets/wn18.py
+-rw-r-----  2.0 unx     1785 b- defN 23-Jul-16 21:57 torchdrug/datasets/yago310.py
+-rw-r-----  2.0 unx     2377 b- defN 23-Jul-16 21:57 torchdrug/datasets/yeast_ppi.py
+-rw-r-----  2.0 unx     1162 b- defN 23-Jul-16 21:57 torchdrug/datasets/zinc250k.py
+-rw-r-----  2.0 unx     1743 b- defN 23-Jul-16 21:57 torchdrug/datasets/zinc2m.py
+-rw-r-----  2.0 unx     1793 b- defN 23-Jul-16 21:57 torchdrug/layers/__init__.py
+-rw-r-----  2.0 unx     5812 b- defN 23-Jul-16 21:57 torchdrug/layers/block.py
+-rw-r-----  2.0 unx    12209 b- defN 23-Jul-16 21:57 torchdrug/layers/common.py
+-rw-r-----  2.0 unx    33425 b- defN 23-Jul-16 21:57 torchdrug/layers/conv.py
+-rw-r-----  2.0 unx     1525 b- defN 23-Jul-16 21:57 torchdrug/layers/distribution.py
+-rw-r-----  2.0 unx     2145 b- defN 23-Jul-16 21:57 torchdrug/layers/flow.py
+-rw-r-----  2.0 unx     9381 b- defN 23-Jul-16 21:57 torchdrug/layers/pool.py
+-rw-r-----  2.0 unx     6144 b- defN 23-Jul-16 21:57 torchdrug/layers/readout.py
+-rw-r-----  2.0 unx     3062 b- defN 23-Jul-16 21:57 torchdrug/layers/sampler.py
+-rw-r-----  2.0 unx     1241 b- defN 23-Jul-16 21:57 torchdrug/layers/functional/__init__.py
+-rw-r-----  2.0 unx     9943 b- defN 23-Jul-16 21:57 torchdrug/layers/functional/embedding.py
+-rw-r-----  2.0 unx    18048 b- defN 23-Jul-16 21:57 torchdrug/layers/functional/functional.py
+-rw-r-----  2.0 unx    13670 b- defN 23-Jul-16 21:57 torchdrug/layers/functional/spmm.py
+-rw-r-----  2.0 unx        0 b- defN 23-Jul-16 21:57 torchdrug/layers/functional/extension/__init__.py
+-rw-r-----  2.0 unx    25464 b- defN 23-Jul-16 21:57 torchdrug/layers/functional/extension/embedding.cpp
+-rw-r-----  2.0 unx    25353 b- defN 23-Jul-16 21:57 torchdrug/layers/functional/extension/embedding.cu
+-rw-r-----  2.0 unx     4529 b- defN 23-Jul-16 21:57 torchdrug/layers/functional/extension/embedding.h
+-rw-r-----  2.0 unx     1841 b- defN 23-Jul-16 21:57 torchdrug/layers/functional/extension/operator.cuh
+-rw-r-----  2.0 unx    12434 b- defN 23-Jul-16 21:57 torchdrug/layers/functional/extension/rspmm.cpp
+-rw-r-----  2.0 unx    16670 b- defN 23-Jul-16 21:57 torchdrug/layers/functional/extension/rspmm.cu
+-rw-r-----  2.0 unx     4506 b- defN 23-Jul-16 21:57 torchdrug/layers/functional/extension/rspmm.h
+-rw-r-----  2.0 unx    13877 b- defN 23-Jul-16 21:57 torchdrug/layers/functional/extension/spmm.cpp
+-rw-r-----  2.0 unx    14092 b- defN 23-Jul-16 21:57 torchdrug/layers/functional/extension/spmm.cu
+-rw-r-----  2.0 unx     3693 b- defN 23-Jul-16 21:57 torchdrug/layers/functional/extension/spmm.h
+-rw-r-----  2.0 unx      623 b- defN 23-Jul-16 21:57 torchdrug/layers/functional/extension/util.cuh
+-rw-r-----  2.0 unx      418 b- defN 23-Jul-16 21:57 torchdrug/layers/geometry/__init__.py
+-rw-r-----  2.0 unx    13246 b- defN 23-Jul-16 21:57 torchdrug/layers/geometry/function.py
+-rw-r-----  2.0 unx     8152 b- defN 23-Jul-16 21:57 torchdrug/layers/geometry/graph.py
+-rw-r-----  2.0 unx      643 b- defN 23-Jul-16 21:57 torchdrug/metrics/__init__.py
+-rw-r-----  2.0 unx    13528 b- defN 23-Jul-16 21:57 torchdrug/metrics/metric.py
+-rw-r-----  2.0 unx        0 b- defN 23-Jul-16 21:57 torchdrug/metrics/rdkit/__init__.py
+-rw-r-----  2.0 unx     2471 b- defN 23-Jul-16 21:57 torchdrug/metrics/rdkit/sascorer.py
+-rw-r-----  2.0 unx     2121 b- defN 23-Jul-16 21:57 torchdrug/models/__init__.py
+-rw-r-----  2.0 unx     4348 b- defN 23-Jul-16 21:57 torchdrug/models/bert.py
+-rw-r-----  2.0 unx     3549 b- defN 23-Jul-16 21:57 torchdrug/models/chebnet.py
+-rw-r-----  2.0 unx     8817 b- defN 23-Jul-16 21:57 torchdrug/models/cnn.py
+-rw-r-----  2.0 unx    10023 b- defN 23-Jul-16 21:57 torchdrug/models/embedding.py
+-rw-r-----  2.0 unx     7454 b- defN 23-Jul-16 21:57 torchdrug/models/esm.py
+-rw-r-----  2.0 unx     5039 b- defN 23-Jul-16 21:57 torchdrug/models/flow.py
+-rw-r-----  2.0 unx     3503 b- defN 23-Jul-16 21:57 torchdrug/models/gat.py
+-rw-r-----  2.0 unx     6806 b- defN 23-Jul-16 21:57 torchdrug/models/gcn.py
+-rw-r-----  2.0 unx     5562 b- defN 23-Jul-16 21:57 torchdrug/models/gearnet.py
+-rw-r-----  2.0 unx     3669 b- defN 23-Jul-16 21:57 torchdrug/models/gin.py
+-rw-r-----  2.0 unx     7228 b- defN 23-Jul-16 21:57 torchdrug/models/infograph.py
+-rw-r-----  2.0 unx     2628 b- defN 23-Jul-16 21:57 torchdrug/models/kbgat.py
+-rw-r-----  2.0 unx     3396 b- defN 23-Jul-16 21:57 torchdrug/models/lstm.py
+-rw-r-----  2.0 unx     3720 b- defN 23-Jul-16 21:57 torchdrug/models/mpnn.py
+-rw-r-----  2.0 unx     3848 b- defN 23-Jul-16 21:57 torchdrug/models/neuralfp.py
+-rw-r-----  2.0 unx     4864 b- defN 23-Jul-16 21:57 torchdrug/models/neurallp.py
+-rw-r-----  2.0 unx     6849 b- defN 23-Jul-16 21:57 torchdrug/models/physicochemical.py
+-rw-r-----  2.0 unx     3356 b- defN 23-Jul-16 21:57 torchdrug/models/schnet.py
+-rw-r-----  2.0 unx     3308 b- defN 23-Jul-16 21:57 torchdrug/models/statistic.py
+-rw-r-----  2.0 unx     1621 b- defN 23-Jul-16 21:57 torchdrug/tasks/__init__.py
+-rw-r-----  2.0 unx     7378 b- defN 23-Jul-16 21:57 torchdrug/tasks/contact_prediction.py
+-rw-r-----  2.0 unx    74693 b- defN 23-Jul-16 21:57 torchdrug/tasks/generation.py
+-rw-r-----  2.0 unx    23157 b- defN 23-Jul-16 21:57 torchdrug/tasks/pretrain.py
+-rw-r-----  2.0 unx    24382 b- defN 23-Jul-16 21:57 torchdrug/tasks/property_prediction.py
+-rw-r-----  2.0 unx    11993 b- defN 23-Jul-16 21:57 torchdrug/tasks/reasoning.py
+-rw-r-----  2.0 unx    55899 b- defN 23-Jul-16 21:57 torchdrug/tasks/retrosynthesis.py
+-rw-r-----  2.0 unx     1111 b- defN 23-Jul-16 21:57 torchdrug/tasks/task.py
+-rw-r-----  2.0 unx      317 b- defN 23-Jul-16 21:57 torchdrug/transforms/__init__.py
+-rw-r-----  2.0 unx    11043 b- defN 23-Jul-16 21:57 torchdrug/transforms/transform.py
+-rw-r-----  2.0 unx      717 b- defN 23-Jul-16 21:57 torchdrug/utils/__init__.py
+-rw-r-----  2.0 unx     8428 b- defN 23-Jul-16 21:57 torchdrug/utils/comm.py
+-rw-r-----  2.0 unx    10252 b- defN 23-Jul-16 21:57 torchdrug/utils/decorator.py
+-rw-r-----  2.0 unx     5973 b- defN 23-Jul-16 21:57 torchdrug/utils/file.py
+-rw-r-----  2.0 unx     2165 b- defN 23-Jul-16 21:57 torchdrug/utils/io.py
+-rw-r-----  2.0 unx     6852 b- defN 23-Jul-16 21:57 torchdrug/utils/plot.py
+-rw-r-----  2.0 unx     1931 b- defN 23-Jul-16 21:57 torchdrug/utils/pretty.py
+-rw-r-----  2.0 unx     6550 b- defN 23-Jul-16 21:57 torchdrug/utils/torch.py
+-rw-r-----  2.0 unx        0 b- defN 23-Jul-16 21:57 torchdrug/utils/extension/__init__.py
+-rw-r-----  2.0 unx      419 b- defN 23-Jul-16 21:57 torchdrug/utils/extension/torch_ext.cpp
+-rw-r-----  2.0 unx     2267 b- defN 23-Jul-16 21:57 torchdrug/utils/template/echarts.html
+-rw-r-----  2.0 unx    11342 b- defN 23-Jul-16 21:59 torchdrug-0.2.1.dist-info/LICENSE
+-rw-r-----  2.0 unx     7515 b- defN 23-Jul-16 21:59 torchdrug-0.2.1.dist-info/METADATA
+-rw-r-----  2.0 unx       92 b- defN 23-Jul-16 21:59 torchdrug-0.2.1.dist-info/WHEEL
+-rw-r-----  2.0 unx       10 b- defN 23-Jul-16 21:59 torchdrug-0.2.1.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx    12566 b- defN 23-Jul-16 21:59 torchdrug-0.2.1.dist-info/RECORD
+144 files, 1086991 bytes uncompressed, 248725 bytes compressed:  77.1%
```

## zipnote {}

```diff
@@ -180,14 +180,17 @@
 
 Filename: torchdrug/datasets/uspto50k.py
 Comment: 
 
 Filename: torchdrug/datasets/wn18.py
 Comment: 
 
+Filename: torchdrug/datasets/yago310.py
+Comment: 
+
 Filename: torchdrug/datasets/yeast_ppi.py
 Comment: 
 
 Filename: torchdrug/datasets/zinc250k.py
 Comment: 
 
 Filename: torchdrug/datasets/zinc2m.py
@@ -384,17 +387,14 @@
 
 Filename: torchdrug/utils/comm.py
 Comment: 
 
 Filename: torchdrug/utils/decorator.py
 Comment: 
 
-Filename: torchdrug/utils/doc.py
-Comment: 
-
 Filename: torchdrug/utils/file.py
 Comment: 
 
 Filename: torchdrug/utils/io.py
 Comment: 
 
 Filename: torchdrug/utils/plot.py
@@ -411,23 +411,23 @@
 
 Filename: torchdrug/utils/extension/torch_ext.cpp
 Comment: 
 
 Filename: torchdrug/utils/template/echarts.html
 Comment: 
 
-Filename: torchdrug-0.2.0.post1.dist-info/LICENSE
+Filename: torchdrug-0.2.1.dist-info/LICENSE
 Comment: 
 
-Filename: torchdrug-0.2.0.post1.dist-info/METADATA
+Filename: torchdrug-0.2.1.dist-info/METADATA
 Comment: 
 
-Filename: torchdrug-0.2.0.post1.dist-info/WHEEL
+Filename: torchdrug-0.2.1.dist-info/WHEEL
 Comment: 
 
-Filename: torchdrug-0.2.0.post1.dist-info/top_level.txt
+Filename: torchdrug-0.2.1.dist-info/top_level.txt
 Comment: 
 
-Filename: torchdrug-0.2.0.post1.dist-info/RECORD
+Filename: torchdrug-0.2.1.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## torchdrug/__init__.py

```diff
@@ -8,8 +8,8 @@
 logger.setLevel(logging.INFO)
 format = logging.Formatter("%(asctime)-10s %(message)s", "%H:%M:%S")
 
 handler = logging.StreamHandler(sys.stdout)
 handler.setFormatter(format)
 logger.addHandler(handler)
 
-__version__ = "0.2.0"
+__version__ = "0.2.1"
```

## torchdrug/patch.py

```diff
@@ -64,15 +64,15 @@
     def register_buffer(self, name, tensor, persistent=True):
         if persistent is False and isinstance(self, torch.jit.ScriptModule):
             raise RuntimeError("ScriptModule does not support non-persistent buffers")
 
         if '_buffers' not in self.__dict__:
             raise AttributeError(
                 "cannot assign buffer before Module.__init__() call")
-        elif not isinstance(name, torch._six.string_classes):
+        elif not isinstance(name, str):
             raise TypeError("buffer name should be a string. "
                             "Got {}".format(torch.typename(name)))
         elif '.' in name:
             raise KeyError("buffer name can't contain \".\"")
         elif name == '':
             raise KeyError("buffer name can't be empty string \"\"")
         elif hasattr(self, name) and name not in self._buffers:
@@ -85,27 +85,14 @@
             self._buffers[name] = tensor
             if persistent:
                 self._non_persistent_buffers_set.discard(name)
             else:
                 self._non_persistent_buffers_set.add(name)
 
 
-class PatchedDistributedDataParallel(nn.parallel.DistributedDataParallel):
-
-    def _distributed_broadcast_coalesced(self, tensors, buffer_size, *args, **kwargs):
-        new_tensors = []
-        for tensor in tensors:
-            # do not broadcast graphs
-            # assume graphs are already init by each process
-            if isinstance(tensor, torch.Tensor):
-                new_tensors.append(tensor)
-        if new_tensors:
-            dist._broadcast_coalesced(self.process_group, new_tensors, buffer_size, *args, **kwargs)
-
-
 def _get_build_directory(name, verbose):
     root_extensions_directory = os.environ.get('TORCH_EXTENSIONS_DIR')
     if root_extensions_directory is None:
         root_extensions_directory = cpp_extension.get_default_build_root()
 
     if verbose:
         print('Using {} as PyTorch extensions root...'.format(
@@ -129,31 +116,30 @@
 def patch(module, name, cls):
     backup = getattr(module, name)
     setattr(module, "_%s" % name, backup)
     setattr(module, name, cls)
 
 
 patch(nn, "Module", PatchedModule)
-patch(nn.parallel, "DistributedDataParallel", PatchedDistributedDataParallel)
 patch(cpp_extension, "_get_build_directory", _get_build_directory)
 
 Optimizer = optim.Optimizer
 for name, cls in inspect.getmembers(optim):
     if inspect.isclass(cls) and issubclass(cls, Optimizer):
         cls = core.make_configurable(cls, ignore_args=("params",))
         cls = R.register("optim.%s" % name)(cls)
         patch(optim, name, cls)
 
 Scheduler = scheduler._LRScheduler
 for name, cls in inspect.getmembers(scheduler):
     if inspect.isclass(cls) and issubclass(cls, Scheduler):
         cls = core.make_configurable(cls, ignore_args=("optimizer",))
         cls = R.register("scheduler.%s" % name)(cls)
-        patch(scheduler, name, cls)
+        setattr(optim, name, cls)
 
 Dataset = dataset.Dataset
 for name, cls in inspect.getmembers(dataset):
     if inspect.isclass(cls) and issubclass(cls, Dataset):
         cls = core.make_configurable(cls)
         cls = R.register("dataset.%s" % name)(cls)
         patch(dataset, name, cls)
-importlib.reload(torch.utils.data)
+importlib.reload(torch.utils.data)
```

## torchdrug/core/core.py

```diff
@@ -82,15 +82,14 @@
             if types:
                 self.meta_dict[key] = types.copy()
         self._setattr(key, value)
 
     def __delattr__(self, key):
         if hasattr(self, "meta_dict") and key in self.meta_dict:
             del self.meta_dict[key]
-            del self.data_dict[key]
         super(_MetaContainer, self).__delattr__(self, key)
 
     def _setattr(self, key, value):
         return super(_MetaContainer, self).__setattr__(key, value)
 
     @property
     def data_dict(self):
@@ -197,15 +196,15 @@
             return obj
 
         return wrapper
 
     @classmethod
     def get(cls, name):
         """
-        Get an object with a canonical name. Hierachical names are separated by ``.``.
+        Get an object with a canonical name. Hierarchical names are separated by ``.``.
         """
         entry = cls.table
         keys = name.split(".")
         for i, key in enumerate(keys):
             if key not in entry:
                 raise KeyError("Can't find `%s` in `%s`" % (key, ".".join(keys[:i])))
             entry = entry[key]
@@ -231,21 +230,30 @@
             raise KeyError("Ambiguous key `%s`. Found %s" % (name, ", ".join(keys)))
         return value
 
 
 class _Configurable(type):
 
     def config_dict(self):
+
+        def unroll_config_dict(obj):
+            if isinstance(type(obj), _Configurable):
+                obj = obj.config_dict()
+            elif isinstance(obj, (str, bytes)):
+                return obj
+            elif isinstance(obj, dict):
+                return type(obj)({k: unroll_config_dict(v) for k, v in obj.items()})
+            elif isinstance(obj, (list, tuple)):
+                return type(obj)(unroll_config_dict(x) for x in obj)
+            return obj
+
         cls = getattr(self, "_registry_key", self.__class__.__name__)
         config = {"class": cls}
-
         for k, v in self._config.items():
-            if isinstance(type(v), _Configurable):
-                v = v.config_dict()
-            config[k] = v
+            config[k] = unroll_config_dict(v)
         return config
 
     @classmethod
     def load_config_dict(cls, config):
         if cls == _Configurable:
             real_cls = Registry.search(config["class"])
             custom_load_func = real_cls.load_config_dict.__func__ != cls.load_config_dict.__func__
@@ -357,8 +365,8 @@
     Metaclass = type(cls)
     if issubclass(Metaclass, _Configurable): # already a configurable class
         return cls
     if Metaclass != type: # already have a meta class
         MetaClass = type(_Configurable.__name__, (Metaclass, _Configurable), {})
     else:
         MetaClass = _Configurable
-    return MetaClass(cls.__name__, (cls,), {"_ignore_args": ignore_args, "__module__": module})
+    return MetaClass(cls.__name__, (cls,), {"_ignore_args": ignore_args, "__module__": module})
```

## torchdrug/core/engine.py

```diff
@@ -93,14 +93,19 @@
             if result is not None:
                 train_set, valid_set, test_set = result
             new_params = list(task.parameters())
             if len(new_params) != len(old_params):
                 optimizer.add_param_group({"params": new_params[len(old_params):]})
         if self.world_size > 1:
             task = nn.SyncBatchNorm.convert_sync_batchnorm(task)
+            buffers_to_ignore = []
+            for name, buffer in task.named_buffers():
+                if not isinstance(buffer, torch.Tensor):
+                    buffers_to_ignore.append(name)
+            task._ddp_params_and_buffers_to_ignore = set(buffers_to_ignore)
         if self.device.type == "cuda":
             task = task.cuda(self.device)
 
         self.model = task
         self.train_set = train_set
         self.valid_set = valid_set
         self.test_set = test_set
@@ -128,14 +133,15 @@
             num_epoch (int, optional): number of epochs
             batch_per_epoch (int, optional): number of batches per epoch
         """
         sampler = torch_data.DistributedSampler(self.train_set, self.world_size, self.rank)
         dataloader = data.DataLoader(self.train_set, self.batch_size, sampler=sampler, num_workers=self.num_worker)
         batch_per_epoch = batch_per_epoch or len(dataloader)
         model = self.model
+        model.split = "train"
         if self.world_size > 1:
             if self.device.type == "cuda":
                 model = nn.parallel.DistributedDataParallel(model, device_ids=[self.device],
                                                             find_unused_parameters=True)
             else:
                 model = nn.parallel.DistributedDataParallel(model, find_unused_parameters=True)
         model.train()
@@ -191,14 +197,15 @@
         if comm.get_rank() == 0:
             logger.warning(pretty.separator)
             logger.warning("Evaluate on %s" % split)
         test_set = getattr(self, "%s_set" % split)
         sampler = torch_data.DistributedSampler(test_set, self.world_size, self.rank)
         dataloader = data.DataLoader(test_set, self.batch_size, sampler=sampler, num_workers=self.num_worker)
         model = self.model
+        model.split = split
 
         model.eval()
         preds = []
         targets = []
         for batch in dataloader:
             if self.device.type == "cuda":
                 batch = utils.cuda(batch, device=self.device)
@@ -214,28 +221,29 @@
             target = comm.cat(target)
         metric = model.evaluate(pred, target)
         if log:
             self.meter.log(metric, category="%s/epoch" % split)
 
         return metric
 
-    def load(self, checkpoint, load_optimizer=True):
+    def load(self, checkpoint, load_optimizer=True, strict=True):
         """
         Load a checkpoint from file.
 
         Parameters:
             checkpoint (file-like): checkpoint file
             load_optimizer (bool, optional): load optimizer state or not
+            strict (bool, optional): whether to strictly check the checkpoint matches the model parameters
         """
         if comm.get_rank() == 0:
             logger.warning("Load checkpoint from %s" % checkpoint)
         checkpoint = os.path.expanduser(checkpoint)
         state = torch.load(checkpoint, map_location=self.device)
 
-        self.model.load_state_dict(state["model"])
+        self.model.load_state_dict(state["model"], strict=strict)
 
         if load_optimizer:
             self.optimizer.load_state_dict(state["optimizer"])
             for state in self.optimizer.state.values():
                 for k, v in state.items():
                     if isinstance(v, torch.Tensor):
                         state[k] = v.to(self.device)
```

## torchdrug/core/logger.py

```diff
@@ -1,8 +1,7 @@
-import pprint
 import logging
 import warnings
 
 from torchdrug.core import Registry as R
 from torchdrug.utils import pretty
 
 
@@ -66,15 +65,15 @@
             for k in sorted(record.keys()):
                 self.logger.warning("average %s: %g" % (k, record[k]))
         else:
             for k in sorted(record.keys()):
                 self.logger.warning("%s: %g" % (k, record[k]))
 
     def log_config(self, config):
-        self.logger.warning(pprint.pformat(config))
+        self.logger.warning(pretty.format(config, compact=True))
 
 
 @R.register("core.WandbLogger")
 class WandbLogger(LoggingLogger):
     """
     Log outputs with `Weights and Biases`_ and track the experiment progress.
 
@@ -100,16 +99,17 @@
         try:
             import wandb
         except ModuleNotFoundError:
             raise ModuleNotFoundError("Wandb is not found. Please install it with `pip install wandb`")
 
         if wandb.run is not None:
             warnings.warn(
-                 "There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse"
-                " this run. If this is not desired, call `wandb.finish()` or `WandbLogger.finish()` before instantiating `WandbLogger`."
+                "There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse "
+                "this run. If this is not desired, call `wandb.finish()` or `WandbLogger.finish()` before "
+                "instantiating `WandbLogger`."
             )
             self.run = wandb.run
         else:
             self.run = wandb.init(project=project, name=name, dir=dir, **kwargs)
 
         self.run.define_metric("train/batch/*", step_metric="batch", summary="none")
         for split in ["train", "valid", "test"]:
```

## torchdrug/data/dataset.py

```diff
@@ -1,15 +1,16 @@
 import os
 import csv
 import math
 import lmdb
 import pickle
 import logging
 import warnings
-from collections import defaultdict, Sequence
+from collections import defaultdict
+from collections.abc import Sequence
 
 from tqdm import tqdm
 
 import numpy as np
 
 from rdkit import Chem
 from rdkit.Chem.Scaffolds import MurckoScaffold
```

## torchdrug/data/feature.py

```diff
@@ -46,14 +46,15 @@
         if index == -1:
             raise ValueError("Unknown value `%s`. Available vocabulary is `%s`" % (x, vocab))
         feature[index] = 1
 
     return feature
 
 
+# TODO: this one is too slow
 @R.register("features.atom.default")
 def atom_default(atom):
     """Default atom feature.
 
     Features:
         GetSymbol(): one-hot embedding for the atomic symbol
         
@@ -327,14 +328,15 @@
 
 
 @R.register("features.molecule.default")
 def molecule_default(mol):
     """Default molecule feature."""
     return ExtendedConnectivityFingerprint(mol)
 
+
 ECFP = ExtendedConnectivityFingerprint
 
 
 __all__ = [
     "atom_default", "atom_center_identification", "atom_synthon_completion",
     "atom_symbol", "atom_explicit_property_prediction", "atom_property_prediction",
     "atom_position", "atom_pretrain", "atom_residue_symbol",
```

## torchdrug/data/graph.py

```diff
@@ -535,15 +535,15 @@
         base = torch.tensor(self.shape, device=self.device)
         base = base[mask]
         max = reduce(int.__mul__, base.tolist())
         if max > torch.iinfo(torch.int64).max:
             raise ValueError("Fail to build an inverted index table based on sorting. "
                              "The graph is too large.")
         scale = base.cumprod(0)
-        scale = scale[-1] // scale
+        scale = torch.div(scale[-1], scale, rounding_mode="floor")
         key = (keys * scale).sum(dim=-1)
         order = key.argsort()
         num_keys = key.unique(return_counts=True)[1]
         ends = num_keys.cumsum(0)
         starts = ends - num_keys
         ranges = torch.stack([starts, ends], dim=-1)
         keys_set = keys[order[starts]]
@@ -721,15 +721,15 @@
         starts = (size.cumsum(0) - size).repeat_interleave(size)
         range = torch.arange(size.sum(), device=self.device)
         # each node u has degree_out[u] * degree_in[u] local edges
         local_index = range - starts
         local_inner_size = degree_in.repeat_interleave(size)
         edge_in_offset = (degree_out.cumsum(0) - degree_out).repeat_interleave(size)
         edge_out_offset = (degree_in.cumsum(0) - degree_in).repeat_interleave(size)
-        edge_in_index = local_index // local_inner_size + edge_in_offset
+        edge_in_index = torch.div(local_index, local_inner_size, rounding_mode="floor") + edge_in_offset
         edge_out_index = local_index % local_inner_size + edge_out_offset
 
         edge_in = edge_in[edge_in_index]
         edge_out = edge_out[edge_out_index]
         edge_list = torch.stack([edge_in, edge_out], dim=-1)
         node_feature = getattr(self, "edge_feature", None)
         num_node = self.num_edge
@@ -1027,14 +1027,18 @@
 
         if is_root:
             if save_file:
                 fig.savefig(save_file)
             else:
                 fig.show()
 
+    @classmethod
+    def __torch_function__(cls, func, types, args=(), kwargs=None):
+        return NotImplemented
+
     def __getstate__(self):
         state = {}
         cls = self.__class__
         for k, v in self.__dict__.items():
             # do not pickle property / cached property
             if hasattr(cls, k) and isinstance(getattr(cls, k), property):
                 continue
@@ -1490,23 +1494,21 @@
         graphs = self.unpack()
         graphs = [graph.full() for graph in graphs]
         return graphs[0].pack(graphs)
 
     @utils.cached_property
     def node2graph(self):
         """Node id to graph id mapping."""
-        range = torch.arange(self.batch_size, device=self.device)
-        node2graph = range.repeat_interleave(self.num_nodes)
+        node2graph = torch.repeat_interleave(self.num_nodes)
         return node2graph
 
     @utils.cached_property
     def edge2graph(self):
         """Edge id to graph id mapping."""
-        range = torch.arange(self.batch_size, device=self.device)
-        edge2graph = range.repeat_interleave(self.num_edges)
+        edge2graph = torch.repeat_interleave(self.num_edges)
         return edge2graph
 
     @property
     def batch_size(self):
         """Batch size."""
         return len(self.num_nodes)
 
@@ -1660,15 +1662,15 @@
         starts = (size.cumsum(0) - size).repeat_interleave(size)
         range = torch.arange(size.sum(), device=self.device)
         # each node u has degree_out[u] * degree_in[u] local edges
         local_index = range - starts
         local_inner_size = degree_in.repeat_interleave(size)
         edge_in_offset = (degree_out.cumsum(0) - degree_out).repeat_interleave(size)
         edge_out_offset = (degree_in.cumsum(0) - degree_in).repeat_interleave(size)
-        edge_in_index = local_index // local_inner_size + edge_in_offset
+        edge_in_index = torch.div(local_index, local_inner_size, rounding_mode="floor") + edge_in_offset
         edge_out_index = local_index % local_inner_size + edge_out_offset
 
         edge_in = edge_in[edge_in_index]
         edge_out = edge_out[edge_out_index]
         edge_list = torch.stack([edge_in, edge_out], dim=-1)
         node_feature = getattr(self, "edge_feature", None)
         num_nodes = self.num_edges
```

## torchdrug/data/molecule.py

```diff
@@ -1,11 +1,11 @@
 import math
 import warnings
 from copy import copy
-from collections import Sequence
+from collections.abc import Sequence
 
 from matplotlib import pyplot as plt
 from rdkit import Chem
 from rdkit.Chem.Scaffolds import MurckoScaffold
 import torch
 from torch_scatter import scatter_add, scatter_min
```

## torchdrug/data/protein.py

```diff
@@ -1,8 +1,9 @@
 import os
+import string
 import warnings
 from collections import defaultdict
 
 from rdkit import Chem
 import torch
 from torch_scatter import scatter_add, scatter_max, scatter_min
 
@@ -46,26 +47,24 @@
     dummy_protein = Chem.MolFromSequence("G")
     dummy_atom = dummy_protein.GetAtomWithIdx(0)
 
     # TODO: rdkit isn't compatible with X in the sequence
     residue2id = {"GLY": 0, "ALA": 1, "SER": 2, "PRO": 3, "VAL": 4, "THR": 5, "CYS": 6, "ILE": 7, "LEU": 8,
                   "ASN": 9, "ASP": 10, "GLN": 11, "LYS": 12, "GLU": 13, "MET": 14, "HIS": 15, "PHE": 16,
                   "ARG": 17, "TYR": 18, "TRP": 19}
+    residue_symbol2id = {"G": 0, "A": 1, "S": 2, "P": 3, "V": 4, "T": 5, "C": 6, "I": 7, "L": 8, "N": 9,
+                         "D": 10, "Q": 11, "K": 12, "E": 13, "M": 14, "H": 15, "F": 16, "R": 17, "Y": 18, "W": 19}
     atom_name2id = {"C": 0, "CA": 1, "CB": 2, "CD": 3, "CD1": 4, "CD2": 5, "CE": 6, "CE1": 7, "CE2": 8,
                     "CE3": 9, "CG": 10, "CG1": 11, "CG2": 12, "CH2": 13, "CZ": 14, "CZ2": 15, "CZ3": 16,
                     "N": 17, "ND1": 18, "ND2": 19, "NE": 20, "NE1": 21, "NE2": 22, "NH1": 23, "NH2": 24,
                     "NZ": 25, "O": 26, "OD1": 27, "OD2": 28, "OE1": 29, "OE2": 30, "OG": 31, "OG1": 32,
                     "OH": 33, "OXT": 34, "SD": 35, "SG": 36, "UNK": 37}
-    alphabet2id = {" ": 0, "A": 1, "B": 2, "C": 3, "D": 4, "E": 5, "F": 6, "G": 7, "H": 8, "I": 9, "J": 10,
-                   "K": 11, "L": 12, "M": 13, "N": 14, "O": 15, "P": 16, "Q": 17, "R": 18, "S": 19, "T": 20,
-                   "U": 21, "V": 22, "W": 23, "X": 24, "Y": 25, "Z": 26}
+    alphabet2id = {c: i for i, c in enumerate(" " + string.ascii_uppercase + string.ascii_lowercase + string.digits)}
     id2residue = {v: k for k, v in residue2id.items()}
-    id2residue_symbol = {0: "G", 1: "A", 2: "S", 3: "P", 4: "V", 5: "T", 6: "C", 7: "I", 8: "L", 9: "N",
-                         10: "D", 11: "Q", 12: "K", 13: "E", 14: "M", 15: "H", 16: "F", 17: "R", 18: "Y", 19: "W"}
-    residue_symbol2id = {v: k for k, v in id2residue_symbol.items()}
+    id2residue_symbol = {v: k for k, v in residue_symbol2id.items()}
     id2atom_name = {v: k for k, v in atom_name2id.items()}
     id2alphabet = {v: k for k, v in alphabet2id.items()}
 
     def __init__(self, edge_list=None, atom_type=None, bond_type=None, residue_type=None, view=None,
                  atom_name=None, atom2residue=None, residue_feature=None, is_hetero_atom=None, occupancy=None,
                  b_factor=None, residue_number=None, insertion_code=None, chain_id=None, **kwargs):
         super(Protein, self).__init__(edge_list, atom_type, bond_type, **kwargs)
@@ -210,15 +209,19 @@
             if canonical_residue != last_residue:
                 last_residue = canonical_residue
                 if type not in cls.residue2id:
                     warnings.warn("Unknown residue `%s`. Treat as glycine" % type)
                     type = "GLY"
                 residue_type.append(cls.residue2id[type])
                 residue_number.append(number)
-                if pdbinfo.GetInsertionCode() not in cls.alphabet2id or pdbinfo.GetChainId() not in cls.alphabet2id:
+                if pdbinfo.GetInsertionCode() not in cls.alphabet2id:
+                    warnings.warn(f"Fail to create the protein. Unknown insertion code {pdbinfo.GetInsertionCode()}.")
+                    return None
+                if pdbinfo.GetChainId() not in cls.alphabet2id:
+                    warnings.warn(f"Fail to create the protein. Unknown chain id {pdbinfo.GetChainId()}.")
                     return None
                 insertion_code.append(cls.alphabet2id[pdbinfo.GetInsertionCode()])
                 chain_id.append(cls.alphabet2id[pdbinfo.GetChainId()])
                 feature = []
                 for name in residue_feature:
                     func = R.get("features.residue.%s" % name)
                     feature += func(pdbinfo)
@@ -291,15 +294,15 @@
             kekulize (bool, optional): convert aromatic bonds to single/double bonds.
                 Note this only affects the relation in ``edge_list``.
                 For ``bond_type``, aromatic bonds are always stored explicitly.
                 By default, aromatic bonds are stored.
         """
         if atom_feature is None and bond_feature is None and residue_feature == "default":
             return cls._residue_from_sequence(sequence)
-        
+
         mol = Chem.MolFromSequence(sequence)
         if mol is None:
             raise ValueError("Invalid sequence `%s`" % sequence)
 
         return cls.from_molecule(mol, atom_feature, bond_feature, residue_feature, mol_feature, kekulize)
 
     @classmethod
@@ -610,15 +613,15 @@
 
         if compact:
             data_dict, meta_dict = self.data_mask(node_index, edge_index, residue_index=index)
         else:
             data_dict, meta_dict = self.data_mask(edge_index=edge_index)
 
         return type(self)(edge_list[edge_index], edge_weight=self.edge_weight[edge_index], num_node=num_node,
-                          view=self.view, meta_dict=meta_dict, **data_dict)
+                          view=self.view, num_relation=self.num_relation, meta_dict=meta_dict, **data_dict)
 
     def subresidue(self, index):
         """
         Return a subgraph based on the specified residues.
         Equivalent to :meth:`residue_mask(index, compact=True) <residue_mask>`.
 
         Parameters:
```

## torchdrug/datasets/__init__.py

```diff
@@ -39,14 +39,15 @@
 
 from .enzyme_commission import EnzymeCommission
 from .gene_ontology import GeneOntology
 from .alphafolddb import AlphaFoldDB
 
 from .fb15k import FB15k, FB15k237
 from .wn18 import WN18, WN18RR
+from .yago310 import YAGO310
 from .hetionet import Hetionet
 
 from .cora import Cora
 from .citeseer import CiteSeer
 from .pubmed import PubMed
 
 __all__ = [
```

## torchdrug/datasets/alphafolddb.py

```diff
@@ -14,18 +14,18 @@
 
     Statistics:
         See https://alphafold.ebi.ac.uk/download
 
     Parameters:
         path (str): path to store the dataset
         species_id (int, optional): the id of species to be loaded. The species are numbered
-            by the order appeared on https://alphafold.ebi.ac.uk/download (0-20 for model 
+            by the order appeared on https://alphafold.ebi.ac.uk/download (0-20 for model
             organism proteomes, 21 for Swiss-Prot)
-        split_id (int, optional): the id of split to be loaded. To avoid large memory consumption 
-            for one dataset, we have cut each species into several splits, each of which contains 
+        split_id (int, optional): the id of split to be loaded. To avoid large memory consumption
+            for one dataset, we have cut each species into several splits, each of which contains
             at most 22000 proteins.
         verbose (int, optional): output verbose level
         **kwargs
     """
 
     urls = [
         "https://ftp.ebi.ac.uk/pub/databases/alphafold/v2/UP000006548_3702_ARATH_v2.tar",
@@ -56,66 +56,72 @@
         "https://ftp.ebi.ac.uk/pub/databases/alphafold/v2/UP000094526_86049_9EURO1_v2.tar",
         "https://ftp.ebi.ac.uk/pub/databases/alphafold/v2/UP000274756_318479_DRAME_v2.tar",
         "https://ftp.ebi.ac.uk/pub/databases/alphafold/v2/UP000325664_1352_ENTFC_v2.tar",
         "https://ftp.ebi.ac.uk/pub/databases/alphafold/v2/UP000053029_1442368_9EURO2_v2.tar",
         "https://ftp.ebi.ac.uk/pub/databases/alphafold/v2/UP000000579_71421_HAEIN_v2.tar",
         "https://ftp.ebi.ac.uk/pub/databases/alphafold/v2/UP000000429_85962_HELPY_v2.tar",
         "https://ftp.ebi.ac.uk/pub/databases/alphafold/v2/UP000007841_1125630_KLEPH_v2.tar",
-        "https://ftp.ebi.ac.uk/pub/databases/alphafold/v2/UP000008153_5671_LEIIN_v2.tar",
+        # "https://ftp.ebi.ac.uk/pub/databases/alphafold/v2/UP000008153_5671_LEIIN_v2.tar",
         "https://ftp.ebi.ac.uk/pub/databases/alphafold/v2/UP000078237_100816_9PEZI1_v2.tar",
         "https://ftp.ebi.ac.uk/pub/databases/alphafold/v2/UP000000806_272631_MYCLE_v2.tar",
-        "https://ftp.ebi.ac.uk/pub/databases/alphafold/v2/UP000001584_83332_MYCTU_v2.tar",
+        # "https://ftp.ebi.ac.uk/pub/databases/alphafold/v2/UP000001584_83332_MYCTU_v2.tar",
         "https://ftp.ebi.ac.uk/pub/databases/alphafold/v2/UP000020681_1299332_MYCUL_v2.tar",
         "https://ftp.ebi.ac.uk/pub/databases/alphafold/v2/UP000000535_242231_NEIG1_v2.tar",
         "https://ftp.ebi.ac.uk/pub/databases/alphafold/v2/UP000006304_1133849_9NOCA1_v2.tar",
         "https://ftp.ebi.ac.uk/pub/databases/alphafold/v2/UP000024404_6282_ONCVO_v2.tar",
         "https://ftp.ebi.ac.uk/pub/databases/alphafold/v2/UP000002059_502779_PARBA_v2.tar",
-        "https://ftp.ebi.ac.uk/pub/databases/alphafold/v2/UP000001450_36329_PLAF7_v2.tar",
+        # "https://ftp.ebi.ac.uk/pub/databases/alphafold/v2/UP000001450_36329_PLAF7_v2.tar",
         "https://ftp.ebi.ac.uk/pub/databases/alphafold/v2/UP000002438_208964_PSEAE_v2.tar",
         "https://ftp.ebi.ac.uk/pub/databases/alphafold/v2/UP000001014_99287_SALTY_v2.tar",
         "https://ftp.ebi.ac.uk/pub/databases/alphafold/v2/UP000008854_6183_SCHMA_v2.tar",
         "https://ftp.ebi.ac.uk/pub/databases/alphafold/v2/UP000002716_300267_SHIDS_v2.tar",
         "https://ftp.ebi.ac.uk/pub/databases/alphafold/v2/UP000018087_1391915_SPOS1_v2.tar",
-        "https://ftp.ebi.ac.uk/pub/databases/alphafold/v2/UP000008816_93061_STAA8_v2.tar",
+        # "https://ftp.ebi.ac.uk/pub/databases/alphafold/v2/UP000008816_93061_STAA8_v2.tar",
         "https://ftp.ebi.ac.uk/pub/databases/alphafold/v2/UP000000586_171101_STRR6_v2.tar",
         "https://ftp.ebi.ac.uk/pub/databases/alphafold/v2/UP000035681_6248_STRER_v2.tar",
         "https://ftp.ebi.ac.uk/pub/databases/alphafold/v2/UP000030665_36087_TRITR_v2.tar",
         "https://ftp.ebi.ac.uk/pub/databases/alphafold/v2/UP000008524_185431_TRYB2_v2.tar",
-        "https://ftp.ebi.ac.uk/pub/databases/alphafold/v2/UP000002296_353153_TRYCC_v2.tar",
+        # "https://ftp.ebi.ac.uk/pub/databases/alphafold/v2/UP000002296_353153_TRYCC_v2.tar",
         "https://ftp.ebi.ac.uk/pub/databases/alphafold/v2/UP000270924_6293_WUCBA_v2.tar"
     ]
     md5s = [
-        "4cd5f596ebfc3d45d9f6b647dc5684af", "9e26602ba2d9f233ef4fcf82703ddb59",
-        "60a09db1e1c47a98763d09879784f536", "a0ab562b7372f149673c4518f949501f", 
-        "6205138b14fb7e7ec09b366e3e4f294b", "31f31359cd7254f82304e3886440bdd3", 
-        "a590096e65461ed4eb092b2147b97f0b", "8f1e120f372995644a7101ad58e5b2ae", 
-        "9a659c4aed2a8b833478dcd5fffc5fd8", "95d775f2ae271cf50a101c73335cd250", 
-        "e5b12da43f5bd77298ca50e19706bdeb", "90e953abba9c8fe202e0adf825c0dfcc", 
-        "38a11553c7e2d00482281e74f7daf321", "2bcdfe2c37154a355fe4e8150c279c13", 
-        "580a55e56a44fed935f0101c37a8c4ab", "b8d08a9033d111429fadb4e25820f9f7", 
-        "59d1167f414a86cbccfb204791fea0eb", "dfde6b44026f19a88f1abc8ac2798ce6", 
-        "a1c2047a16130d61cac4db23b2f5b560", "e4d4b72df8d075aeb607dcb095210304", 
-        "5cdad48c799ffd723636cae26433f1f9", "98a7c13987f578277bfb66ac48a1e242", 
+        "4cd5f596ebfc3d45d9f6b647dc5684af", "b89bee5507f78f971417cc8fd75b40f7", "a6459a1f1a0a22fbf25f1c05c2889ae3",
+        "24dfba8ab93dbf3f51e7db6b912dd6b4", "6b81b3086ed9e57e04a54f148ecf974c", "a50f4fd9f581c89e79e1b2857e54b786",
+        "fdd16245769bf1f7d91a0e285ac00e52", "66b9750c511182bc5f8ee71fe2ab2a17", "5dadeb5aac704025cac33f7557794858",
+        "99b22e0f050d845782d914becbfe4d2f", "da938dfae4fabf6e144f4b5ede5885ec", "2003c09d437cfb4093552c588a33e06d",
+        "fba59f386cfa33af3f70ae664b7feac0", "d7a1a6c02213754ee1a1ffb3b41ad4ba", "8a0e8deadffec2aba3b7edd6534b7481",
+        "1854d0bbcf819de1de7b0cfdb6d32b2e", "d9720e3809db6916405db096b520c236", "6b918e9e4d645b12a80468bcea805f1f",
+        "ed0eefe927eb8c3b81cf87eaabbb8d6e", "051369e0dc8fed4798c8b2c68e6cbe2e", "b05ff57164167851651c625dca66ed28",
+        "68e7a6e57bd43cb52e344b3190073387", "75d027ac7833f284fda65ea620353e8a", "7d85bb2ee4130096a6d905ab8d726bcc",
+        "63498210c88e8bfb1a7346c4ddf73bb1", "5bf2211304ef91d60bb3838ec12d89cd", "4981758eb8980e9df970ac6113e4084c",
+        "322431789942595b599d2b86670f41b3", "35d7b32e37bcc23d02b12b03b1e0c093", "1b8847dd786fa41b5b38f5e7aa58b813",
+        "126bdbe59fa82d55bfa098b710bdf650", "6c6d3248ed943dd7137637fc92d7ba37", "532203c6877433df5651b95d27685825",
+        "6e7112411da5843bec576271c44e0a0a", "0e4f913a9b4672b0ad3cc9c4f2de5c8d", "a138d0060b2e8a0ef1f90cf3ab7b7ca0",
+        "04d491dd1c679e91b5a2f3b9f14db555", "889c051e39305614accdff00414bfa67", "cd87cf24e5135c9d729940194ccc65c8",
+        "75eb8bfe866cf3040f4c08a566c32bc1", "fd8e6ddb9c159aab781a11c287c85feb", "b91a2e103980b96f755712f2b559ad66",
+        "26187d09b093649686d7c158aa4fd113", "62e16894bb4b8951a82befd24ad4ee21", "85c001df1d91788bf3cc1f97230b1dac",
+        "91a25af808351757b101a8c9c787db9e", "8b3e8645cc4c2484c331759b9d1df5bc", "e8a76a6ab290e6743233510e8d1eb4a5",
+        "38280bd7804f4c060b0775c4abed9b89"
     ]
     species_nsplit = [
         2, 1, 1, 2, 1, 1, 1, 3, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 20,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
-        1, 1, 1, 1, 1, 1, 1, 1, 1, 1
+        1, 1, 1, 1, 1, #1, 1, 1, 1, 1
     ]
     split_length = 22000
 
     def __init__(self, path, species_id=0, split_id=0, verbose=1, **kwargs):
         path = os.path.expanduser(path)
         if not os.path.exists(path):
             os.makedirs(path)
         self.path = path
 
         species_name = os.path.basename(self.urls[species_id])[:-4]
         if split_id >= self.species_nsplit[species_id]:
-            raise ValueError("Split id %d should be less than %d in species %s" % 
+            raise ValueError("Split id %d should be less than %d in species %s" %
                             (split_id, self.species_nsplit[species_id], species_name))
         self.processed_file = "%s_%d.pkl.gz" % (species_name, split_id)
         pkl_file = os.path.join(path, self.processed_file)
 
         if os.path.exists(pkl_file):
             self.load_pickle(pkl_file, verbose=verbose, **kwargs)
         else:
```

## torchdrug/datasets/gene_ontology.py

```diff
@@ -9,16 +9,16 @@
 from torchdrug.core import Registry as R
 
 
 @R.register("datasets.GeneOntology")
 @utils.copy_args(data.ProteinDataset.load_pdbs)
 class GeneOntology(data.ProteinDataset):
     """
-    A set of proteins with their 3D structures and GO terms. These terms classify proteins 
-    into hierarchically related functional classes organized into three ontologies: molecular 
+    A set of proteins with their 3D structures and GO terms. These terms classify proteins
+    into hierarchically related functional classes organized into three ontologies: molecular
     function (MF), biological process (BP) and cellular component (CC).
 
     Statistics (test_cutoff=0.95):
         - #Train: 27,496
         - #Valid: 3,053
         - #Test: 2,991
 
@@ -47,15 +47,15 @@
         if test_cutoff not in self.test_cutoffs:
             raise ValueError("Unknown test cutoff `%.2f` for GeneOntology dataset" % test_cutoff)
         self.test_cutoff = test_cutoff
 
         zip_file = utils.download(self.url, path, md5=self.md5)
         path = os.path.join(utils.extract(zip_file), "GeneOntology")
         pkl_file = os.path.join(path, self.processed_file)
-        
+
         csv_file = os.path.join(path, "nrPDB-GO_test.csv")
         pdb_ids = []
         with open(csv_file, "r") as fin:
             reader = csv.reader(fin, delimiter=",")
             idx = self.test_cutoffs.index(test_cutoff) + 1
             _ = next(reader)
             for line in reader:
```

## torchdrug/layers/common.py

```diff
@@ -325,18 +325,18 @@
 
 
 class SinusoidalPositionEmbedding(nn.Module):
     """
     Positional embedding based on sine and cosine functions, proposed in `Attention Is All You Need`_.
 
     .. _Attention Is All You Need:
-        https://arxiv.org/pdf/1706.03762.pdf
+       https://arxiv.org/pdf/1706.03762.pdf
 
     Parameters:
-        output_dim (int): output dimension
+       output_dim (int): output dimension
     """
 
     def __init__(self, output_dim):
         super(SinusoidalPositionEmbedding, self).__init__()
         inverse_frequency = 1 / (10000 ** (torch.arange(0.0, output_dim, 2.0) / output_dim))
         self.register_buffer("inverse_frequency", inverse_frequency)
```

## torchdrug/layers/conv.py

 * *Ordering differences only*

```diff
@@ -806,8 +806,8 @@
             edge_input = graph.edge_feature.float()
             edge_input = self.edge_linear(edge_input)
             edge_weight = graph.edge_weight.unsqueeze(-1)
             edge_update = scatter_add(edge_input * edge_weight, node_out, dim=0,
                                       dim_size=graph.num_node * graph.num_relation)
             update += edge_update
 
-        return update.view(graph.num_node, self.num_relation * self.input_dim)
+        return update.view(graph.num_node, self.num_relation * self.input_dim)
```

## torchdrug/layers/functional/__init__.py

```diff
@@ -1,12 +1,12 @@
 from .functional import multinomial, masked_mean, mean_with_nan, shifted_softplus, multi_slice, multi_slice_mask, \
-    as_mask, _size_to_index, _extend, variadic_log_softmax, variadic_softmax, variadic_sum, variadic_mean, \
-    variadic_max, variadic_cross_entropy, variadic_sort, variadic_topk, variadic_arange, variadic_randperm, \
-    variadic_sample, variadic_meshgrid, variadic_to_padded, padded_to_variadic, one_hot, \
-    clipped_policy_gradient_objective, policy_gradient_objective
+    as_mask, _extend, variadic_log_softmax, variadic_softmax, variadic_sum, variadic_mean, variadic_max, \
+    variadic_cross_entropy, variadic_sort, variadic_topk, variadic_arange, variadic_randperm, variadic_sample,\
+    variadic_meshgrid, variadic_to_padded, padded_to_variadic, one_hot, clipped_policy_gradient_objective, \
+    policy_gradient_objective
 from .embedding import transe_score, distmult_score, complex_score, simple_score, rotate_score
 from .spmm import generalized_spmm, generalized_rspmm
 
 __all__ = [
     "multinomial", "masked_mean", "mean_with_nan", "shifted_softplus", "multi_slice_mask", "as_mask",
     "variadic_log_softmax", "variadic_softmax", "variadic_sum", "variadic_mean", "variadic_max",
     "variadic_cross_entropy", "variadic_sort", "variadic_topk", "variadic_arange", "variadic_randperm",
```

## torchdrug/layers/functional/functional.py

```diff
@@ -74,15 +74,15 @@
         ends (LongTensor): end indexes of slices
     """
     values = torch.cat([torch.ones_like(starts), -torch.ones_like(ends)])
     slices = torch.cat([starts, ends])
     slices, order = slices.sort()
     values = values[order]
     depth = values.cumsum(0)
-    valid = (values == 1 & depth == 0) | (values == -1 & depth == 1)
+    valid = ((values == 1) & (depth == 1)) | ((values == -1) & (depth == 0))
     slices = slices[valid]
 
     starts, ends = slices.view(-1, 2).t()
     size = ends - starts
     indexes = variadic_arange(size)
     indexes = indexes + starts.repeat_interleave(size)
     return indexes
@@ -120,31 +120,14 @@
         length (int): maximal possible value of indexes
     """
     mask = torch.zeros(length, dtype=torch.bool, device=indexes.device)
     mask[indexes] = 1
     return mask
 
 
-def _size_to_index(size):
-    """
-    Convert sizes to variadic indexes.
-
-    Example::
-
-        >>> index = _size_to_index(torch.tensor([3, 2, 1]))
-        >>> assert (index == torch.tensor([0, 0, 0, 1, 1, 2])).all()
-
-    Parameters:
-        size (LongTensor): size of each sample
-    """
-    range = torch.arange(len(size), device=size.device)
-    index2sample = range.repeat_interleave(size)
-    return index2sample
-
-
 def _extend(data, size, input, input_size):
     """
     Extend variadic-sized data with variadic-sized input.
     This is a variadic variant of ``torch.cat([data, input], dim=-1)``.
 
     Example::
 
@@ -182,15 +165,15 @@
 
     Suppose there are :math:`N` sets, and the sizes of all sets are summed to :math:`B`.
 
     Parameters:
         input (Tensor): input of shape :math:`(B, ...)`
         size (LongTensor): size of sets of shape :math:`(N,)`
     """
-    index2sample = _size_to_index(size)
+    index2sample = torch.repeat_interleave(size)
     index2sample = index2sample.view([-1] + [1] * (input.ndim - 1))
     index2sample = index2sample.expand_as(input)
 
     value = scatter_add(input, index2sample, dim=0)
     return value
 
 
@@ -200,15 +183,15 @@
 
     Suppose there are :math:`N` sets, and the sizes of all sets are summed to :math:`B`.
 
     Parameters:
         input (Tensor): input of shape :math:`(B, ...)`
         size (LongTensor): size of sets of shape :math:`(N,)`
     """
-    index2sample = _size_to_index(size)
+    index2sample = torch.repeat_interleave(size)
     index2sample = index2sample.view([-1] + [1] * (input.ndim - 1))
     index2sample = index2sample.expand_as(input)
 
     value = scatter_mean(input, index2sample, dim=0)
     return value
 
 
@@ -221,15 +204,15 @@
     Parameters:
         input (Tensor): input of shape :math:`(B, ...)`
         size (LongTensor): size of sets of shape :math:`(N,)`
 
     Returns
         (Tensor, LongTensor): max values and indexes
     """
-    index2sample = _size_to_index(size)
+    index2sample = torch.repeat_interleave(size)
     index2sample = index2sample.view([-1] + [1] * (input.ndim - 1))
     index2sample = index2sample.expand_as(input)
 
     value, index = scatter_max(input, index2sample, dim=0)
     index = index + (size - size.cumsum(0)).view([-1] + [1] * (index.ndim - 1))
     return value, index
 
@@ -240,15 +223,15 @@
 
     Suppose there are :math:`N` samples, and the numbers of categories in all samples are summed to :math:`B`.
 
     Parameters:
         input (Tensor): input of shape :math:`(B, ...)`
         size (LongTensor): number of categories of shape :math:`(N,)`
     """
-    index2sample = _size_to_index(size)
+    index2sample = torch.repeat_interleave(size)
     index2sample = index2sample.view([-1] + [1] * (input.ndim - 1))
     index2sample = index2sample.expand_as(input)
 
     log_likelihood = scatter_log_softmax(input, index2sample, dim=0)
     return log_likelihood
 
 
@@ -258,15 +241,15 @@
 
     Suppose there are :math:`N` samples, and the numbers of categories in all samples are summed to :math:`B`.
 
     Parameters:
         input (Tensor): input of shape :math:`(B, ...)`
         size (LongTensor): number of categories of shape :math:`(N,)`
     """
-    index2sample = _size_to_index(size)
+    index2sample = torch.repeat_interleave(size)
     index2sample = index2sample.view([-1] + [1] * (input.ndim - 1))
     index2sample = index2sample.expand_as(input)
 
     log_likelihood = scatter_softmax(input, index2sample, dim=0)
     return log_likelihood
 
 
@@ -279,15 +262,15 @@
     Parameters:
         input (Tensor): prediction of shape :math:`(B, ...)`
         target (Tensor): target of shape :math:`(N, ...)`. Each target is a relative index in a sample.
         size (LongTensor): number of categories of shape :math:`(N,)`
         reduction (string, optional): reduction to apply to the output.
             Available reductions are ``none``, ``sum`` and ``mean``.
     """
-    index2sample = _size_to_index(size)
+    index2sample = torch.repeat_interleave(size)
     index2sample = index2sample.view([-1] + [1] * (input.ndim - 1))
     index2sample = index2sample.expand_as(input)
 
     log_likelihood = scatter_log_softmax(input, index2sample, dim=0)
     size = size.view([-1] + [1] * (input.ndim - 1))
     assert (target >= 0).all() and (target < size).all()
     target_index = target + size.cumsum(0) - size
@@ -317,15 +300,15 @@
         k (int or LongTensor): the k in "top-k". Can be a fixed value for all sets,
             or different values for different sets of shape :math:`(N,)`.
         largest (bool, optional): return largest or smallest elements
 
     Returns
         (Tensor, LongTensor): top-k values and indexes
     """
-    index2graph = _size_to_index(size)
+    index2graph = torch.repeat_interleave(size)
     index2graph = index2graph.view([-1] + [1] * (input.ndim - 1))
 
     mask = ~torch.isinf(input)
     max = input[mask].max().item()
     min = input[mask].min().item()
     abs_max = input[mask].abs().max().item()
     # special case: max = min
@@ -344,15 +327,15 @@
     starts = size.cumsum(0) - size
     ends = starts + num_actual
     mask = multi_slice_mask(starts, ends, len(index_ext)).nonzero().flatten()
 
     if (num_padding > 0).any():
         # special case: size < k, pad with the last valid index
         padding = ends - 1
-        padding2graph = _size_to_index(num_padding)
+        padding2graph = torch.repeat_interleave(num_padding)
         mask = _extend(mask, num_actual, padding[padding2graph], num_padding)[0]
 
     index = index_ext[mask] # (N * k, ...)
     value = input.gather(0, index)
     if isinstance(k, torch.Tensor) and k.shape == size.shape:
         value = value.view(-1, *input.shape[1:])
         index = index.view(-1, *input.shape[1:])
@@ -375,15 +358,15 @@
         input (Tensor): input of shape :math:`(B, ...)`
         size (LongTensor): size of sets of shape :math:`(N,)`
         descending (bool, optional): return ascending or descending order
     
     Returns
         (Tensor, LongTensor): sorted values and indexes
     """
-    index2sample = _size_to_index(size)
+    index2sample = torch.repeat_interleave(size)
     index2sample = index2sample.view([-1] + [1] * (input.ndim - 1))
 
     mask = ~torch.isinf(input)
     max = input[mask].max().item()
     min = input[mask].min().item()
     abs_max = input[mask].abs().max().item()
     # special case: max = min
@@ -467,15 +450,15 @@
         (Tensor, Tensor): the first and the second elements in the Cartesian product
     """
     grid_size = size1 * size2
     local_index = variadic_arange(grid_size)
     local_inner_size = size2.repeat_interleave(grid_size)
     offset1 = (size1.cumsum(0) - size1).repeat_interleave(grid_size)
     offset2 = (size2.cumsum(0) - size2).repeat_interleave(grid_size)
-    index1 = local_index // local_inner_size + offset1
+    index1 = torch.div(local_index, local_inner_size, rounding_mode="floor") + offset1
     index2 = local_index % local_inner_size + offset2
     return input1[index1], input2[index2]
 
 
 def variadic_to_padded(input, size, value=0):
     """
     Convert a variadic tensor to a padded tensor.
```

## torchdrug/layers/geometry/function.py

```diff
@@ -34,15 +34,15 @@
     Parameters:
         k (int, optional): number of neighbors
         min_distance (int, optional): minimum distance between the residues of two nodes
     """
 
     eps = 1e-10
 
-    def __init__(self, k=10, min_distance=5, max_distance=0):
+    def __init__(self, k=10, min_distance=5, max_distance=None):
         super(KNNEdge, self).__init__()
         self.k = k
         self.min_distance = min_distance
         self.max_distance = max_distance
 
     def forward(self, graph):
         """
@@ -59,15 +59,15 @@
         edge_list = torch.cat([edge_list, relation], dim=-1)
 
         if self.min_distance > 0:
             node_in, node_out = edge_list.t()[:2]
             mask = (graph.atom2residue[node_in] - graph.atom2residue[node_out]).abs() < self.min_distance
             edge_list = edge_list[~mask]
 
-        if self.max_distance > 0:
+        if self.max_distance:
             node_in, node_out = edge_list.t()[:2]
             mask = (graph.atom2residue[node_in] - graph.atom2residue[node_out]).abs() > self.max_distance
             edge_list = edge_list[~mask]
 
         node_in, node_out = edge_list.t()[:2]
         mask = (graph.node_position[node_in] - graph.node_position[node_out]).norm(dim=-1) < self.eps
         edge_list = edge_list[~mask]
@@ -83,18 +83,19 @@
     Parameters:
         radius (float, optional): spatial radius
         min_distance (int, optional): minimum distance between the residues of two nodes
     """
 
     eps = 1e-10
 
-    def __init__(self, radius=5, min_distance=5, max_num_neighbors=32):
+    def __init__(self, radius=5, min_distance=5, max_distance=None, max_num_neighbors=32):
         super(SpatialEdge, self).__init__()
         self.radius = radius
         self.min_distance = min_distance
+        self.max_distance = max_distance
         self.max_num_neighbors = max_num_neighbors
 
     def forward(self, graph):
         """
         Return spatial radius edges constructed based on the input graph.
 
         Parameters:
@@ -108,14 +109,19 @@
         edge_list = torch.cat([edge_list, relation], dim=-1)
 
         if self.min_distance > 0:
             node_in, node_out = edge_list.t()[:2]
             mask = (graph.atom2residue[node_in] - graph.atom2residue[node_out]).abs() < self.min_distance
             edge_list = edge_list[~mask]
 
+        if self.max_distance:
+            node_in, node_out = edge_list.t()[:2]
+            mask = (graph.atom2residue[node_in] - graph.atom2residue[node_out]).abs() > self.max_distance
+            edge_list = edge_list[~mask]
+        
         node_in, node_out = edge_list.t()[:2]
         mask = (graph.node_position[node_in] - graph.node_position[node_out]).norm(dim=-1) < self.eps
         edge_list = edge_list[~mask]
 
         return edge_list, 1
 
 
@@ -124,44 +130,55 @@
     """
     Construct edges between atoms within close residues.
 
     Parameters:
         max_distance (int, optional): maximum distance between two residues in the sequence
     """
 
-    def __init__(self, max_distance=2):
+    def __init__(self, max_distance=2, only_backbone=False):
         super(SequentialEdge, self).__init__()
         self.max_distance = max_distance
+        self.only_backbone = only_backbone
 
     def forward(self, graph):
         """
         Return sequential edges constructed based on the input graph.
         Edge types are defined by the relative distance between two residues in the sequence
 
         Parameters:
             graph (Graph): :math:`n` graph(s)
 
         Returns:
             (Tensor, int): edge list of shape :math:`(|E|, 3)`, number of relations
         """
-        residue2num_atom = graph.atom2residue.bincount(minlength=graph.num_residue)
+        if self.only_backbone:
+            is_backbone = (graph.atom_name == graph.atom_name2id["CA"]) \
+                        | (graph.atom_name == graph.atom_name2id["C"]) \
+                        | (graph.atom_name == graph.atom_name2id["N"])
+            atom2residue = graph.atom2residue[is_backbone]
+        else:
+            atom2residue = graph.atom2residue
+        residue2num_atom = atom2residue.bincount(minlength=graph.num_residue)
         edge_list = []
         for i in range(-self.max_distance, self.max_distance + 1):
             node_index = torch.arange(graph.num_node, device=graph.device)
             residue_index = torch.arange(graph.num_residue, device=graph.device)
             if i > 0:
                 is_node_in = graph.atom2residue < graph.num_cum_residues[graph.atom2graph] - i
                 is_node_out = graph.atom2residue >= (graph.num_cum_residues - graph.num_residues)[graph.atom2graph] + i
                 is_residue_in = residue_index < graph.num_cum_residues[graph.residue2graph] - i
                 is_residue_out = residue_index >= (graph.num_cum_residues - graph.num_residues)[graph.residue2graph] + i
             else:
                 is_node_in = graph.atom2residue >= (graph.num_cum_residues - graph.num_residues)[graph.atom2graph] - i
                 is_node_out = graph.atom2residue < graph.num_cum_residues[graph.atom2graph] + i
                 is_residue_in = residue_index >= (graph.num_cum_residues - graph.num_residues)[graph.residue2graph] - i
                 is_residue_out = residue_index < graph.num_cum_residues[graph.residue2graph] + i
+            if self.only_backbone:    
+                is_node_in = is_node_in & is_backbone
+                is_node_out = is_node_out & is_backbone
             node_in = node_index[is_node_in]
             node_out = node_index[is_node_out]
             # group atoms by residue ids
             node_in = node_in[graph.atom2residue[node_in].argsort()]
             node_out = node_out[graph.atom2residue[node_out].argsort()]
             num_node_in = residue2num_atom[is_residue_in]
             num_node_out = residue2num_atom[is_residue_out]
@@ -236,15 +253,15 @@
         Return a graph with some edges masked out.
 
         Parameters:
             graph (Graph): :math:`n` graph(s)
         """
         num_samples = (graph.num_edges * self.mask_rate).long().clamp(min=1)
         num_sample = num_samples.sum()
-        sample2graph = functional._size_to_index(num_samples)
+        sample2graph = torch.repeat_interleave(num_samples)
         edge_index = (torch.rand(num_sample, device=graph.device) * graph.num_edges[sample2graph]).long()
         edge_index = edge_index + (graph.num_cum_edges - graph.num_edges)[sample2graph]
         edge_mask = ~functional.as_mask(edge_index, graph.num_edge)
 
         return graph.edge_mask(edge_mask)
 
 
@@ -271,16 +288,15 @@
         """
         starts = (torch.rand(graph.batch_size, device=graph.device) *
                   (graph.num_residues - self.max_length).clamp(min=0)).long()
         ends = torch.min(starts + self.max_length, graph.num_residues)
         starts = starts + graph.num_cum_residues - graph.num_residues
         ends = ends + graph.num_cum_residues - graph.num_residues
 
-        node_mask = functional.multi_slice_mask(starts, ends, graph.num_residue)
-        residue_mask = node_mask[graph.atom2residue]
+        residue_mask = functional.multi_slice_mask(starts, ends, graph.num_residue)
         graph = graph.subresidue(residue_mask)
 
         return graph
 
 
 @R.register("layers.geometry.SubspaceNode")
 class SubspaceNode(nn.Module, core.Configurable):
```

## torchdrug/layers/geometry/graph.py

```diff
@@ -22,14 +22,24 @@
             Available features are ``residue_type``, ``gearnet``.
 
             1. For ``residue_type``, the feature of the edge :math:`e_{ij}` between residue :math:`i` and residue
                 :math:`j` is the concatenation ``[residue_type(i), residue_type(j)]``.
             2. For ``gearnet``, the feature of the edge :math:`e_{ij}` between residue :math:`i` and residue :math:`j`
                 is the concatenation ``[residue_type(i), residue_type(j), edge_type(e_ij),
                 sequential_distance(i,j), spatial_distance(i,j)]``.
+
+    .. note::
+        You may customize your own edge features by inheriting this class and define a member function
+        for your features. Use ``edge_feature="my_feature"`` to call the following feature function.
+
+        .. code:: python
+
+            def edge_my_feature(self, graph, edge_list, num_relation):
+                ...
+                return feature # the first dimension must be ``graph.num_edge``
     """
 
     max_seq_dist = 10
 
     def __init__(self, node_layers=None, edge_layers=None, edge_feature="residue_type"):
         super(GraphConstruction, self).__init__()
         if node_layers is None:
@@ -39,15 +49,15 @@
         if edge_layers is None:
             edge_layers = nn.ModuleList()
         else:
             edge_layers = nn.ModuleList(edge_layers)
         self.edge_layers = edge_layers
         self.edge_feature = edge_feature
 
-    def edge_residue_type(self, graph, edge_list):
+    def edge_residue_type(self, graph, edge_list, num_relation):
         node_in, node_out, _ = edge_list.t()
         residue_in, residue_out = graph.atom2residue[node_in], graph.atom2residue[node_out]
         in_residue_type = graph.residue_type[residue_in]
         out_residue_type = graph.residue_type[residue_out]
 
         return torch.cat([
             functional.one_hot(in_residue_type, len(data.Protein.residue2id)),
@@ -99,21 +109,23 @@
         node_in = edge_list[:, 0]
         edge2graph = graph.node2graph[node_in]
         order = edge2graph.argsort()
         edge_list = edge_list[order]
         num_edges = edge2graph.bincount(minlength=graph.batch_size)
         offsets = (graph.num_cum_nodes - graph.num_nodes).repeat_interleave(num_edges)
 
-        if self.edge_feature == "residue_type":
-            edge_feature = self.edge_residue_type(graph, edge_list)
-        elif self.edge_feature == "gearnet":
-            edge_feature = self.edge_gearnet(graph, edge_list, num_relation)
+        if hasattr(self, "edge_%s" % self.edge_feature):
+            edge_feature = getattr(self, "edge_%s" % self.edge_feature)(graph, edge_list, num_relation)
+        elif self.edge_feature is None:
+            edge_feature = None
         else:
             raise ValueError("Unknown edge feature `%s`" % self.edge_feature)
-        data_dict, meta_dict = graph.data_by_meta(include=("node", "residue", "node reference", "residue reference"))
+        data_dict, meta_dict = graph.data_by_meta(include=(
+            "node", "residue", "node reference", "residue reference", "graph"
+        ))
 
         if isinstance(graph, data.PackedProtein):
             data_dict["num_residues"] = graph.num_residues
         if isinstance(graph, data.PackedMolecule):
             data_dict["bond_type"] = torch.zeros_like(edge_list[:, 2])
         return type(graph)(edge_list, num_nodes=graph.num_nodes, num_edges=num_edges, num_relation=num_relation,
                            view=graph.view, offsets=offsets, edge_feature=edge_feature,
@@ -170,13 +182,13 @@
         node_j = node_in[edge_out]
         node_k = node_in[edge_in]
         vector1 = graph.node_position[node_i] - graph.node_position[node_j]
         vector2 = graph.node_position[node_k] - graph.node_position[node_j]
         x = (vector1 * vector2).sum(dim=-1)
         y = torch.cross(vector1, vector2).norm(dim=-1)
         angle = torch.atan2(y, x)
-        relation = (angle / math.pi * self.num_angle_bin).long()
+        relation = (angle / math.pi * self.num_angle_bin).long().clamp(max=self.num_angle_bin - 1)
         edge_list = torch.cat([line_graph.edge_list, relation.unsqueeze(-1)], dim=-1)
 
         return type(line_graph)(edge_list, num_nodes=line_graph.num_nodes, offsets=line_graph._offsets,
                                 num_edges=line_graph.num_edges, num_relation=self.num_angle_bin,
                                 meta_dict=line_graph.meta_dict, **line_graph.data_dict)
```

## torchdrug/metrics/metric.py

```diff
@@ -185,15 +185,15 @@
     Suppose there are :math:`N` sets, and the sizes of all sets are summed to :math:`B`.
 
     Parameters:
         pred (Tensor): prediction of shape :math:`(B,)`
         target (Tensor): target of shape :math:`(B,)`.
         size (Tensor): size of sets of shape :math:`(N,)`
     """
-    index2graph = functional._size_to_index(size)
+    index2graph = torch.repeat_interleave(size)
     _, order = functional.variadic_sort(pred, size, descending=True)
     cum_size = (size.cumsum(0) - size)[index2graph]
     target = target[order + cum_size]
     total_hit = functional.variadic_sum(target, size)
     total_hit = total_hit.cumsum(0) - total_hit
     hit = target.cumsum(0) - total_hit[index2graph]
     hit = torch.where(target == 0, hit, torch.zeros_like(hit))
@@ -211,15 +211,15 @@
     Suppose there are :math:`N` sets, and the sizes of all sets are summed to :math:`B`.
 
     Parameters:
         pred (Tensor): prediction of shape :math:`(B,)`
         target (Tensor): target of shape :math:`(B,)`.
         size (Tensor): size of sets of shape :math:`(N,)`
     """
-    index2graph = functional._size_to_index(size)
+    index2graph = torch.repeat_interleave(size)
     _, order = functional.variadic_sort(pred, size, descending=True)
     cum_size = (size.cumsum(0) - size)[index2graph]
     target = target[order + cum_size]
     total_hit = functional.variadic_sum(target, size)
     total_hit = total_hit.cumsum(0) - total_hit
     hit = target.cumsum(0) - total_hit[index2graph]
     total = torch.ones_like(target).cumsum(0) - (size.cumsum(0) - size)[index2graph]
@@ -291,15 +291,15 @@
     Suppose there are :math:`N` samples, and the number of categories in all samples is summed to :math:`B`.
 
     Parameters:
         input (Tensor): prediction of shape :math:`(B,)`
         target (Tensor): target of shape :math:`(N,)`. Each target is a relative index in a sample.
         size (Tensor): number of categories of shape :math:`(N,)`
     """
-    index2graph = functional._size_to_index(size)
+    index2graph = torch.repeat_interleave(size)
 
     input_class = scatter_max(input, index2graph)[1]
     target_index = target + size.cumsum(0) - size
     accuracy = (input_class == target_index).float()
     return accuracy
```

## torchdrug/models/esm.py

```diff
@@ -26,66 +26,97 @@
     """
 
     url = {
         "ESM-1b": "https://dl.fbaipublicfiles.com/fair-esm/models/esm1b_t33_650M_UR50S.pt",
         "ESM-1v": "https://dl.fbaipublicfiles.com/fair-esm/models/esm1v_t33_650M_UR90S_1.pt",
         "ESM-1b-regression":
             "https://dl.fbaipublicfiles.com/fair-esm/regression/esm1b_t33_650M_UR50S-contact-regression.pt",
+        "ESM-2-8M": "https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t6_8M_UR50D.pt",
+        "ESM-2-35M": "https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t12_35M_UR50D.pt",
+        "ESM-2-150M": "https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t30_150M_UR50D.pt",
+        "ESM-2-650M": "https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t33_650M_UR50D.pt",
+        "ESM-2-3B": "https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t36_3B_UR50D.pt",
+        "ESM-2-15B": "https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t48_15B_UR50D.pt",
     }
 
     md5 = {
         "ESM-1b": "ba8914bc3358cae2254ebc8874ee67f6",
         "ESM-1v": "1f04c2d2636b02b544ecb5fbbef8fefd",
         "ESM-1b-regression": "e7fe626dfd516fb6824bd1d30192bdb1",
+        "ESM-2-8M": "8039fc9cee7f71cd2633b13b5a38ff50",
+        "ESM-2-35M": "a894ddb31522e511e1273abb23b5f974",
+        "ESM-2-150M": "229fcf8f9f3d4d442215662ca001b906",
+        "ESM-2-650M": "ba6d997e29db07a2ad9dca20e024b102",
+        "ESM-2-3B": "d37a0d0dbe7431e48a72072b9180b16b",
+        "ESM-2-15B": "af61a9c0b792ae50e244cde443b7f4ac",
     }
 
     output_dim = {
         "ESM-1b": 1280,
         "ESM-1v": 1280,
+        "ESM-2-8M": 320,
+        "ESM-2-35M": 480,
+        "ESM-2-150M": 640,
+        "ESM-2-650M": 1280,
+        "ESM-2-3B": 2560,
+        "ESM-2-15B": 5120,
+    }
+
+    num_layer = {
+        "ESM-1b": 33,
+        "ESM-1v": 33,
+        "ESM-2-8M": 6,
+        "ESM-2-35M": 12,
+        "ESM-2-150M": 30,
+        "ESM-2-650M": 33,
+        "ESM-2-3B": 36,
+        "ESM-2-15B": 48,
     }
 
     max_input_length = 1024 - 2
 
     def __init__(self, path, model="ESM-1b", readout="mean"):
         super(EvolutionaryScaleModeling, self).__init__()
         path = os.path.expanduser(path)
         if not os.path.exists(path):
             os.makedirs(path)
         self.path = path
 
         _model, alphabet = self.load_weight(path, model)
+        self.alphabet = alphabet
         mapping = self.construct_mapping(alphabet)
         self.output_dim = self.output_dim[model]
         self.model = _model
         self.alphabet = alphabet
+        self.repr_layer = self.num_layer[model]
         self.register_buffer("mapping", mapping)
 
         if readout == "sum":
             self.readout = layers.SumReadout("residue")
         elif readout == "mean":
             self.readout = layers.MeanReadout("residue")
         else:
             raise ValueError("Unknown readout `%s`" % readout)
 
     def load_weight(self, path, model):
         if model not in self.url:
             raise ValueError("Unknown model `%s`" % model)
         model_file = utils.download(self.url[model], path, md5=self.md5[model])
         model_data = torch.load(model_file, map_location="cpu")
-        if model != "ESM-1v":
+        if model != "ESM-1v" and not model.startswith("ESM-2"):
             regression_model = "%s-regression" % model
             regression_file = utils.download(self.url[regression_model], path, md5=self.md5[regression_model])
             regression_data = torch.load(regression_file, map_location="cpu")
         else:
             regression_data = None
         model_name = os.path.basename(self.url[model])
         return esm.pretrained.load_model_and_alphabet_core(model_name, model_data, regression_data)
 
     def construct_mapping(self, alphabet):
-        mapping = [0] * len(data.Protein.id2residue_symbol)
+        mapping = [-1] * max(len(data.Protein.id2residue_symbol), len(self.alphabet))
         for i, token in data.Protein.id2residue_symbol.items():
             mapping[i] = alphabet.get_idx(token)
         mapping = torch.tensor(mapping)
         return mapping
 
     def forward(self, graph, input, all_loss=None, metric=None):
         """
@@ -99,14 +130,15 @@
 
         Returns:
             dict with ``residue_feature`` and ``graph_feature`` fields:
                 residue representations of shape :math:`(|V_{res}|, d)`, graph representations of shape :math:`(n, d)`
         """
         input = graph.residue_type
         input = self.mapping[input]
+        input[input == -1] = graph.residue_type[input == -1]
         size = graph.num_residues
         if (size > self.max_input_length).any():
             warnings.warn("ESM can only encode proteins within %d residues. Truncate the input to fit into ESM."
                           % self.max_input_length)
             starts = size.cumsum(0) - size
             size = size.clamp(max=self.max_input_length)
             ends = starts + size
@@ -118,23 +150,23 @@
             bos = torch.ones(graph.batch_size, dtype=torch.long, device=self.device) * self.alphabet.cls_idx
             input, size_ext = functional._extend(bos, torch.ones_like(size_ext), input, size_ext)
         if self.alphabet.append_eos:
             eos = torch.ones(graph.batch_size, dtype=torch.long, device=self.device) * self.alphabet.eos_idx
             input, size_ext = functional._extend(input, size_ext, eos, torch.ones_like(size_ext))
         input = functional.variadic_to_padded(input, size_ext, value=self.alphabet.padding_idx)[0]
 
-        output = self.model(input, repr_layers=[33])
-        residue_feature = output["representations"][33]
+        output = self.model(input, repr_layers=[self.repr_layer])
+        residue_feature = output["representations"][self.repr_layer]
 
         residue_feature = functional.padded_to_variadic(residue_feature, size_ext)
         starts = size_ext.cumsum(0) - size_ext
         if self.alphabet.prepend_bos:
             starts = starts + 1
         ends = starts + size
         mask = functional.multi_slice_mask(starts, ends, len(residue_feature))
         residue_feature = residue_feature[mask]
         graph_feature = self.readout(graph, residue_feature)
 
         return {
             "graph_feature": graph_feature,
             "residue_feature": residue_feature
-        }
+        }
```

## torchdrug/models/infograph.py

```diff
@@ -129,16 +129,20 @@
         Returns:
             dict with ``node_feature1``, ``node_feature2``, ``graph_feature1`` and ``graph_feature2`` fields:
                 node representations of shape :math:`(|V|, d)`, graph representations of shape :math:`(n, d)`
                 for two augmented views respectively
         """
         # Get two augmented views
         graph = copy.copy(graph)
-        with graph.residue():
-            graph.input = input
+        if graph.view == "residue":
+            with graph.residue():
+                graph.input = input
+        else:
+            with graph.atom():
+                graph.input = input
         crop_func1, noise_func1 = random.sample(self.crop_funcs, 1)[0], random.sample(self.noise_funcs, 1)[0]
         graph1 = crop_func1(graph)
         graph1 = noise_func1(graph1)
         output1 = self.model(graph1, graph1.input)
 
         crop_func2, noise_func2 = random.sample(self.crop_funcs, 1)[0], random.sample(self.noise_funcs, 1)[0]
         graph2 = crop_func2(graph)
```

## torchdrug/models/lstm.py

```diff
@@ -1,10 +1,7 @@
-from collections.abc import Sequence
-
-import torch
 from torch import nn
 from torch.nn import functional as F
 
 from torchdrug import core
 from torchdrug.layers import functional
 from torchdrug.core import Registry as R
```

## torchdrug/models/mpnn.py

```diff
@@ -46,15 +46,15 @@
         self.concat_hidden = concat_hidden
 
         self.linear = nn.Linear(input_dim, hidden_dim)
         self.layer = layers.MessagePassing(hidden_dim, edge_input_dim, [hidden_dim] * (num_mlp_layer - 1),
                                            batch_norm, activation)
         self.gru = nn.GRU(hidden_dim, hidden_dim, num_gru_layer)
 
-        self.readout = layers.Set2Set(feature_dim, num_s2s_step)
+        self.readout = layers.Set2Set(feature_dim, num_step=num_s2s_step)
 
     def forward(self, graph, input, all_loss=None, metric=None):
         """
         Compute the node representations and the graph representation(s).
 
         Parameters:
             graph (Graph): :math:`n` graph(s)
```

## torchdrug/models/neurallp.py

```diff
@@ -98,15 +98,15 @@
         """
         assert graph.num_relation == self.num_relation
         graph = graph.undirected(add_inverse=True)
 
         h_index, t_index, r_index = self.negative_sample_to_tail(h_index, t_index, r_index)
         hr_index = h_index * graph.num_relation + r_index
         hr_index_set, hr_inverse = hr_index.unique(return_inverse=True)
-        h_index_set = hr_index_set // graph.num_relation
+        h_index_set = torch.div(hr_index_set, graph.num_relation, rounding_mode="floor")
         r_index_set = hr_index_set % graph.num_relation
 
         output = self.get_t_output(graph, h_index_set, r_index_set)
 
         score = output[t_index, hr_inverse]
         score = self.linear(score.unsqueeze(-1)).squeeze(-1)
         return score
```

## torchdrug/models/physicochemical.py

```diff
@@ -102,15 +102,15 @@
         mask_0 = functional.multi_slice_mask(starts, ends, graph.num_residue) # num_residue * nlag
 
         ends = size.cumsum(0)  # batch_size * nlag
         ends = ends.unsqueeze(-1).expand(-1, self.nlag)
         starts = ends - steps
         mask_1 = functional.multi_slice_mask(starts, ends, graph.num_residue) # num_residue * nlag
 
-        index2sample = functional._size_to_index(size)
+        index2sample = torch.repeat_interleave(size)
         numerator = torch.zeros((graph.num_residue, self.nlag, x.shape[-1]), dtype=torch.float, device=graph.device)
         if self.type == "moran":
             _numerator = (x - x_mean[index2sample]).unsqueeze(1).expand(-1, self.nlag, -1)[mask_0] * \
                          (x - x_mean[index2sample]).unsqueeze(1).expand(-1, self.nlag, -1)[mask_1]
             numerator[mask_0] = _numerator
             numerator = numerator / (steps[index2sample].unsqueeze(-1) + 1e-10)
             numerator = scatter_add(numerator, graph.residue2graph, dim=0, dim_size=graph.batch_size) # batch_size * nlag * 8
```

## torchdrug/tasks/contact_prediction.py

```diff
@@ -151,17 +151,18 @@
 
         metric = {}
         for _metric in self.metric:
             if _metric == "accuracy":
                 score = (pred > 0) == label
                 score = functional.variadic_mean(score.float(), size).mean()
             elif _metric.startswith("prec@L"):
-                l = target['size'].sqrt().long()
+                l = target["size"].sqrt().long()
                 k = int(_metric[7:]) if len(_metric) > 7 else 1
-                score = metrics.variadic_top_precision(pred, label, size, l // k).mean()
+                l = torch.div(l, k, rounding_mode="floor")
+                score = metrics.variadic_top_precision(pred, label, size, l).mean()
             elif _metric.startswith("prec@"):
                 k = int(_metric[5:])
                 k = torch.full_like(size, k)
                 score = metrics.variadic_top_precision(pred, label, size, k).mean()
             else:
                 raise ValueError("Unknown criterion `%s`" % _metric)
```

## torchdrug/tasks/pretrain.py

```diff
@@ -48,15 +48,15 @@
 
         pred = torch.einsum("bd, bd -> b", node_feature[node_in], node_feature[node_out])
         return pred
 
     def target(self, batch):
         graph = batch["graph"]
         target = torch.ones(graph.num_edge, device=self.device)
-        target[graph.num_edge // 2:] = 0
+        target[len(target) // 2:] = 0
         return target
 
     def evaluate(self, pred, target):
         metric = {}
         accuracy = ((pred > 0) == (target > 0.5)).float().mean()
 
         name = tasks._get_metric_name("acc")
@@ -120,15 +120,15 @@
         if self.graph_construction_model:
             graph = self.graph_construction_model.apply_node_layer(graph)
 
         num_nodes = graph.num_nodes if self.view in ["atom", "node"] else graph.num_residues
         num_cum_nodes = num_nodes.cumsum(0)
         num_samples = (num_nodes * self.mask_rate).long().clamp(1)
         num_sample = num_samples.sum()
-        sample2graph = functional._size_to_index(num_samples)
+        sample2graph = torch.repeat_interleave(num_samples)
         node_index = (torch.rand(num_sample, device=self.device) * num_nodes[sample2graph]).long()
         node_index = node_index + (num_cum_nodes - num_nodes)[sample2graph]
 
         if self.view == "atom":
             target = graph.atom_type[node_index]
             input = graph.node_feature.float()
             input[node_index] = 0
```

## torchdrug/tasks/property_prediction.py

```diff
@@ -24,32 +24,37 @@
         criterion (str, list or dict, optional): training criterion(s). For dict, the keys are criterions and the values
             are the corresponding weights. Available criterions are ``mse``, ``bce`` and ``ce``.
         metric (str or list of str, optional): metric(s).
             Available metrics are ``mae``, ``rmse``, ``auprc`` and ``auroc``.
         num_mlp_layer (int, optional): number of layers in mlp prediction head
         normalization (bool, optional): whether to normalize the target
         num_class (int, optional): number of classes
+        mlp_batch_norm (bool, optional): apply batch normalization in mlp or not
+        mlp_dropout (float, optional): dropout in mlp
         graph_construction_model (nn.Module, optional): graph construction model
         verbose (int, optional): output verbose level
     """
 
     eps = 1e-10
     _option_members = {"task", "criterion", "metric"}
 
     def __init__(self, model, task=(), criterion="mse", metric=("mae", "rmse"), num_mlp_layer=1,
-                 normalization=True, num_class=None, graph_construction_model=None, verbose=0):
+                 normalization=True, num_class=None, mlp_batch_norm=False, mlp_dropout=0,
+                 graph_construction_model=None, verbose=0):
         super(PropertyPrediction, self).__init__()
         self.model = model
         self.task = task
         self.criterion = criterion
         self.metric = metric
         self.num_mlp_layer = num_mlp_layer
         # For classification tasks, we disable normalization tricks.
         self.normalization = normalization and ("ce" not in criterion) and ("bce" not in criterion)
         self.num_class = (num_class,) if isinstance(num_class, int) else num_class
+        self.mlp_batch_norm = mlp_batch_norm
+        self.mlp_dropout = mlp_dropout
         self.graph_construction_model = graph_construction_model
         self.verbose = verbose
 
     def preprocess(self, train_set, valid_set, test_set):
         """
         Compute the mean and derivation for each task on the training set.
         """
@@ -82,15 +87,16 @@
 
         self.register_buffer("mean", torch.as_tensor(mean, dtype=torch.float))
         self.register_buffer("std", torch.as_tensor(std, dtype=torch.float))
         self.register_buffer("weight", torch.as_tensor(weight, dtype=torch.float))
         self.num_class = self.num_class or num_class
 
         hidden_dims = [self.model.output_dim] * (self.num_mlp_layer - 1)
-        self.mlp = layers.MLP(self.model.output_dim, hidden_dims + [sum(self.num_class)])
+        self.mlp = layers.MLP(self.model.output_dim, hidden_dims + [sum(self.num_class)],
+                            batch_norm=self.mlp_batch_norm, dropout=self.mlp_dropout)
 
     def forward(self, batch):
         """"""
         all_loss = torch.tensor(0, dtype=torch.float32, device=self.device)
         metric = {}
 
         pred = self.predict(batch, all_loss, metric)
@@ -203,15 +209,15 @@
             elif _metric == "pearsonr":
                 score = []
                 for _pred, _target, _labeled in zip(pred.t(), target.t(), labeled.t()):
                     _score = metrics.pearsonr(_pred[_labeled], _target[_labeled])
                     score.append(_score)
                 score = torch.stack(score)
             else:
-                raise ValueError("Unknown criterion `%s`" % _metric)
+                raise ValueError("Unknown metric `%s`" % _metric)
 
             name = tasks._get_metric_name(_metric)
             for t, s in zip(self.task, score):
                 metric["%s [%s]" % (name, t)] = s
 
         return metric
```

## torchdrug/tasks/reasoning.py

```diff
@@ -12,44 +12,47 @@
 class KnowledgeGraphCompletion(tasks.Task, core.Configurable):
     """
     Knowledge graph completion task.
 
     This class provides routines for the family of knowledge graph embedding models.
 
     Parameters:
-        model (nn.Module): knowledge graph embedding model
+        model (nn.Module): knowledge graph completion model
         criterion (str, list or dict, optional): training criterion(s). For dict, the keys are criterions and the values
             are the corresponding weights. Available criterions are ``bce``, ``ce`` and ``ranking``.
         metric (str or list of str, optional): metric(s). Available metrics are ``mr``, ``mrr`` and ``hits@K``.
         num_negative (int, optional): number of negative samples per positive sample
         margin (float, optional): margin in ranking criterion
         adversarial_temperature (float, optional): temperature for self-adversarial negative sampling.
             Set ``0`` to disable self-adversarial negative sampling.
         strict_negative (bool, optional): use strict negative sampling or not
-        filtered_ranking (bool, optional): use filtered or unfiltered ranking for evaluation
         fact_ratio (float, optional): split the training set into facts and labels.
             Set ``None`` to use the whole training set as both facts and labels.
         sample_weight (bool, optional): whether to down-weight triplets from entities of large degrees
+        filtered_ranking (bool, optional): use filtered or unfiltered ranking for evaluation
+        full_batch_eval (bool, optional): whether to feed test negative samples by full batch or mini batch.
+            Full batch speeds up evaluation significantly, but may cause OOM problems for some models and datasets.
     """
     _option_members = {"criterion", "metric"}
 
     def __init__(self, model, criterion="bce", metric=("mr", "mrr", "hits@1", "hits@3", "hits@10"),
-                 num_negative=128, margin=6, adversarial_temperature=0, strict_negative=True, filtered_ranking=True,
-                 fact_ratio=None, sample_weight=True):
+                 num_negative=128, margin=6, adversarial_temperature=0, strict_negative=True, fact_ratio=None,
+                 sample_weight=True, filtered_ranking=True, full_batch_eval=False):
         super(KnowledgeGraphCompletion, self).__init__()
         self.model = model
         self.criterion = criterion
         self.metric = metric
         self.num_negative = num_negative
         self.margin = margin
         self.adversarial_temperature = adversarial_temperature
         self.strict_negative = strict_negative
-        self.filtered_ranking = filtered_ranking
         self.fact_ratio = fact_ratio
         self.sample_weight = sample_weight
+        self.filtered_ranking = filtered_ranking
+        self.full_batch_eval = full_batch_eval
 
     def preprocess(self, train_set, valid_set, test_set):
         if isinstance(train_set, torch_data.Subset):
             dataset = train_set.dataset
         else:
             dataset = train_set
         self.num_entity = dataset.num_entity
@@ -127,21 +130,22 @@
         batch_size = len(batch)
 
         if all_loss is None:
             # test
             all_index = torch.arange(self.num_entity, device=self.device)
             t_preds = []
             h_preds = []
-            for neg_index in all_index.split(self.num_negative):
+            num_negative = self.num_entity if self.full_batch_eval else self.num_negative
+            for neg_index in all_index.split(num_negative):
                 r_index = pos_r_index.unsqueeze(-1).expand(-1, len(neg_index))
                 h_index, t_index = torch.meshgrid(pos_h_index, neg_index)
                 t_pred = self.model(self.fact_graph, h_index, t_index, r_index, all_loss=all_loss, metric=metric)
                 t_preds.append(t_pred)
             t_pred = torch.cat(t_preds, dim=-1)
-            for neg_index in all_index.split(self.num_negative):
+            for neg_index in all_index.split(num_negative):
                 r_index = pos_r_index.unsqueeze(-1).expand(-1, len(neg_index))
                 t_index, h_index = torch.meshgrid(pos_t_index, neg_index)
                 h_pred = self.model(self.fact_graph, h_index, t_index, r_index, all_loss=all_loss, metric=metric)
                 h_preds.append(h_pred)
             h_pred = torch.cat(h_preds, dim=-1)
             pred = torch.stack([t_pred, h_pred], dim=1)
             # in case of GPU OOM
@@ -166,22 +170,22 @@
         batch_size = len(batch)
         pos_h_index, pos_t_index, pos_r_index = batch.t()
         any = -torch.ones_like(pos_h_index)
 
         pattern = torch.stack([pos_h_index, any, pos_r_index], dim=-1)
         edge_index, num_t_truth = self.graph.match(pattern)
         t_truth_index = self.graph.edge_list[edge_index, 1]
-        pos_index = functional._size_to_index(num_t_truth)
+        pos_index = torch.repeat_interleave(num_t_truth)
         t_mask = torch.ones(batch_size, self.num_entity, dtype=torch.bool, device=self.device)
         t_mask[pos_index, t_truth_index] = 0
 
         pattern = torch.stack([any, pos_t_index, pos_r_index], dim=-1)
         edge_index, num_h_truth = self.graph.match(pattern)
         h_truth_index = self.graph.edge_list[edge_index, 0]
-        pos_index = functional._size_to_index(num_h_truth)
+        pos_index = torch.repeat_interleave(num_h_truth)
         h_mask = torch.ones(batch_size, self.num_entity, dtype=torch.bool, device=self.device)
         h_mask[pos_index, h_truth_index] = 0
 
         mask = torch.stack([t_mask, h_mask], dim=1)
         target = torch.stack([pos_t_index, pos_h_index], dim=1)
 
         # in case of GPU OOM
@@ -222,26 +226,26 @@
         batch_size = len(pos_h_index)
         any = -torch.ones_like(pos_h_index)
 
         pattern = torch.stack([pos_h_index, any, pos_r_index], dim=-1)
         pattern = pattern[:batch_size // 2]
         edge_index, num_t_truth = self.fact_graph.match(pattern)
         t_truth_index = self.fact_graph.edge_list[edge_index, 1]
-        pos_index = functional._size_to_index(num_t_truth)
+        pos_index = torch.repeat_interleave(num_t_truth)
         t_mask = torch.ones(len(pattern), self.num_entity, dtype=torch.bool, device=self.device)
         t_mask[pos_index, t_truth_index] = 0
         neg_t_candidate = t_mask.nonzero()[:, 1]
         num_t_candidate = t_mask.sum(dim=-1)
         neg_t_index = functional.variadic_sample(neg_t_candidate, num_t_candidate, self.num_negative)
 
         pattern = torch.stack([any, pos_t_index, pos_r_index], dim=-1)
         pattern = pattern[batch_size // 2:]
         edge_index, num_h_truth = self.fact_graph.match(pattern)
         h_truth_index = self.fact_graph.edge_list[edge_index, 0]
-        pos_index = functional._size_to_index(num_h_truth)
+        pos_index = torch.repeat_interleave(num_h_truth)
         h_mask = torch.ones(len(pattern), self.num_entity, dtype=torch.bool, device=self.device)
         h_mask[pos_index, h_truth_index] = 0
         neg_h_candidate = h_mask.nonzero()[:, 1]
         num_h_candidate = h_mask.sum(dim=-1)
         neg_h_index = functional.variadic_sample(neg_h_candidate, num_h_candidate, self.num_negative)
 
         neg_index = torch.cat([neg_t_index, neg_h_index])
```

## torchdrug/tasks/retrosynthesis.py

```diff
@@ -723,15 +723,15 @@
         node_feature = torch.cat(node_feature, dim=-1)
 
         new_node_feature = self.new_atom_feature.weight.repeat(len(graph), 1)
         new_graph_feature = graph_feature.unsqueeze(1).repeat(1, self.num_atom_type, 1).flatten(0, 1)
         new_node_feature = torch.cat([new_node_feature, new_graph_feature], dim=-1)
         node_feature, num_nodes_ext = self._extend(node_feature, graph.num_nodes, new_node_feature)
 
-        node2graph_ext = functional._size_to_index(num_nodes_ext)
+        node2graph_ext = torch.repeat_interleave(num_nodes_ext)
         num_cum_nodes_ext = num_nodes_ext.cumsum(0)
         starts = num_cum_nodes_ext - num_nodes_ext + graph.num_nodes
         ends = num_cum_nodes_ext
         is_new_node = functional.multi_slice_mask(starts, ends, num_cum_nodes_ext[-1])
         infinity = float("inf")
 
         node_in_pred = self.node_in_mlp(node_feature).squeeze(-1)
@@ -868,15 +868,15 @@
         new_graph, feature_valid = self._update_molecule_feature(new_graph)
         return new_graph[feature_valid]
 
     @torch.no_grad()
     def predict_reactant(self, batch, num_beam=10, max_prediction=20, max_step=20):
         if "synthon" in batch:
             synthon = batch["synthon"]
-            synthon2product = functional._size_to_index(batch["num_synthon"])
+            synthon2product = torch.repeat_interleave(batch["num_synthon"])
             assert (synthon2product < len(batch["reaction"])).all()
             reaction = batch["reaction"][synthon2product]
         else:
             reactant, synthon = batch["graph"]
             reaction = batch["reaction"]
 
         # In any case, ensure that the synthon is a molecule rather than an ion
@@ -1019,15 +1019,15 @@
 
         new_node_feature = self.new_atom_feature.weight.repeat(len(graph), 1)
         new_graph_feature = graph_feature.unsqueeze(1).repeat(1, self.num_atom_type, 1).flatten(0, 1)
         new_node_feature = torch.cat([new_node_feature, new_graph_feature], dim=-1)
         node_feature, num_nodes_ext = self._extend(node_feature, graph.num_nodes, new_node_feature)
         assert (num_nodes_ext == size_ext).all()
 
-        node2graph_ext = functional._size_to_index(num_nodes_ext)
+        node2graph_ext = torch.repeat_interleave(num_nodes_ext)
         num_cum_nodes_ext = num_nodes_ext.cumsum(0)
         starts = num_cum_nodes_ext - num_nodes_ext + graph.num_nodes
         ends = num_cum_nodes_ext
         is_new_node = functional.multi_slice_mask(starts, ends, num_cum_nodes_ext[-1])
 
         node_in = node_in_target + num_cum_nodes_ext - num_nodes_ext
         node_out = node_out_target + num_cum_nodes_ext - num_nodes_ext
@@ -1089,15 +1089,15 @@
 
     def predict(self, batch, all_loss=None, metric=None):
         synthon_batch = self.center_identification.predict_synthon(batch, self.center_topk)
 
         synthon = synthon_batch["synthon"]
         num_synthon = synthon_batch["num_synthon"]
         assert (num_synthon >= 1).all() and (num_synthon <= 2).all()
-        synthon2split = functional._size_to_index(num_synthon)
+        synthon2split = torch.repeat_interleave(num_synthon)
         with synthon.graph():
             synthon.reaction_center = synthon_batch["reaction_center"][synthon2split]
             synthon.split_logp = synthon_batch["log_likelihood"][synthon2split]
 
         reactant = self.synthon_completion.predict_reactant(synthon_batch, self.num_synthon_beam, self.max_prediction)
 
         logps = []
@@ -1153,15 +1153,15 @@
         logps = logps[~is_duplicate]
         offset = torch.arange(self.max_prediction, device=self.device) * len(reactant)
         reactant_id = reactant_id + offset.view(1, -1, 1)
         reactant_id = reactant_id[~(is_padding | is_duplicate.unsqueeze(-1))]
         reactant = reactant.repeat(self.max_prediction)
         reactant = reactant[reactant_id]
         assert num_synthon.sum() == len(reactant)
-        synthon2graph = functional._size_to_index(num_synthon)
+        synthon2graph = torch.repeat_interleave(num_synthon)
         first_synthon = num_synthon.cumsum(0) - num_synthon
         # inherit graph attributes from the first synthon
         data_dict = reactant.data_mask(graph_index=first_synthon, include="graph")[0]
         # merge synthon pairs from the same split into a single graph
         reactant = reactant.merge(synthon2graph)
         with reactant.graph():
             for k, v in data_dict.items():
```

## torchdrug/tasks/task.py

```diff
@@ -1,8 +1,8 @@
-from collections import Mapping, Sequence
+from collections.abc import Mapping, Sequence
 
 from torch import nn
 
 
 class Task(nn.Module):
 
     _option_members = set()
```

## torchdrug/utils/pretty.py

```diff
@@ -1,10 +1,49 @@
+import pprint
+from itertools import islice, chain
+
+
 separator = ">" * 30
 line = "-" * 30
 
+
+class Ellipsis(object):
+
+    def __repr__(self):
+        return "..."
+
+
+ellipsis = Ellipsis()
+
+
+class PrettyPrinter(pprint.PrettyPrinter):
+
+    truncation = 10
+    display = 3
+
+    def _format_items(self, items, stream, indent, allowance, context, level):
+        if self._compact and len(items) > self.truncation:
+            items = chain(islice(items, self.display), [ellipsis], islice(items, len(items) - self.display, None))
+        super(PrettyPrinter, self)._format_items(items, stream, indent, allowance, context, level)
+
+
+def print(object, *args, **kwargs):
+    """
+    Print a python object to a stream.
+    """
+    return PrettyPrinter(*args, **kwargs).pprint(object)
+
+
+def format(object, *args, **kwargs):
+    """
+    Format a python object as a string.
+    """
+    return PrettyPrinter(*args, **kwargs).pformat(object)
+
+
 def time(seconds):
     """
     Format time as a string.
 
     Parameters:
         seconds (float): time in seconds
     """
```

## torchdrug/utils/torch.py

```diff
@@ -1,9 +1,8 @@
 import os
-from collections.abc import Mapping, Sequence
 
 import torch
 from torch.utils import cpp_extension
 
 from torchdrug import data
 from . import decorator, comm
 
@@ -63,109 +62,113 @@
             sources = new_sources
 
     return LazyExtensionLoader(name, sources, extra_cflags, extra_cuda_cflags, **kwargs)
 
 
 def cpu(obj, *args, **kwargs):
     """
-    Transfer any nested conatiner of tensors to CPU.
+    Transfer any nested container of tensors to CPU.
     """
     if hasattr(obj, "cpu"):
         return obj.cpu(*args, **kwargs)
-    elif isinstance(obj, Mapping):
+    elif isinstance(obj, (str, bytes)):
+        return obj
+    elif isinstance(obj, dict):
         return type(obj)({k: cpu(v, *args, **kwargs) for k, v in obj.items()})
-    elif isinstance(obj, Sequence):
+    elif isinstance(obj, (list, tuple)):
         return type(obj)(cpu(x, *args, **kwargs) for x in obj)
 
     raise TypeError("Can't transfer object type `%s`" % type(obj))
 
 
 def cuda(obj, *args, **kwargs):
     """
-    Transfer any nested conatiner of tensors to CUDA.
+    Transfer any nested container of tensors to CUDA.
     """
     if hasattr(obj, "cuda"):
         return obj.cuda(*args, **kwargs)
-    elif isinstance(obj, Mapping):
+    elif isinstance(obj, (str, bytes)):
+        return obj
+    elif isinstance(obj, dict):
         return type(obj)({k: cuda(v, *args, **kwargs) for k, v in obj.items()})
-    elif isinstance(obj, Sequence):
+    elif isinstance(obj, (list, tuple)):
         return type(obj)(cuda(x, *args, **kwargs) for x in obj)
 
     raise TypeError("Can't transfer object type `%s`" % type(obj))
 
 
 def detach(obj):
     """
     Detach tensors in any nested conatiner.
     """
     if hasattr(obj, "detach"):
         return obj.detach()
-    elif isinstance(obj, Mapping):
+    elif isinstance(obj, dict):
         return type(obj)({k: detach(v) for k, v in obj.items()})
-    elif isinstance(obj, Sequence):
+    elif isinstance(obj, (list, tuple)):
         return type(obj)(detach(x) for x in obj)
 
     raise TypeError("Can't perform detach over object type `%s`" % type(obj))
 
 
 def clone(obj, *args, **kwargs):
     """
     Clone tensors in any nested conatiner.
     """
     if hasattr(obj, "clone"):
         return obj.clone(*args, **kwargs)
-    elif isinstance(obj, Mapping):
+    elif isinstance(obj, dict):
         return type(obj)({k: clone(v, *args, **kwargs) for k, v in obj.items()})
-    elif isinstance(obj, Sequence):
+    elif isinstance(obj, (list, tuple)):
         return type(obj)(clone(x, *args, **kwargs) for x in obj)
 
     raise TypeError("Can't perform detach over object type `%s`" % type(obj))
 
 
 def mean(obj, *args, **kwargs):
     """
     Compute mean of tensors in any nested container.
     """
     if hasattr(obj, "mean"):
         return obj.mean(*args, **kwargs)
-    elif isinstance(obj, Mapping):
+    elif isinstance(obj, dict):
         return type(obj)({k: mean(v, *args, **kwargs) for k, v in obj.items()})
-    elif isinstance(obj, Sequence):
+    elif isinstance(obj, (list, tuple)):
         return type(obj)(mean(x, *args, **kwargs) for x in obj)
 
     raise TypeError("Can't perform mean over object type `%s`" % type(obj))
 
 
 def cat(objs, *args, **kwargs):
     """
     Concatenate a list of nested containers with the same structure.
     """
     obj = objs[0]
     if isinstance(obj, torch.Tensor):
         return torch.cat(objs, *args, **kwargs)
     elif isinstance(obj, data.PackedGraph):
         return data.cat(objs)
-    elif isinstance(obj, Mapping):
+    elif isinstance(obj, dict):
         return {k: cat([x[k] for x in objs], *args, **kwargs) for k in obj}
-    elif isinstance(obj, Sequence):
+    elif isinstance(obj, (list, tuple)):
         return type(obj)(cat(xs, *args, **kwargs) for xs in zip(*objs))
 
     raise TypeError("Can't perform concatenation over object type `%s`" % type(obj))
 
 
 def stack(objs, *args, **kwargs):
     """
     Stack a list of nested containers with the same structure.
     """
     obj = objs[0]
     if isinstance(obj, torch.Tensor):
         return torch.stack(objs, *args, **kwargs)
-    elif isinstance(obj, Mapping):
+    elif isinstance(obj, dict):
         return {k: stack([x[k] for x in objs], *args, **kwargs) for k in obj}
-    elif isinstance(obj, Sequence):
+    elif isinstance(obj, (list, tuple)):
         return type(obj)(stack(xs, *args, **kwargs) for xs in zip(*objs))
 
     raise TypeError("Can't perform stack over object type `%s`" % type(obj))
 
 
 def sparse_coo_tensor(indices, values, size):
     """
```

## Comparing `torchdrug-0.2.0.post1.dist-info/LICENSE` & `torchdrug-0.2.1.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `torchdrug-0.2.0.post1.dist-info/METADATA` & `torchdrug-0.2.1.dist-info/METADATA`

 * *Files 8% similar despite different names*

```diff
@@ -1,24 +1,24 @@
 Metadata-Version: 2.1
 Name: torchdrug
-Version: 0.2.0.post1
+Version: 0.2.1
 Summary: A powerful and flexible machine learning platform for drug discovery
 Home-page: https://torchdrug.ai/
 Author: TorchDrug Team
 License: Apache-2.0
 Keywords: deep-learning,pytorch,drug-discovery
 Classifier: Development Status :: 4 - Beta
 Classifier: Intended Audience :: Developers
 Classifier: Intended Audience :: Science/Research
 Classifier: License :: OSI Approved :: Apache Software License
 Classifier: Topic :: Scientific/Engineering :: Mathematics
 Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
 Classifier: Topic :: Software Development :: Libraries
 Classifier: Programming Language :: Python :: 3
-Requires-Python: >=3.7,<3.10
+Requires-Python: >=3.7,<3.11
 Description-Content-Type: text/markdown
 License-File: LICENSE
 Requires-Dist: torch (>=1.8.0)
 Requires-Dist: torch-scatter (>=2.0.8)
 Requires-Dist: torch-cluster (>=1.5.9)
 Requires-Dist: decorator
 Requires-Dist: numpy (>=1.11)
@@ -60,28 +60,28 @@
 
 [PyTorch]: https://pytorch.org/
 
 Installation
 ------------
 
 TorchDrug can be installed on either Linux, Windows or macOS. It is compatible with
-Python 3.7/3.8/3.9 and PyTorch >= 1.8.0.
+3.7 <= Python <= 3.10 and PyTorch >= 1.8.0.
 
 ### From Conda ###
 
 ```bash
 conda install torchdrug -c milagraph -c conda-forge -c pytorch -c pyg
 ```
 
 ### From Pip ###
 
 ```bash
-pip3 install torch==1.9.0
-pip3 install torch-scatter torch-cluster -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html
-pip3 install torchdrug
+pip install torch==1.9.0
+pip install torch-scatter torch-cluster -f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html
+pip install torchdrug
 ```
 
 To install `torch-scatter` for other PyTorch or CUDA versions, please see the
 instructions in https://github.com/rusty1s/pytorch_scatter
 
 ### From Source ###
 
@@ -107,14 +107,27 @@
 the library path according to your own case.
 
 ```powershell
 Import-VisualStudioVars -Architecture x64
 $env:LIB += ";C:\Program Files\Python37\libs"
 ```
 
+### Apple Silicon (M1/M2 Chips) ###
+
+We need PyTorch >= 1.13 to run TorchDrug on Apple silicon. For `torch-scatter` and
+`torch-cluster`, they can be compiled from their sources. Note TorchDrug doesn't
+support `mps` devices.
+
+```bash
+pip install torch==1.13.0
+pip install git+https://github.com/rusty1s/pytorch_scatter.git
+pip install git+https://github.com/rusty1s/pytorch_cluster.git
+pip install torchdrug
+```
+
 Quick Start
 -----------
 
 TorchDrug is designed for humans and focused on graph structured data.
 It enables easy implementation of graph operations in machine learning models.
 All the operations in TorchDrug are backed by [PyTorch] framework, and support GPU
 acceleration and auto differentiation.
```

### html2text {}

```diff
@@ -1,17 +1,17 @@
-Metadata-Version: 2.1 Name: torchdrug Version: 0.2.0.post1 Summary: A powerful
-and flexible machine learning platform for drug discovery Home-page: https://
+Metadata-Version: 2.1 Name: torchdrug Version: 0.2.1 Summary: A powerful and
+flexible machine learning platform for drug discovery Home-page: https://
 torchdrug.ai/ Author: TorchDrug Team License: Apache-2.0 Keywords: deep-
 learning,pytorch,drug-discovery Classifier: Development Status :: 4 - Beta
 Classifier: Intended Audience :: Developers Classifier: Intended Audience ::
 Science/Research Classifier: License :: OSI Approved :: Apache Software License
 Classifier: Topic :: Scientific/Engineering :: Mathematics Classifier: Topic ::
 Scientific/Engineering :: Artificial Intelligence Classifier: Topic :: Software
 Development :: Libraries Classifier: Programming Language :: Python :: 3
-Requires-Python: >=3.7,<3.10 Description-Content-Type: text/markdown License-
+Requires-Python: >=3.7,<3.11 Description-Content-Type: text/markdown License-
 File: LICENSE Requires-Dist: torch (>=1.8.0) Requires-Dist: torch-scatter
 (>=2.0.8) Requires-Dist: torch-cluster (>=1.5.9) Requires-Dist: decorator
 Requires-Dist: numpy (>=1.11) Requires-Dist: rdkit-pypi (>=2020.9) Requires-
 Dist: matplotlib Requires-Dist: tqdm Requires-Dist: networkx Requires-Dist:
 ninja Requires-Dist: jinja2 Requires-Dist: lmdb Requires-Dist: fair-esm [!
 [TorchDrug](asset/torchdrug_logo_full.svg)](https://torchdrug.ai/)
                        ****** with [TorchProtein] ******
@@ -33,45 +33,50 @@
 [Benchmarks]: https://deepgraphlearning.github.io/torchdrug-site/docs/benchmark
 [Papers Implemented]: https://deepgraphlearning.github.io/torchdrug-site/docs/
 paper TorchDrug is a [PyTorch]-based machine learning toolbox designed for
 several purposes. - Easy implementation of graph operations in a PyTorchic
 style with GPU support - Being friendly to practitioners with minimal knowledge
 about drug discovery - Rapid prototyping of machine learning research
 [PyTorch]: https://pytorch.org/ Installation ------------ TorchDrug can be
-installed on either Linux, Windows or macOS. It is compatible with Python 3.7/
-3.8/3.9 and PyTorch >= 1.8.0. ### From Conda ### ```bash conda install
+installed on either Linux, Windows or macOS. It is compatible with 3.7 <=
+Python <= 3.10 and PyTorch >= 1.8.0. ### From Conda ### ```bash conda install
 torchdrug -c milagraph -c conda-forge -c pytorch -c pyg ``` ### From Pip ###
-```bash pip3 install torch==1.9.0 pip3 install torch-scatter torch-cluster -
-f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html pip3 install
+```bash pip install torch==1.9.0 pip install torch-scatter torch-cluster -
+f https://pytorch-geometric.com/whl/torch-1.9.0+cu102.html pip install
 torchdrug ``` To install `torch-scatter` for other PyTorch or CUDA versions,
 please see the instructions in https://github.com/rusty1s/pytorch_scatter ###
 From Source ### ```bash git clone https://github.com/DeepGraphLearning/
 torchdrug cd torchdrug pip install -r requirements.txt python setup.py install
 ``` ### Windows (PowerShell) ### We need to first install the build tools for
 Visual Studio. We then install the following modules in PowerShell.
 ```powershell Install-Module Pscx -AllowClobber Install-Module VSSetup ```
 Initialize Visual Studio in PowerShell with the following commands. We may
 setup this for all PowerShell sessions by writing it to the PowerShell profile.
 Change the library path according to your own case. ```powershell Import-
 VisualStudioVars -Architecture x64 $env:LIB += ";C:\Program
-Files\Python37\libs" ``` Quick Start ----------- TorchDrug is designed for
-humans and focused on graph structured data. It enables easy implementation of
-graph operations in machine learning models. All the operations in TorchDrug
-are backed by [PyTorch] framework, and support GPU acceleration and auto
-differentiation. ```python from torchdrug import data edge_list = [[0, 1], [1,
-2], [2, 3], [3, 4], [4, 5], [5, 0]] graph = data.Graph(edge_list, num_node=6)
-graph = graph.cuda() # the subgraph induced by nodes 2, 3 & 4 subgraph =
-graph.subgraph([2, 3, 4]) ``` Molecules are also supported in TorchDrug. You
-can get the desired molecule properties without any domain knowledge. ```python
-mol = data.Molecule.from_smiles("CCOC(=O)N", atom_feature="default",
-bond_feature="default") print(mol.node_feature) print(mol.atom_type) print
-(mol.to_scaffold()) ``` You may also register custom node, edge or graph
-attributes. They will be automatically processed during indexing operations.
-```python with mol.edge(): mol.is_CC_bond = (mol.edge_list[:, :2] ==
-td.CARBON).all(dim=-1) sub_mol = mol.subgraph(mol.atom_type != td.NITROGEN)
+Files\Python37\libs" ``` ### Apple Silicon (M1/M2 Chips) ### We need PyTorch >=
+1.13 to run TorchDrug on Apple silicon. For `torch-scatter` and `torch-
+cluster`, they can be compiled from their sources. Note TorchDrug doesn't
+support `mps` devices. ```bash pip install torch==1.13.0 pip install git+https:
+//github.com/rusty1s/pytorch_scatter.git pip install git+https://github.com/
+rusty1s/pytorch_cluster.git pip install torchdrug ``` Quick Start ----------
+- TorchDrug is designed for humans and focused on graph structured data. It
+enables easy implementation of graph operations in machine learning models. All
+the operations in TorchDrug are backed by [PyTorch] framework, and support GPU
+acceleration and auto differentiation. ```python from torchdrug import data
+edge_list = [[0, 1], [1, 2], [2, 3], [3, 4], [4, 5], [5, 0]] graph = data.Graph
+(edge_list, num_node=6) graph = graph.cuda() # the subgraph induced by nodes 2,
+3 & 4 subgraph = graph.subgraph([2, 3, 4]) ``` Molecules are also supported in
+TorchDrug. You can get the desired molecule properties without any domain
+knowledge. ```python mol = data.Molecule.from_smiles("CCOC(=O)N",
+atom_feature="default", bond_feature="default") print(mol.node_feature) print
+(mol.atom_type) print(mol.to_scaffold()) ``` You may also register custom node,
+edge or graph attributes. They will be automatically processed during indexing
+operations. ```python with mol.edge(): mol.is_CC_bond = (mol.edge_list[:, :2]
+== td.CARBON).all(dim=-1) sub_mol = mol.subgraph(mol.atom_type != td.NITROGEN)
 print(sub_mol.is_CC_bond) ``` TorchDrug provides a wide range of common
 datasets and building blocks for drug discovery. With minimal code, you can
 apply standard models to solve your own problem. ```python import torch from
 torchdrug import datasets dataset = datasets.Tox21() dataset[0].visualize()
 lengths = [int(0.8 * len(dataset)), int(0.1 * len(dataset))] lengths += [len
 (dataset) - sum(lengths)] train_set, valid_set, test_set =
 torch.utils.data.random_split(dataset, lengths) ``` ```python from torchdrug
```

## Comparing `torchdrug-0.2.0.post1.dist-info/RECORD` & `torchdrug-0.2.1.dist-info/RECORD`

 * *Files 7% similar despite different names*

```diff
@@ -1,27 +1,27 @@
-torchdrug/__init__.py,sha256=nTCoaMyeqZJxoXu9M66CHLc3KdZUg_i1nYqyGdoZbdg,330
-torchdrug/patch.py,sha256=I8x5FGO4FvsYe5jilmI-R4dgTBsfuo77joBvzu1wn_w,6263
+torchdrug/__init__.py,sha256=WqFP3NNVIs1hY903Bdvp5PB5MG8UgPRqbVc22Te9LZk,331
+torchdrug/patch.py,sha256=vKNTmPwOf6tV4tOvUGzTSNWyylSaVAf7nPHRDYCnIaw,5625
 torchdrug/core/__init__.py,sha256=JfbhuZbbKlSITBm7c41RqwovExumDUppw_mYJjjwzsI,320
-torchdrug/core/core.py,sha256=_p5fGlzxmcy3U98F6gYiNb-9xEgH5MDy0ueZYkZyrEU,12721
-torchdrug/core/engine.py,sha256=0ia7FAsnJ1fOb8VlAlr8IeHlnLfA0JfHrrW_TDNdeAE,11218
-torchdrug/core/logger.py,sha256=3ZGMrIBse2OVFbRGCrOUGQQwbihIRqCax25fcNSTWVY,4180
+torchdrug/core/core.py,sha256=idkE9hryWNHrM0pnqdfFVLnXWHu9DeEA0MxdrVxa9Zs,13092
+torchdrug/core/engine.py,sha256=xKs3UlGfHzScraPq2J5aaJSAMSFpcE5odyQ6Fv-ez6g,11684
+torchdrug/core/logger.py,sha256=CHrqpB59ZONqeAJ0EUziO-9RkTzIbFZmGzmSbm2oB1s,4197
 torchdrug/core/meter.py,sha256=6N_ihT3isa_O2kJKWDyRWSvKXvEeHHVq4_01Tb2EvNY,3894
 torchdrug/data/__init__.py,sha256=XFrr64mXcCNdmYG3kEz-YHLvt-RPbU5hC73QtEIjjyw,989
 torchdrug/data/constant.py,sha256=LkqlIfoyUEJJujQHBN5MbAD3KLpCYgcQNMPMxf-2JTY,3295
 torchdrug/data/dataloader.py,sha256=8_bRi6bZdx49txu5CjBY23vY9CCbq65T0nUMeJKAs1k,3729
-torchdrug/data/dataset.py,sha256=rDneE6R55Sk0_cKm-9jomO_8MgIBU4Sy2HQlQMiayCw,49243
+torchdrug/data/dataset.py,sha256=5wD-uTyP-QkWo2JnC7GtPndwKrucA2sq3fMCviZue38,49270
 torchdrug/data/dictionary.py,sha256=5d-hBF5HKBswb8bjMZgTfAWx6QLhYr0FQP7Ct6xuF0c,10947
-torchdrug/data/feature.py,sha256=_kz-1phZUpG3q1v_ir2_2H_pE3W-tlOE6TyGGeGGVtU,12469
-torchdrug/data/graph.py,sha256=PeshSjoQ9GFtwUsGoIgKmtmohbbCkvNVRvyaLsnQIgA,76505
-torchdrug/data/molecule.py,sha256=AOpWPRRFA1dWPid8PskGEAh68A0miEB9oKBwcz7wqV4,42169
-torchdrug/data/protein.py,sha256=b2_VwoB5jMmjgdP3sTZo7q3w9qAwZHmZVf87OWR2ZZc,65097
+torchdrug/data/feature.py,sha256=h4GeWfeBpgO9q2zfP430ckcVsfYWH9OjG5y82Mjkohk,12499
+torchdrug/data/graph.py,sha256=YzQq_ihY19uwWAXVvZYBJPYBJXY38qa9USjYyx-f97g,76585
+torchdrug/data/molecule.py,sha256=HEyEWH-lmUCVoF2n2SuvaAgAN0STpBxpmpqDnCi6O00,42173
+torchdrug/data/protein.py,sha256=WboS_7FdTn9GiijUGkw9l8pGwJiNRdDwFxTBxLhrSXw,65238
 torchdrug/data/rdkit/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 torchdrug/data/rdkit/draw.py,sha256=lpqjA9xyyx1kHsLo61HwgAYigWmvhOPUYhuBNTkZ5fo,1771
-torchdrug/datasets/__init__.py,sha256=zcTCToENwWSF_D1GASdOdhehCeAFnWv7kcsG5w1wqcA,2115
-torchdrug/datasets/alphafolddb.py,sha256=3o0dgMDcQi2K_-tv1CJ0mNfhxnXzKUCLJEy8rprbN-g,9114
+torchdrug/datasets/__init__.py,sha256=cei7QaqmiCAVQsqOyuUm8C6dTlzYUKtJAQKtlJPbO20,2144
+torchdrug/datasets/alphafolddb.py,sha256=eRZ8Z3gN_LGfSFmSLw8aTQTNvLaUDM0WZBmnS2Fq49E,10130
 torchdrug/datasets/bace.py,sha256=uGR1olIjP-N3oAv18jJZiOFcCsOjmyniXmbcubD3bA0,1111
 torchdrug/datasets/bbbp.py,sha256=hdBLHvPxA0AXRjK779fHGU9jKOzDAzfj1o9Fy9hzL9k,1071
 torchdrug/datasets/beta_lactamase.py,sha256=TqifRx7-sLooyBnaPC_JPKGpiZhLiT5zC7uMtiuZiWs,1652
 torchdrug/datasets/binary_localization.py,sha256=kLVmuH7lipalB0wlr4DqeRyg9Ig4cI22ihsYnO-2_xo,1750
 torchdrug/datasets/bindingdb.py,sha256=NVVO_1WXyExQ6ryzoBS1Xan96l0byr87VfUe463-omI,2566
 torchdrug/datasets/cep.py,sha256=de_epg6hnVzG-8GkgcCFT3yiFwg_KweRO9nuM6LgbW0,1122
 torchdrug/datasets/chembl_filtered.py,sha256=lICiHuXVl3ROYODWtBpgNSKjVUrVfFQFkbT_-a_xceo,1126
@@ -30,15 +30,15 @@
 torchdrug/datasets/cora.py,sha256=1Qv-FRvrsQAecYkvj_E-SzgUfuodkmHtfOn5pgQQSEU,992
 torchdrug/datasets/delaney.py,sha256=qu05EEUQ95PWVhfxxP8vmRT5WTwoDtctTfdErICFzfo,1119
 torchdrug/datasets/enzyme_commission.py,sha256=8bMM8ScTJW_NiWbHY9x5VwjlR7KUIp5rRBZQTi-Pluo,5152
 torchdrug/datasets/fb15k.py,sha256=pVQvxG96MTXVS3ht_5VauMG5z9OZRKCJxGNR50A5nS4,3362
 torchdrug/datasets/fluorescence.py,sha256=0N3GHAF6SCJTYwMB0J_IzFxDgsYU-16QHht1Efpi1oc,1622
 torchdrug/datasets/fold.py,sha256=Kba5buwsKsk4Aw7gnwl-CoxL4FrgI1Olmrhf6rbH4gM,1801
 torchdrug/datasets/freesolv.py,sha256=xDcQTyWRndufypYA4YysB2b7RXs_RWkqbH7axprmmNs,1173
-torchdrug/datasets/gene_ontology.py,sha256=JCqmulwUgYmRCPIQQEBjkXu7eAMEJhttwqRlTlAusVk,5740
+torchdrug/datasets/gene_ontology.py,sha256=lLzVj74U0ZV90Dm7OBwL08wuVOBGOQwGDbs6bM3K6i0,5730
 torchdrug/datasets/hetionet.py,sha256=nDc1AyZQOU11W8fgCREfsTW-blAu5-NFByUyy4d2qcA,1641
 torchdrug/datasets/hiv.py,sha256=QzNjs3XenQpd1CqWnnilizGkGSS9wDoAkO-i9ADY1pI,1087
 torchdrug/datasets/human_ppi.py,sha256=auIrUubGIW2hwjyLSyRg4xYlrf3W1iRMpaNkf2QrF-E,2377
 torchdrug/datasets/lipophilicity.py,sha256=VkDg_h2bTKEUIWu13TEC6Lws9aLae3Q-EseBIhGI1FY,1130
 torchdrug/datasets/malaria.py,sha256=vQZwDMAlREsUEnq2v7ROwRQ4Kfv_4BeoH93ZSVvtKG0,1171
 torchdrug/datasets/moses.py,sha256=3LKLDPkP4DLzVekmbiNDwyMCgdkMs6UIa-gJNTeaOeg,1590
 torchdrug/datasets/muv.py,sha256=XuZnUyX2h8FCbPbhBChlQAPZMLAB2Epf66pLFUe0E_o,1340
@@ -56,89 +56,89 @@
 torchdrug/datasets/solubility.py,sha256=YUvMVxpgMgrzCntEPUCYg5EWns5E02vWqguR4t7P2M8,1612
 torchdrug/datasets/stability.py,sha256=HG_0POJbT6x4UXydrSdRccc2cuh39OSiUSGHSEIogj0,1600
 torchdrug/datasets/subcellular_localization.py,sha256=zvMSoCc3JVr7SfsDMm6dhAWzfpQyQAEiawj6n4ztag4,1693
 torchdrug/datasets/tox21.py,sha256=vJpb4qZ6A2-SXwroDWSC9JtVBsFTKlp-JosOpR5JbiY,1343
 torchdrug/datasets/toxcast.py,sha256=53dK43nDjZCYOuuit8-ZvWcc-Kv9NY4FnE7ux_CPbyA,1158
 torchdrug/datasets/uspto50k.py,sha256=oZzshgZd0-SPzJIbN1_se0wnmL2UsG_Ulur2DgWNzj4,11457
 torchdrug/datasets/wn18.py,sha256=PnWuh-zEWC3t3JaWbr49j4AY4ZowfJx0TDFAd9D6i2s,3294
+torchdrug/datasets/yago310.py,sha256=5CNlsTSRYgLw99kmhNQGWe1xYV2FS12mG3TdnQKuyB0,1785
 torchdrug/datasets/yeast_ppi.py,sha256=f6XH6zKuGTApKvbSZ7lzBigJ78G_dl6--Jslx3Nrwjc,2377
 torchdrug/datasets/zinc250k.py,sha256=0nEf4Qzrb44k14tYpJA09vk83trAGVrJtnYaP23iGXk,1162
 torchdrug/datasets/zinc2m.py,sha256=OZT3kI_8IW60-fmJqSFNKlCFdLEj603_3aytcGCp5mM,1743
 torchdrug/layers/__init__.py,sha256=UkjELIxHYhwEImSUreJuXyQju6saO23FErFoV12oEM8,1793
 torchdrug/layers/block.py,sha256=n_3JL-I6JTYk62Pk0w24OjmU91EUIBHfqzO2VG3oHVs,5812
-torchdrug/layers/common.py,sha256=4Jt2O6wS1WMqKsPPttoRsKP4G7biPMfQcQsDZI2nA_Q,12211
-torchdrug/layers/conv.py,sha256=0LTPmYov8AEB-j7y841CvZQN2opTnmy5w0l02XJ9kg8,33424
+torchdrug/layers/common.py,sha256=sovuGcR0zOw6XoTj2Usx5tm1pmvnjLho5ohDUMNbWjk,12209
+torchdrug/layers/conv.py,sha256=vwVXqF0IkJ0qLLRD3r12dmNxqpNimFUK364MD3tRu0Q,33425
 torchdrug/layers/distribution.py,sha256=u4irTiPJyJECKrMUdpBaLk6mxBuDONI5TrA51TqHTkE,1525
 torchdrug/layers/flow.py,sha256=7_i8VxB_zlc_IvucYZPZNNuzKQQuMnZDPVfL0wyfL1Y,2145
 torchdrug/layers/pool.py,sha256=BC5iiho0Eghou76mHNjPffn_PKSfjIBSX_uF8-e_wYU,9381
 torchdrug/layers/readout.py,sha256=F2gmVzTfmg_kVTPt6HP1NWa76yGxBvzZPxb8wu17cl8,6144
 torchdrug/layers/sampler.py,sha256=C8O0aRCWoDJNFso_wFhotDy2_XFRtEEpZOWgTCp52nQ,3062
-torchdrug/layers/functional/__init__.py,sha256=lfEElyJDxUWbIvhCD3h5Gr7hmxZHPRxCVnlBXUu77v4,1258
+torchdrug/layers/functional/__init__.py,sha256=eYeRRkOHx5wGY89HAJ_--tPH5OARlp9s_7yzLk7GQCk,1241
 torchdrug/layers/functional/embedding.py,sha256=MjiS7rv9G6qtkIOn53BRsv5WGiSSQBooSK3zZp5187M,9943
-torchdrug/layers/functional/functional.py,sha256=671SL7tlILrS4DgdNworKNV7CihX75oX3zy9FZFDpgs,18348
+torchdrug/layers/functional/functional.py,sha256=XZSRMWH3-qs-iWu4pcr6cDqHWvDCc4lTuEevT974A20,18048
 torchdrug/layers/functional/spmm.py,sha256=crOuGIli16vB_Gs-0UXgPaZsXkmPF1u-hhDRAy7y3A0,13670
 torchdrug/layers/functional/extension/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 torchdrug/layers/functional/extension/embedding.cpp,sha256=hzfOqoGnZC-xcYeKLgHdoYOiC7f65fU4GxJN05Qvkno,25464
 torchdrug/layers/functional/extension/embedding.cu,sha256=Aaz4FEkelkTg2kS_9INwUu1wBd27aF7ms-w2CZqhtTw,25353
 torchdrug/layers/functional/extension/embedding.h,sha256=16qklpO4T2JlcboHuYVm9Wrd-2oRy1ED7dk496MkOyA,4529
 torchdrug/layers/functional/extension/operator.cuh,sha256=WkJVEjosn9YvGOhmPrUxva2gbNmLEeVTpSy30FLj8Rg,1841
 torchdrug/layers/functional/extension/rspmm.cpp,sha256=kMqF89ZIsI8oRGVDXfMdrfuERjiwVjvLuwWwY0eIAqA,12434
 torchdrug/layers/functional/extension/rspmm.cu,sha256=MnXscUw4ah3XnEz2z44vju2UE_x81pUYiFamnwd3-vQ,16670
 torchdrug/layers/functional/extension/rspmm.h,sha256=vrskaz7Tjd74hawCEqQLTllx6Oeb7MyxB2HgNbK9SFo,4506
 torchdrug/layers/functional/extension/spmm.cpp,sha256=HvQ3ypev7PH_UAaQA4yqX_ccvH6sXi3lOP_fAXRDIeY,13877
 torchdrug/layers/functional/extension/spmm.cu,sha256=Jil823cVM5b09m52XahYQb1SHlbQUa0ycQaR6ro2uCg,14092
 torchdrug/layers/functional/extension/spmm.h,sha256=zs073HaR4wRBoQwsoaAwZR0rm6iMyNnw3mGoD9t6eQs,3693
 torchdrug/layers/functional/extension/util.cuh,sha256=629Ix_QJVaYI1GHJv7LMk2KoMMrlFi_Bw2AjXu2WOpg,623
 torchdrug/layers/geometry/__init__.py,sha256=-INWLoTF6Immmh09063lDCKscfd5lDjEFsHhzCg9KXc,418
-torchdrug/layers/geometry/function.py,sha256=1WMFSITODk0mfm3eIqEJ4kWrj0so2ZWrD5BqiRVcd3I,12428
-torchdrug/layers/geometry/graph.py,sha256=wLgxKtwmcYNYSMfCxV-kRzzcvkvdUNu5kY--hrDxHMg,7661
+torchdrug/layers/geometry/function.py,sha256=_BkE7p4ihRgVlacEXb8FAQhgS7nHLXwbvNRkKulg-vo,13246
+torchdrug/layers/geometry/graph.py,sha256=-sVBvhA0VxfH4oMOfeilLA6KLW0tJxYEWrZy54xzHXE,8152
 torchdrug/metrics/__init__.py,sha256=TI8QGMYM8tbFRjvjMa8_Gdun45Q-9Cn_sDG60I2NwRA,643
-torchdrug/metrics/metric.py,sha256=C0N8bE8fszaUpyKYZkXTlp2TusGpq3HChBrHjLd0Eok,13534
+torchdrug/metrics/metric.py,sha256=dg83bUElqyzJMyyeg7lE1EZNpRrqV311Jm2SR6yoF3Y,13528
 torchdrug/metrics/rdkit/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 torchdrug/metrics/rdkit/sascorer.py,sha256=AzkPxyG10ff80VmzlYzJ6MRKI0Qmw-K3Q7h4rwVO00w,2471
 torchdrug/models/__init__.py,sha256=MaIghlp6bu59I4OpTPS9S43KvKww8u28ZKwZzrcIY7E,2121
 torchdrug/models/bert.py,sha256=Hl7Gl66P6paNKnhOsmfVtoPeJabCga71PpXfFUXk_oM,4348
 torchdrug/models/chebnet.py,sha256=FQvD23gSt-_d1DeauC6Guym_M5bSUNR9TiDTaFcSCAM,3549
 torchdrug/models/cnn.py,sha256=G0kR_K6GSq8WQwFd0Shto3DYdMJ3WFxyjOoDNkfJBq8,8817
 torchdrug/models/embedding.py,sha256=fXMSIDPNZ4SH20sypdAtWWzUhd4b_aNWQTb5IjSw1sg,10023
-torchdrug/models/esm.py,sha256=iK8KYXQPi2E1ulnu-LL442ZgLpr2QvGxli8Ax6V5QBY,5949
+torchdrug/models/esm.py,sha256=wn5zuTyzZRYIBZaEALAee72WNlcdPTENxByPE2fif-U,7454
 torchdrug/models/flow.py,sha256=PxRwHw8d8Y_a87umwvjrGHm2r0HOY6YUKkUT3TCwir4,5039
 torchdrug/models/gat.py,sha256=JW9qbc86l6SANw_8SyVMCnN1gzOxVZpkAobZEZRsTKg,3503
 torchdrug/models/gcn.py,sha256=3OvKSx26JGWOQ-nCCs1JGVSotIV1AZqVxCaHBD0L-4w,6806
 torchdrug/models/gearnet.py,sha256=YVtGHbRYL13TPKATiEFOBuOhrNvybCooI9m1pFEnAwo,5562
 torchdrug/models/gin.py,sha256=oBoUvBjO2WWEtK7ZuUdbr3W3Q9tE9MmmPZO45jG2pKQ,3669
-torchdrug/models/infograph.py,sha256=uxRTSdLvloNzAi2U8UPhuGPrVDDl_W0PZBdoUZ21Q60,7103
+torchdrug/models/infograph.py,sha256=zCxbq5ol1nFrOU-fwx28nupi4AKzacH682gPrHQv91c,7228
 torchdrug/models/kbgat.py,sha256=d3PLfmR9Julsgthvan7LRhXnmAo8eecJDqGM6xRdYpw,2628
-torchdrug/models/lstm.py,sha256=Vhu_LnAXo3chC6BU6ApOuLtyiqR3ZPh4yGweiXeC_Dk,3447
-torchdrug/models/mpnn.py,sha256=6PffgBoX_7u81Ocd1uuKdANrQZFEJI_L4g23kA6W8FU,3711
+torchdrug/models/lstm.py,sha256=fnM9OkKiHiGApnN_OierkG3o32ExlZnfFPRahOx4JNE,3396
+torchdrug/models/mpnn.py,sha256=r3cftsUlYlasaOhbjdmjKSedNLFlmDKEvSa9b5jJdWE,3720
 torchdrug/models/neuralfp.py,sha256=JCfEMeUY6H_SYRg7ZQH3sf1LKCsS_271yV_tS2MeQvA,3848
-torchdrug/models/neurallp.py,sha256=DKkejM-2iLk7juf85unSnl5ZGmxOyFVWTx3nrDf_Wd8,4832
-torchdrug/models/physicochemical.py,sha256=Ly0A3IXiQC6A1wgjZKdjNEfUIUoXsW0qz_KiFKpy88c,6851
+torchdrug/models/neurallp.py,sha256=bnglnbZLc1CL-N2vxmV33zyRYk7-PTaE5PqqUiK-jHc,4864
+torchdrug/models/physicochemical.py,sha256=64QDWLr5jYN8TkjwUlQCH_wB2jvFl8HRVVnDmERc7tI,6849
 torchdrug/models/schnet.py,sha256=UNaOFBw_Pud9q6sezXf1zda8KCMAwIjg_voVh243LWg,3356
 torchdrug/models/statistic.py,sha256=Mb5DDbiHEu3aCCglimRIS19EV23h2prp7xxO1FJ7Zs0,3308
 torchdrug/tasks/__init__.py,sha256=riDqXkq2R9ISU_AHk23WZxsH_17cSW101c7m_HI5kEo,1621
-torchdrug/tasks/contact_prediction.py,sha256=xamW4jNaRqpFF45996icRBYUn69zmnnKdGv1PwTvcIs,7324
+torchdrug/tasks/contact_prediction.py,sha256=H75PljbwgglugfOQWHTSHSGTfNARjcCQo00IswxevSk,7378
 torchdrug/tasks/generation.py,sha256=XCv__5YRctWClVhnzze99xf_-PMgwgM1_qtQMkuikqk,74693
-torchdrug/tasks/pretrain.py,sha256=bmro814TmFDGzELUqlnIegolR_VjwIOk_NN0dPDqhwo,23162
-torchdrug/tasks/property_prediction.py,sha256=fbaDCvwooLfhztlXM2ezKqJmr9vWZnmjrzLBFtbU8H8,24026
-torchdrug/tasks/reasoning.py,sha256=Y82Y9N_W9BAE6Zj9S7-mPaiJKZ-QDlLbd4H1Mf_S0GA,11625
-torchdrug/tasks/retrosynthesis.py,sha256=rB-YhFJPg0hH_XgAFI5CRmOtCs-t8AQgJEFwT-m5Uvc,55909
-torchdrug/tasks/task.py,sha256=YWPACestj1qQyjE_4btodzJthqSXkaq4jkNGY1QSenA,1107
+torchdrug/tasks/pretrain.py,sha256=Ek7iPrfR8KehkBgQ-T7ntnn8rJt8hOg4h2Vzd9XYSiQ,23157
+torchdrug/tasks/property_prediction.py,sha256=zMP-w_RYQFiGnOvBC5ZWzUYrHrRDGDzPeLW1uxnHch4,24382
+torchdrug/tasks/reasoning.py,sha256=UnxlD0UWkLWcOxy3j6oIf0ECKdZImiSDTk159CV1_Hw,11993
+torchdrug/tasks/retrosynthesis.py,sha256=UyyxFiRcOqvlJl-SxUjsZNkPisT5mJ5mCkBr4DDEQTU,55899
+torchdrug/tasks/task.py,sha256=DCcnGrOaFhb3hnqxWSwJWnEMEmt75Jk4reV8ZAlqu_s,1111
 torchdrug/transforms/__init__.py,sha256=M31_Bg0JJIap3cpHa1EYScYtIa-ObnSPwFBcfWsa8BI,317
 torchdrug/transforms/transform.py,sha256=OqTVvExAH6aXg8XAjPyStsO1DsfAmvYhsfPBnKEwrvQ,11043
 torchdrug/utils/__init__.py,sha256=QgQ682bYoh2gRXQIaCA3sHjEh0l20rHoCKuOi1Qp5To,717
 torchdrug/utils/comm.py,sha256=YSpfLhU2ozENureXEqUJCYzMl9yZaKtqX9sROjTSvlQ,8428
 torchdrug/utils/decorator.py,sha256=InczDJf3QTN4zG2DHCcI-DIYhy1LCgV7hz_QnetG5vE,10252
-torchdrug/utils/doc.py,sha256=tm3-4CmJ_7MsYjsH3xwQ1_rwNe6080P3cKAGFPQlPek,5452
 torchdrug/utils/file.py,sha256=Sk9XDowxga64pWdSroJX_IirXOsDvuC79gzHaQ1-7JU,5973
 torchdrug/utils/io.py,sha256=xFKwPl-T61Q6nGAkngaNL0g-iBl1tacHY71X8VKGk90,2165
 torchdrug/utils/plot.py,sha256=Dg1ujeDKMdhejrwr_CBOR3EyQakksl31zZxLtQ6lnFE,6852
-torchdrug/utils/pretty.py,sha256=EtU-rlqOJifBYaPi_Cd6z8_6_I-wPHb9nt-BDoq_P1M,1044
-torchdrug/utils/torch.py,sha256=PgOnFzgvBlwcn_tgKH0AXo_MkA_s3L5Jm7tR4pIg8tU,6464
+torchdrug/utils/pretty.py,sha256=YXKm5bAdNZutFq6qkp1zodSeu31lIkV_YFgVgLMkbEA,1931
+torchdrug/utils/torch.py,sha256=Q3I84rP0qTgzZ_Wr-vWschHRwouX-uklfftDiIsyvDw,6550
 torchdrug/utils/extension/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 torchdrug/utils/extension/torch_ext.cpp,sha256=UpEooqWaSVrEc7f8Obr0FNRrVK0RK7nUbfw0lJIOnIc,419
 torchdrug/utils/template/echarts.html,sha256=XB3Q0kIrrLBKUs1rVzdohg4rnbwFqQNr78nCt9gzlbg,2267
-torchdrug-0.2.0.post1.dist-info/LICENSE,sha256=J-xTuZ3sB7FFaQEHg8NFMpdr4Slk_KapzDmDFgGwyYs,11342
-torchdrug-0.2.0.post1.dist-info/METADATA,sha256=zWd1LzfwssNgQjJ1x55jsqkKbrg6-lGqfncUMiC4DV4,7109
-torchdrug-0.2.0.post1.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
-torchdrug-0.2.0.post1.dist-info/top_level.txt,sha256=slAtMFb5TlcTvi1MGBvWeFwoN2aDjex9ykA9sUVPlQk,10
-torchdrug-0.2.0.post1.dist-info/RECORD,,
+torchdrug-0.2.1.dist-info/LICENSE,sha256=J-xTuZ3sB7FFaQEHg8NFMpdr4Slk_KapzDmDFgGwyYs,11342
+torchdrug-0.2.1.dist-info/METADATA,sha256=Fo28lnHj7kErt1X4uP6X1BulRk9AkH6ENuxKzsCZTYE,7515
+torchdrug-0.2.1.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+torchdrug-0.2.1.dist-info/top_level.txt,sha256=slAtMFb5TlcTvi1MGBvWeFwoN2aDjex9ykA9sUVPlQk,10
+torchdrug-0.2.1.dist-info/RECORD,,
```

