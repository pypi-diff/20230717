# Comparing `tmp/am_viewer-3.9-py3-none-any.whl.zip` & `tmp/am_viewer-4.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,28 +1,28 @@
-Zip file size: 710237 bytes, number of entries: 26
--rw-r--r--  2.0 unx        0 b- defN 19-Sep-10 19:37 adm/__init__.py
--rw-r--r--  2.0 unx    24641 b- defN 20-Jul-02 17:39 adm/adm_classes.py
--rw-r--r--  2.0 unx    11741 b- defN 20-Sep-09 00:32 adm/adm_const.py
--rw-r--r--  2.0 unx    41926 b- defN 20-Sep-09 00:32 adm/adm_tool.py
--r--r--r--  2.0 unx      381 b- defN 19-Sep-10 19:37 adm/limits.txt
--rw-r--r--  2.0 unx        0 b- defN 19-Sep-10 19:37 am_viewer/__init__.py
--rw-r--r--  2.0 unx    78208 b- defN 20-Sep-10 22:20 am_viewer/am_viewer.py
--rw-r--r--  2.0 unx     7594 b- defN 20-Aug-11 13:29 am_viewer/am_xml_viewer.py
--rwx------  2.0 unx   443892 b- defN 20-Mar-02 16:16 am_viewer/pmd_tool.Darwin
--rwx------  2.0 unx   490960 b- defN 20-Mar-02 16:58 am_viewer/pmd_tool.Linux
--rwx------  2.0 unx   515584 b- defN 20-Mar-02 16:52 am_viewer/pmd_tool.Windows.exe
--rwxr-xr-x  2.0 unx       62 b- defN 20-Sep-10 22:20 am_viewer-3.9.data/scripts/am_viewer
--rw-r--r--  2.0 unx        0 b- defN 19-Sep-10 19:37 aoip_services/__init__.py
--rw-r--r--  2.0 unx    12610 b- defN 20-Sep-09 00:32 aoip_services/aoip_discovery.py
--rw-r--r--  2.0 unx     3729 b- defN 20-Jan-29 23:30 aoip_services/multicast.py
--rw-r--r--  2.0 unx     3455 b- defN 20-May-15 20:42 aoip_services/sdp_parser.py
--rw-r--r--  2.0 unx        0 b- defN 19-Sep-10 19:37 pmd/__init__.py
--rw-r--r--  2.0 unx     6993 b- defN 20-Mar-16 19:51 pmd/pmd_classes.py
--rw-r--r--  2.0 unx    10146 b- defN 20-Mar-16 19:51 pmd/pmd_const.py
--rw-r--r--  2.0 unx    64327 b- defN 20-Sep-10 22:11 pmd/pmd_tool.py
--r--r--r--  2.0 unx     1531 b- defN 20-Sep-10 22:20 am_viewer-3.9.dist-info/LICENSE
--rw-r--r--  2.0 unx     8484 b- defN 20-Sep-10 22:20 am_viewer-3.9.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 20-Sep-10 22:20 am_viewer-3.9.dist-info/WHEEL
--rw-r--r--  2.0 unx       54 b- defN 20-Sep-10 22:20 am_viewer-3.9.dist-info/entry_points.txt
--rw-r--r--  2.0 unx       32 b- defN 20-Sep-10 22:20 am_viewer-3.9.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx     2054 b- defN 20-Sep-10 22:20 am_viewer-3.9.dist-info/RECORD
-26 files, 1728496 bytes uncompressed, 706971 bytes compressed:  59.1%
+Zip file size: 716858 bytes, number of entries: 26
+-rw-r--r--  2.0 unx        0 b- defN 22-Sep-28 12:24 adm/__init__.py
+-rw-r--r--  2.0 unx    25731 b- defN 22-Nov-04 02:21 adm/adm_classes.py
+-rw-r--r--  2.0 unx    12258 b- defN 22-Nov-04 02:21 adm/adm_const.py
+-rw-r--r--  2.0 unx    52280 b- defN 22-Nov-04 02:21 adm/adm_tool.py
+-rw-r--r--  2.0 unx      381 b- defN 22-Sep-28 12:24 adm/limits.txt
+-rw-r--r--  2.0 unx        0 b- defN 22-Sep-28 12:24 am_viewer/__init__.py
+-rw-r--r--  2.0 unx    85448 b- defN 23-Jul-17 15:32 am_viewer/am_viewer.py
+-rw-r--r--  2.0 unx     7594 b- defN 22-Sep-28 12:24 am_viewer/am_xml_viewer.py
+-rwxr-xr-x  2.0 unx   443892 b- defN 22-Sep-28 12:24 am_viewer/pmd_tool.Darwin
+-rwxr-xr-x  2.0 unx   490960 b- defN 22-Sep-28 12:24 am_viewer/pmd_tool.Linux
+-rwxr-xr-x  2.0 unx   515584 b- defN 22-Sep-28 12:24 am_viewer/pmd_tool.Windows.exe
+-rwxr-xr-x  2.0 unx       62 b- defN 23-Jul-17 16:09 am_viewer-4.0.data/scripts/am_viewer
+-rw-r--r--  2.0 unx        0 b- defN 22-Sep-28 12:24 aoip_services/__init__.py
+-rw-r--r--  2.0 unx    12610 b- defN 22-Sep-28 12:24 aoip_services/aoip_discovery.py
+-rw-r--r--  2.0 unx     3729 b- defN 22-Sep-28 12:24 aoip_services/multicast.py
+-rw-r--r--  2.0 unx     3455 b- defN 22-Sep-28 12:24 aoip_services/sdp_parser.py
+-rw-r--r--  2.0 unx        0 b- defN 22-Sep-28 12:24 pmd/__init__.py
+-rw-r--r--  2.0 unx    10914 b- defN 22-Nov-05 13:55 pmd/pmd_classes.py
+-rw-r--r--  2.0 unx    10249 b- defN 22-Nov-05 13:55 pmd/pmd_const.py
+-rw-r--r--  2.0 unx    79111 b- defN 22-Nov-14 15:21 pmd/pmd_tool.py
+-r--r--r--  2.0 unx     1531 b- defN 23-Jul-17 16:09 am_viewer-4.0.dist-info/LICENSE
+-rw-r--r--  2.0 unx     8549 b- defN 23-Jul-17 16:09 am_viewer-4.0.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Jul-17 16:09 am_viewer-4.0.dist-info/WHEEL
+-rw-r--r--  2.0 unx       55 b- defN 23-Jul-17 16:09 am_viewer-4.0.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx       32 b- defN 23-Jul-17 16:09 am_viewer-4.0.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     2055 b- defN 23-Jul-17 16:09 am_viewer-4.0.dist-info/RECORD
+26 files, 1766572 bytes uncompressed, 713592 bytes compressed:  59.6%
```

## zipnote {}

```diff
@@ -27,15 +27,15 @@
 
 Filename: am_viewer/pmd_tool.Linux
 Comment: 
 
 Filename: am_viewer/pmd_tool.Windows.exe
 Comment: 
 
-Filename: am_viewer-3.9.data/scripts/am_viewer
+Filename: am_viewer-4.0.data/scripts/am_viewer
 Comment: 
 
 Filename: aoip_services/__init__.py
 Comment: 
 
 Filename: aoip_services/aoip_discovery.py
 Comment: 
@@ -54,26 +54,26 @@
 
 Filename: pmd/pmd_const.py
 Comment: 
 
 Filename: pmd/pmd_tool.py
 Comment: 
 
-Filename: am_viewer-3.9.dist-info/LICENSE
+Filename: am_viewer-4.0.dist-info/LICENSE
 Comment: 
 
-Filename: am_viewer-3.9.dist-info/METADATA
+Filename: am_viewer-4.0.dist-info/METADATA
 Comment: 
 
-Filename: am_viewer-3.9.dist-info/WHEEL
+Filename: am_viewer-4.0.dist-info/WHEEL
 Comment: 
 
-Filename: am_viewer-3.9.dist-info/entry_points.txt
+Filename: am_viewer-4.0.dist-info/entry_points.txt
 Comment: 
 
-Filename: am_viewer-3.9.dist-info/top_level.txt
+Filename: am_viewer-4.0.dist-info/top_level.txt
 Comment: 
 
-Filename: am_viewer-3.9.dist-info/RECORD
+Filename: am_viewer-4.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## adm/adm_classes.py

```diff
@@ -161,37 +161,61 @@
     def __init__(self, name, language, id):
         self.name = name
         self.language = language
         self.id = id
         self.audio_programme_label = []
         self.audio_content_idref = []
         self.loudness_metadata = None
+        self.alternative_value_set_idref = []
+        self.needs_unrolling = False
+
+
+class RolledProgramme:
+    def __init__(self, programme_id):
+        self.id = programme_id
+        self.audio_object_group_leader = None
+        self.audio_content_idref = []
+        self.audio_object_idref = []
 
 
 class AudioContent:
     def __init__(self, id, name):
         self.id = id
         self.name = name
         self.dialogue = None
         self.audio_object_idref = []
 
 
+class Gain:
+    def __init__(self, gain_unit, gain_value):
+        self.gain_unit = gain_unit
+        self.gain_value = gain_value
+
+
 class Dialogue:
     def __init__(self, value, classification):
         value = int(value)
         classification = int(classification)
         self.value = value
         if value == NON_DIALOGUE_CONTENT:
             self.content_kind = NonDialogueContentKind(classification)
         elif value == DIALOGUE_CONTENT:
             self.content_kind = DialogueContentKind(classification)
         elif value == MIXED_CONTENT:
             self.content_kind = MixedContentKind(classification)
 
 
+class AlternativeValueSet:
+    def __init__(self, id):
+        self.id = id
+        self.gain = None
+        self.audio_object_interaction = None
+        self.position_offset = None
+
+
 class NonDialogueContentKind:
     def __init__(self, classification):
         self.classification = classification
         self.classification_text = NON_DIALOGUE_CONTENT_KIND[classification]
 
 
 class DialogueContentKind:
@@ -209,17 +233,33 @@
 class AudioObject:
     def __init__(self, id, name):
         self.id = id
         self.name = name
         self.audio_pack_idref = []
         self.audio_track_idref = []
         self.head_locked = None
-        self.gain = None
+        self.gain = {'gain_value': 0.0, 'gain_unit': 'dB'}
+        self.audio_complementary_object_idref = []
+        self.alternative_value_set = []
 
 
+class Gain:
+    def __init__(self, gain_unit='dB', gain_value=0.0):
+        self.gain_unit = gain_unit
+        self.gain_value = gain_value
+        
+
+class AlternativeValueSet:
+    def __init__(self, id):
+        self.id = id
+        self.gain = None
+        self.audio_object_interaction = None
+        self.position_offset = None
+        
+        
 class AudioChannelFormat:
     def __init__(self, id, name):
         self.id = id
         self.name = name
         self.audio_block = None
```

## adm/adm_const.py

```diff
@@ -54,14 +54,15 @@
 NON_DIALOGUE_CONTENT_KIND = ["undefined", "music", "effect"]
 DIALOGUE_CONTENT_KIND = ["undefined", "dialogue", "voiceover", "spoken subtitle", "audio description", "commentary", "emergency"]
 MIXED_CONTENT_KIND = ["undefined", "complete main", "mixed", "hearing impaired"]
 DIALOGUE_TEXT = ["nonDialogueContentKind", "dialogueContentKind", "mixedContentKind"]
 COORDINATE_MODE = ["Polar", "Cartesian"]
 TYPE_DEFINITION = ["Invalid", "DirectSpeakers", "Matrix", "Objects", "HOA", "Binaural"]
 TYPE_LABEL = ["Invalid", "0001", "0002", "0003", "0004", "0005"]
+SUPPORTED_COMMON_DEFS = ['AP_00010002', 'AP_0001000a', 'AP_00010003', 'AP_00010013', 'AP_00010005', 'AP_00010017']
 
 AUDIO_PACK_STR = "AP_000"
 AUDIO_PROGRAMME_STR = "APR_"
 AUDIO_CONTENT_STR = "AC_"
 AUDIO_OBJECT_STR = "AO_"
 AUDIO_BLOCK_STR = "AB_000"
 AUDIO_CHANNEL_STR = "AC_000"
@@ -206,14 +207,15 @@
 ADM_XML_APR_ELN_AT_NM = 'audioProgrammeName'
 ADM_XML_APR_ELN_AT_LN = 'audioProgrammeLanguage'
 ADM_XML_APR_ELN_AT_ID = 'audioProgrammeID'
 ADM_XML_APR_ELN_SE_PL = 'audioProgrammeLabel'
 ADM_XML_APR_ELN_SE_PL_AT_LN = 'language'
 ADM_XML_APR_ELN_SE_CR = 'audioContentIDRef'
 ADM_XML_APR_ELN_SE_LM = 'loudnessMetadata'
+ADM_XML_APR_ELN_SE_AV = 'alternativeValueSetIDRef'
 
 ADM_XML_ACO_ELN = 'audioContent'
 ADM_XML_ACO_ELN_AT_ID = 'audioContentID'
 ADM_XML_ACO_ELN_AT_NM = 'audioContentName'
 ADM_XML_APR_ELN_SE_DG = 'dialogue'
 ADM_XML_APR_ELN_SE_DG_AT_ND = 'nonDialogueContentKind'
 ADM_XML_APR_ELN_SE_DG_AT_DC = 'dialogueContentKind'
@@ -224,14 +226,16 @@
 ADM_XML_AOB_ELN = 'audioObject'
 ADM_XML_AOB_ELN_AT_ID = 'audioObjectID'
 ADM_XML_AOB_ELN_AT_NM = 'audioObjectName'
 ADM_XML_AOB_ELN_SE_AP = 'audioPackFormatIDRef'
 ADM_XML_AOB_ELN_SE_AT = 'audioTrackUIDRef'
 ADM_XML_AOB_ELN_SE_HL = 'headLocked'
 ADM_XML_AOB_ELN_SE_GN = 'gain'
+ADM_XML_AOB_ELN_SE_CO = 'audioComplementaryObjectIDRef'
+ADM_XML_AOB_ELN_SE_AV = 'alternativeValueSet'
 
 ADM_XML_APF_ELN = 'audioPackFormat'
 ADM_XML_APF_ELN_AT_ID = 'audioPackFormatID'
 ADM_XML_APF_ELN_AT_NM = 'audioPackFormatName'
 ADM_XML_APF_ELN_AT_TL = 'typeLabel'
 ADM_XML_APF_ELN_SE_AC = 'audioChannelFormatIDRef'
 
@@ -258,13 +262,20 @@
 
 SADM_XML_FH = 'frameHeader'
 SADM_XML_TTF_ELN = 'transportTrackFormat'
 SADM_XML_TTF_ELN_SE_AT = 'audioTrack'
 SADM_XML_TTF_ELN_SE_AT_SE_AR = 'audioTrackUIDRef'
 SADM_XML_TTF_ELN_SE_AT_AT_TI = 'trackID'
 
+SADM_XML_FRM_AT_VER = 'version'
+SADM_XML_FRM_AT_VER_OV = 'ITU-R_BS.2125-0'
+ADM_XML_FRM_AT_VER_OV = 'ITU-R_BS.2076-0'
+ADVSS_PROFILE_NAME = 'AdvSS Emission ADM and S-ADM Profile'
+TARGET_ADM_VER = 'ITU-R_BS.2076-3'
+TARGET_SADM_VER = 'ITU-R_BS.2125-1'
+
 ADM_XML_INDENT = "  "
 PMD_XML_MODE_FILE = 0
 PMD_XML_MODE_STRING = 1
 
 # ************************************************************************************************************************************************************ #
 # ************************************************************************************************************************************************************ #
```

## adm/adm_tool.py

```diff
@@ -140,22 +140,25 @@
 
 from adm.adm_const import ADM_XML_ATU_ELN, ADM_XML_ATU_ELN_AT_ID, ADM_XML_ATU_ELN_SE_CF, ADM_XML_ATU_ELN_SE_PF
 
 from adm.adm_const import ADM_XML_APR_ELN_SE_DG_AT_ND, ADM_XML_APR_ELN_SE_DG_AT_DC, ADM_XML_APR_ELN_SE_DG_AT_MC
 
 from adm.adm_const import ADM_XML_INDENT, PMD_XML_MODE_FILE, PMD_XML_MODE_STRING
 
-from adm.adm_const import SADM_XML_TTF_ELN_SE_AT_SE_AR, SADM_XML_TTF_ELN_SE_AT_AT_TI, SADM_XML_FH, SADM_XML_TTF_ELN , SADM_XML_TTF_ELN_SE_AT
+from adm.adm_const import SADM_XML_TTF_ELN_SE_AT_SE_AR, SADM_XML_TTF_ELN_SE_AT_AT_TI, SADM_XML_FH, SADM_XML_TTF_ELN
+from adm.adm_const import SADM_XML_TTF_ELN_SE_AT, SADM_XML_FRM_AT_VER, SADM_XML_FRM_AT_VER_OV, ADM_XML_FRM_AT_VER_OV
+from adm.adm_const import ADVSS_PROFILE_NAME, TARGET_ADM_VER, TARGET_SADM_VER, ADM_XML_APR_ELN_SE_AV, ADM_XML_AOB_ELN_SE_CO
+from adm.adm_const import ADM_XML_AOB_ELN_SE_AV
 
 # Classes ******************************************************************************************************************************************************
 from adm.adm_classes import AudioProgramme, AudioContent, AudioObject, AudioBlockFormat, AudioPackFormat, AudioProgrammeLabel
 from adm.adm_classes import AudioChannelFormat, AudioTrackFormat, AudioTrackUID, AudioMXFLookUp, AudioStreamFormat
 from adm.adm_classes import Objects, DirectSpeakers, HeadphoneRender, LoudnessMetadata, Dialogue, NonDialogueContentKind, DialogueContentKind, MixedContentKind
 from adm.adm_classes import AudioObjectInteraction, GainInteractionRange, PositionInteractionRange, Zone, ChannelLock, JumpPosition
-from adm.adm_classes import ItemValidationData, Position, Headphone, AudioFormatExtended
+from adm.adm_classes import ItemValidationData, Position, Headphone, AudioFormatExtended, AlternativeValueSet, RolledProgramme
 
 # External system **********************************************************************************************************************************************
 import csv
 import logging
 import xml.etree.cElementTree as ET
 from collections import defaultdict
 import xml.dom.minidom as minidom
@@ -178,14 +181,15 @@
 audio_content_list = []
 audio_object_list = []
 audio_channel_format_list = []
 audio_pack_format_list = []
 audio_block_format_list = []
 audio_track_uid_list = []
 transport_track_format_list = []
+alternative_value_set_list = []
 
 # ************************************************************************************************************************************************************ #
 # ************************************************************************************************************************************************************ #
 
 
 def check_parameter_type(parameter, expected_type, calling_function):
     if type(parameter) is not expected_type:
@@ -240,67 +244,115 @@
         i += 1
     return None
 
 
 def parse_adm_xml(xml_struct, mode):
     global audio_programme_list, audio_content_list, audio_object_list, audio_channel_format_list
     global audio_pack_format_list, audio_block_format, audio_track_uid_list, transport_track_format_list
+    global alternative_value_set_list
 
     # Clear out model lists
     del audio_programme_list[:]
     del audio_content_list[:]
     del audio_object_list[:]
     del audio_channel_format_list[:]
     del audio_pack_format_list[:]
     del audio_block_format_list[:]
     del audio_track_uid_list[:]
     del transport_track_format_list[:]
+    del alternative_value_set_list[:]
 
     tree = None
 
     xml_audio_programme_list = []
     xml_audio_content_list = []
     xml_audio_object_list = []
     xml_audio_channel_format_list = []
     xml_audio_pack_format_list = []
     xml_audio_block_format_list = []
     xml_audio_track_uid_list = []
     xml_transport_track_format_list = []
+    xml_alternative_value_set_list = []
 
     # Is source a blob of XML or an XML file ?
     if mode == ADM_XML_MODE_FILE:
         logging.info('Parsing XML ADM file ') # + xml_struct.name)
         tree = ET.ElementTree(file=xml_struct)
     elif mode == ADM_XML_MODE_STRING:
         logging.info('Parsing XML ADM blob ')
         tree = ET.ElementTree(ET.fromstring(xml_struct))
     tree.getroot()
     root = tree.getroot()
 
     # Find root of metadata, there are two variants with S-ADM, one with and one without coreMetadata in the structure
     sadm_format_root = root.find(ADM_XML_CM)
     if sadm_format_root is not None:
+
         adm_format_root = sadm_format_root.find(ADM_XML_FT)
         adm_format_extended_root = adm_format_root.find(ADM_XML_AF)
     else:
         adm_format_extended_root = root.find(ADM_XML_AF)
 
-    # Get virtual to physical track mapping info
+    sadm_version = None
+    adm_version = None
+    sadm_advss_profile = False
+    adm_advss_profile = False
+
+    # Get S-ADM version
+    if SADM_XML_FRM_AT_VER in root.attrib:
+        sadm_version = root.attrib[SADM_XML_FRM_AT_VER]
+    else:
+        sadm_version = SADM_XML_FRM_AT_VER_OV
+
     sadm_frame_header_root = root.find(SADM_XML_FH)
+    # Get profile info
     if sadm_frame_header_root is not None:
+        sadm_profile_list = sadm_frame_header_root.find('profileList')
+        if sadm_profile_list is not None:
+            sadm_profiles_list = sadm_profile_list.findall('profile')
+            if sadm_profiles_list is not None:
+                # Do we have an AdvSS emission profile entry?
+                for i in range(0, len(sadm_profiles_list)):
+                    if sadm_profiles_list[i].attrib['profileName'] == ADVSS_PROFILE_NAME:
+                        sadm_advss_profile = True
+                        break
+
+        # Get profile info and virtual to physical track mapping info
         sadm_transport_track_format = sadm_frame_header_root.find(SADM_XML_TTF_ELN)
         if sadm_transport_track_format is not None:
             xml_transport_track_format_list = sadm_transport_track_format.findall(SADM_XML_TTF_ELN_SE_AT)
 
+    # Get ADM version, see if there is profile information
     if adm_format_extended_root is not None:
+        if SADM_XML_FRM_AT_VER in adm_format_extended_root.attrib:
+            adm_version = adm_format_extended_root.attrib[SADM_XML_FRM_AT_VER]
+            if adm_version == TARGET_ADM_VER:
+                adm_profile_list = adm_format_extended_root.find('profileList')
+                if adm_profile_list is not None:
+                    adm_profiles_list = adm_profile_list.findall('profile')
+                    if adm_profiles_list is not None:
+                        adm_advss_profile = False
+                        # Do we have an AdvSS emission profile entry?
+                        for i in range(0, len(adm_profiles_list)):
+                            if adm_profiles_list[i].attrib['profileName'] == ADVSS_PROFILE_NAME:
+                                adm_advss_profile = True
+                                break
+        else:
+            adm_version = ADM_XML_FRM_AT_VER_OV
+
+        # Get list of programmes
         xml_audio_programme_list = adm_format_extended_root.findall(ADM_XML_APR_ELN)
     else:
         logging.critical('Failed to find ' + ADM_XML_APR_ELN + ' *** Aborting ***')
         return False
 
+    # Save composition details
+    composition_details = {'sadm_version': sadm_version, 'adm_version': adm_version,
+                           'sadm_advss_profile': sadm_advss_profile, 'adm_advss_profile': adm_advss_profile}
+
     # Check limits for element, abort if content is invalid
     if not get_item_limits(ADM_XML_APR_ELN, len(xml_audio_programme_list)):
         return False
 
     # Populate programmes list from XML source
     if xml_audio_programme_list is not None:
         for i in range(0, len(xml_audio_programme_list)):
@@ -320,33 +372,38 @@
 
             k = xml_audio_programme_list[i].findall(ADM_XML_APR_ELN_SE_CR)
 
             # Check limits for element, abort if content is invalid
             if not get_item_limits(ADM_XML_APR_ELN_SE_CR, len(k)):
                 return False
 
-            if k is not None:
+            if len(k) > 0:
                 for j in range(0, len(k)):
                     audio_programme_list[i].audio_content_idref.append(k[j].text)
             else:
                 logging.debug(MSG_INVALID_STUB + ADM_XML_APR_ELN_SE_CR)
 
             # TODO actually grab loudness metadata and populate
             k = xml_audio_programme_list[i].findall(ADM_XML_APR_ELN_SE_LM)
 
             # Check limits for element, abort if content is invalid
             if not get_item_limits(ADM_XML_APR_ELN_SE_LM, len(k)):
                 return False
 
-            if k is not None:
+            if len(k) > 0:
                 for j in range(0, len(k)):
                     audio_programme_list[i].loudness_metadata = LoudnessMetadata()
             else:
                 logging.debug(MSG_INVALID_STUB + ADM_XML_APR_ELN_SE_LM)
 
+            # Get any alternative values sets
+            k = xml_audio_programme_list[i].findall(ADM_XML_APR_ELN_SE_AV)
+            if len(k) > 0:
+                for j in range(0, len(k)):
+                    audio_programme_list[i].alternative_value_set_idref.append(k[j].text)
     else:
         logging.debug(MSG_INVALID_STUB + ADM_XML_APR_ELN)
 
     # Populate content list from XML source
     xml_audio_content_list = adm_format_extended_root.findall(ADM_XML_ACO_ELN)
 
     # Check limits for element, abort if content is invalid
@@ -444,15 +501,15 @@
 
             # Check limits for element, abort if content is invalid
             if not get_item_limits(ADM_XML_AOB_ELN_SE_GN, len(k)):
                 return False
 
             if k is not None:
                 for j in range(0, len(k)):
-                    audio_object_list[i].gain = k[j].text
+                    audio_object_list[i].gain['gain_value'] = float(k[j].text)
             else:
                 logging.debug(MSG_INVALID_STUB + ADM_XML_AOB_ELN_SE_GN)
 
             # For each object get headlocked
             k = xml_audio_object_list[i].findall(ADM_XML_AOB_ELN_SE_HL)
 
             # Check limits for element, abort if content is invalid
@@ -460,14 +517,38 @@
                 return False
 
             if k is not None:
                 for j in range(0, len(k)):
                     audio_object_list[i].head_locked = k[j].text
             else:
                 logging.debug(MSG_INVALID_STUB + ADM_XML_AOB_ELN_SE_HL)
+
+            # For each object get complementary objects
+            k = xml_audio_object_list[i].findall(ADM_XML_AOB_ELN_SE_CO)
+            if k is not None:
+                for j in range(0, len(k)):
+                    audio_object_list[i].audio_complementary_object_idref.append(k[j].text)
+
+            # For each object get alternative value sets, for now just gain
+            # TODO Add more alternative value parameters
+            k = xml_audio_object_list[i].findall(ADM_XML_AOB_ELN_SE_AV)
+            if k is not None:
+                for j in range(0, len(k)):
+                    audio_object_list[i].alternative_value_set.append(k[j].attrib['alternativeValueSetID'])
+                    a = k[j].find('gain')
+                    if a is not None:
+                        alternative_value_set_list.append(({'alternative_value_set_id': k[j].attrib['alternativeValueSetID'] ,
+                                                            'gain_value': a.text,
+                                                            'gain_unit': a.attrib['gainUnit']}))
+                    a = k[j].find('positionOffset')
+                    if a is not None:
+                        alternative_value_set_list.append(({'alternative_value_set_id': k[j].attrib['alternativeValueSetID'],
+                                                            'offset': a.text,
+                                                            'coordinate': a.attrib['coordinate']}))
+
     else:
         logging.debug(MSG_INVALID_STUB + ADM_XML_AOB_ELN)
 
     # Populate pack format list from XML source
     xml_audio_pack_format_list = adm_format_extended_root.findall(ADM_XML_APF_ELN)
 
     # Check limits for element, abort if content is invalid
@@ -526,32 +607,46 @@
             if not get_item_limits(ADM_XML_ACF_ELN_SE_AB, len(k)):
                 return False
 
             # Currently we assume that there is only one audio block for now as PMD XML does not support dynamic XML timelines
             if k is not None:
                 audio_block_format_list.append(AudioBlockFormat(k[0].attrib[ADM_XML_ACF_ELN_SE_AB_AT_ID]))
                 audio_block_format_list[audio_block_format_counter].position_coord = Position(False)
-                # If we are dealing with a type lable of Object then set teh cartesian flag
                 if type_label == ADM_XML_INT_TYP_OB:
-                    audio_block_format_list[audio_block_format_counter].cartesian = 1
+                    # What coordinate mode is being used
+                    a = k[0].find(ADM_XML_ACF_ELN_SE_AB_SE_CT)
+                    if a is not None:
+                        audio_block_format_list[audio_block_format_counter].cartesian = int(a.text)
+                        audio_block_format_list[audio_block_format_counter].position_coord.is_polar = False
+                    else:
+                        audio_block_format_list[audio_block_format_counter].cartesian = POLAR
+                        audio_block_format_list[audio_block_format_counter].position_coord.is_polar = True
 
                 # Get position coordinates and update
                 m = k[0].findall(ADM_XML_ACF_ELN_SE_AB_SE_PS)
 
                 # Check limits for element, abort if content is invalid
                 if not get_item_limits(ADM_XML_ACF_ELN_SE_AB_SE_PS, len(m)):
                     return False
 
                 for q in range(0, len(m)):
-                    if m[q].attrib[ADM_XML_ACF_ELN_SE_AB_SE_PS_AT_CO] == ADM_XML_ACF_ELN_SE_AB_SE_PS_AT_XC:
-                        audio_block_format_list[audio_block_format_counter].position_coord.x_or_az = m[q].text
-                    if m[q].attrib[ADM_XML_ACF_ELN_SE_AB_SE_PS_AT_CO] == ADM_XML_ACF_ELN_SE_AB_SE_PS_AT_YC:
-                        audio_block_format_list[audio_block_format_counter].position_coord.y_or_el = m[q].text
-                    if m[q].attrib[ADM_XML_ACF_ELN_SE_AB_SE_PS_AT_CO] == ADM_XML_ACF_ELN_SE_AB_SE_PS_AT_ZC:
-                        audio_block_format_list[audio_block_format_counter].position_coord.z_or_ds = m[q].text
+                    if audio_block_format_list[audio_block_format_counter].cartesian == POLAR:
+                        if m[q].attrib[ADM_XML_ACF_ELN_SE_AB_SE_PS_AT_CO] == 'azimuth':
+                            audio_block_format_list[audio_block_format_counter].position_coord.x_or_az = m[q].text
+                        elif m[q].attrib[ADM_XML_ACF_ELN_SE_AB_SE_PS_AT_CO] == 'elevation':
+                            audio_block_format_list[audio_block_format_counter].position_coord.y_or_el = m[q].text
+                        elif m[q].attrib[ADM_XML_ACF_ELN_SE_AB_SE_PS_AT_CO] == 'distance':
+                            audio_block_format_list[audio_block_format_counter].position_coord.z_or_ds = m[q].text
+                    elif audio_block_format_list[audio_block_format_counter].cartesian == CARTESIAN:
+                        if m[q].attrib[ADM_XML_ACF_ELN_SE_AB_SE_PS_AT_CO] == ADM_XML_ACF_ELN_SE_AB_SE_PS_AT_XC:
+                            audio_block_format_list[audio_block_format_counter].position_coord.x_or_az = m[q].text
+                        elif m[q].attrib[ADM_XML_ACF_ELN_SE_AB_SE_PS_AT_CO] == ADM_XML_ACF_ELN_SE_AB_SE_PS_AT_YC:
+                            audio_block_format_list[audio_block_format_counter].position_coord.y_or_el = m[q].text
+                        elif m[q].attrib[ADM_XML_ACF_ELN_SE_AB_SE_PS_AT_CO] == ADM_XML_ACF_ELN_SE_AB_SE_PS_AT_ZC:
+                            audio_block_format_list[audio_block_format_counter].position_coord.z_or_ds = m[q].text
 
                 # Get speaker label and update
                 m = k[0].find(ADM_XML_ACF_ELN_SE_AB_SE_SL)
                 if m is not None:
                     audio_block_format_list[audio_block_format_counter].speaker_label = m.text
                     logging.info(MSG_FND_EL + ADM_XML_ACF_ELN_SE_AB_SE_SL + ' ' + m.text)
 
@@ -608,28 +703,60 @@
             else:
                 logging.critical(ADM_XML_ATU_ELN + MSG_FND_NO + ADM_XML_ATU_ELN_SE_PF)
                 return False
 
     else:
         logging.debug(MSG_INVALID_STUB + ADM_XML_ACF_ELN)
 
+    # Does composition contain audio programmes that reference complementary group leaders
+    programme_has_complementary_leader = []
+
+    for i in range(0, len(audio_programme_list)):
+        for j in range(0, len(audio_programme_list[i].audio_content_idref)):
+            audio_content_idref = audio_programme_list[i].audio_content_idref[j]
+            # Get referenced audio object and see if it contains complementary object references
+            for k in range(0, len(audio_content_list)):
+                if audio_content_idref == audio_content_list[k].id:
+                    for m in range(0, len(audio_content_list[k].audio_object_idref)):
+                        audio_object_idref = audio_content_list[k].audio_object_idref[m]
+                        for n in range(0, len(audio_object_list)):
+                            if audio_object_idref == audio_object_list[n].id:
+                                a = len(audio_object_list[n].audio_complementary_object_idref)
+                                if a > 0:
+                                    programme_has_complementary_leader.\
+                                        append({'audio_programme_id': audio_programme_list[i].id,
+                                                'object_group_leader': audio_object_list[n].id})
+
+    # Get list of objects that are complementary to the group leader
+    object_group_leader_info = []
+    for i in range(0, len(programme_has_complementary_leader)):
+        for j in range(0, len(audio_object_list)):
+            if programme_has_complementary_leader[i]['object_group_leader'] == audio_object_list[j].id:
+                object_group_leader_info.append({'audio_programme_id': programme_has_complementary_leader[i]['audio_programme_id'],
+                                                'object_group_leader': audio_object_list[j].id,
+                                                'complementary_objects': audio_object_list[j].audio_complementary_object_idref})
+
     # Populate the final model
     mdl_audio_programmes = []
     mdl_audio_content = []
     mdl_audio_object = []
     mdl_audio_pack_fmt = []
     mdl_audio_channel_fmt = []
     mdl_audio_block_fmt = []
     mdl_audio_track_uid = []
 
+    # TODO audio pack ref in object for common defs, insert common def bed into audio channel format
     # Start populating audio programmes
     for i in range(0, len(audio_programme_list)):
         mdl_audio_programmes.append(AudioProgramme(audio_programme_list[i].name, audio_programme_list[i].language, audio_programme_list[i].id))
         mdl_audio_programmes[i].loudness_metadata = audio_programme_list[i].loudness_metadata
         mdl_audio_programmes[i].audio_programme_label = audio_programme_list[i].audio_programme_label
+        for j in range(0, len(object_group_leader_info)):
+            if mdl_audio_programmes[i].id == object_group_leader_info[j]['audio_programme_id']:
+                mdl_audio_programmes[i].needs_unrolling = True
 
     # Start populating audio content
     for i in range(0, len(audio_content_list)):
         mdl_audio_content.append(AudioContent(audio_content_list[i].id, audio_content_list[i].name))
         mdl_audio_content[i].dialogue = audio_content_list[i].dialogue
 
     # Start populating audio object
@@ -668,30 +795,34 @@
                 mdl_audio_track_uid[i].pack_format_id = mdl_audio_pack_fmt[j]
                 break
 
         for j in range(0, len(xml_transport_track_format_list)):
             q = xml_transport_track_format_list[j].findall(SADM_XML_TTF_ELN_SE_AT_SE_AR)
             if q is not None:
                 for k in range(0, len(q)):
-                    if q[k].text == audio_track_uid_list[i].id:
+                    if q[k].text.lower() == audio_track_uid_list[i].id.lower():
                         mdl_audio_track_uid[i].track_id = xml_transport_track_format_list[j].attrib[SADM_XML_TTF_ELN_SE_AT_AT_TI]
                         break
 
     # Update audio object with gain, audio_pack_idref, audio_track_uidref
     for i in range(0, len(mdl_audio_object)):
         # gain
         for j in range(0, len(audio_object_list)):
             if mdl_audio_object[i].id == audio_object_list[j].id:
-                mdl_audio_object[i].gain = audio_object_list[j].gain
+                mdl_audio_object[i].gain['gain_value'] = audio_object_list[j].gain['gain_value']
                 break
 
         # Audio pack
         for j in range(0, len(audio_object_list)):
             if mdl_audio_object[i].id == audio_object_list[j].id:
-                mdl_audio_object[i].audio_pack_idref.append(find_list_reference_by_id(mdl_audio_pack_fmt, audio_object_list[j].audio_pack_idref[0]))
+                # TODO Proper common definitions
+                if int(audio_object_list[j].audio_pack_idref[0][7:8]) == 0:
+                    mdl_audio_object[i].audio_pack_idref = audio_object_list[j].audio_pack_idref[0]
+                else:
+                    mdl_audio_object[i].audio_pack_idref.append(find_list_reference_by_id(mdl_audio_pack_fmt, audio_object_list[j].audio_pack_idref[0]))
                 break
 
         # Audio tracks
         for j in range(0, len(audio_object_list)):
             if mdl_audio_object[i].id == audio_object_list[j].id:
                 for k in range(0, len(audio_object_list[j].audio_track_idref)):
                     mdl_audio_object[i].audio_track_idref.append(find_list_reference_by_id(mdl_audio_track_uid, audio_object_list[j].audio_track_idref[k]))
@@ -709,26 +840,55 @@
     for i in range(0, len(mdl_audio_programmes)):
         for j in range(0, len(audio_programme_list)):
             if mdl_audio_programmes[i].id == audio_programme_list[j].id:
                 for k in range(0, len(audio_programme_list[j].audio_content_idref)):
                     z = find_list_reference_by_id(mdl_audio_content, audio_programme_list[j].audio_content_idref[k])
                     mdl_audio_programmes[i].audio_content_idref.append(z)
                 break
+    # Update audio programmes with alternative value sets
+    for i in range(0, len(mdl_audio_programmes)):
+        for j in range(0, len(audio_programme_list)):
+            if mdl_audio_programmes[i].id == audio_programme_list[j].id:
+
+                for k in range(0, len(audio_programme_list[j].alternative_value_set_idref)):
+                    mdl_audio_programmes[i].alternative_value_set_idref.append(audio_programme_list[j].alternative_value_set_idref[k])
+
+    # Update audio objects that are complimentary group leaders
+    for i in range(0, len(mdl_audio_object)):
+        for j in range(0, len(object_group_leader_info)):
+            if mdl_audio_object[i].id == object_group_leader_info[j]['object_group_leader']:
+                #mdl_audio_object[i].audio_complementary_object_idref = object_group_leader_info[j]['complementary_objects']
+                for k in range(0, len(object_group_leader_info[j]['complementary_objects'])):
+                    #b = find_list_reference_by_id(mdl_audio_object, object_group_leader_info[j]['complementary_objects'][k])
+                    if find_list_reference_by_id(mdl_audio_object, object_group_leader_info[j]['complementary_objects']
+                    [k]) not in mdl_audio_object[i].audio_complementary_object_idref:
+                        mdl_audio_object[i].audio_complementary_object_idref.append\
+                            (find_list_reference_by_id(mdl_audio_object,object_group_leader_info[j]['complementary_objects'][k]))
+
+    # Update audio objects that contain alternative value sets
+    for i in range(0, len(mdl_audio_object)):
+        for j in range(0, len(alternative_value_set_list)):
+            a = mdl_audio_object[i].id[3:]
+            b = alternative_value_set_list[j]['alternative_value_set_id'][4:8]
+            if a == b:
+                mdl_audio_object[i].alternative_value_set.append(alternative_value_set_list[j])
 
     # Package all the data together into a audio format extended container
     a = AudioFormatExtended()
+    a.composition_details = composition_details
     a.audio_programme = mdl_audio_programmes
     a.audio_content = mdl_audio_content
     a.audio_object = mdl_audio_object
     a.audio_pack_format = mdl_audio_pack_fmt
     a.audio_channel_format = mdl_audio_channel_fmt
     a.audio_track_uid = mdl_audio_track_uid
 
     return a
 
+
 def get_item_limits(item_name, number_found):
 
     # TODO This is slow
     return True
 
     minval = None
     maxval = None
@@ -781,16 +941,19 @@
 
         # tracemalloc.start()
  
         loop_counter = 1
         startsecs = time.time()
         
         for i in range(0, loop_counter):
-            my_metadata = parse_adm_xml("skip_sadm.xml", ADM_XML_MODE_FILE)
-            #my_metadata = parse_adm_xml("gen.adm_+_gen.sadm.xml", ADM_XML_MODE_FILE)
+            #my_metadata = parse_adm_xml("skip.sadm.advss.xml", ADM_XML_MODE_FILE)
+            #my_metadata = parse_adm_xml("dtm_axml_v2_sadm.xml", ADM_XML_MODE_FILE)
+            #my_metadata = parse_adm_xml("eac_axml_v2_sadm.xml", ADM_XML_MODE_FILE)
+            #my_metadata = parse_adm_xml("skip.sadm.emission.profile.compliant_v2.xml", ADM_XML_MODE_FILE)
+            my_metadata = parse_adm_xml("complimentary_objects_v2.xml", ADM_XML_MODE_FILE)
 
         endsecs = time.time()
         call_time = (endsecs - startsecs) / loop_counter
         print('Runtime = ' + str(endsecs - startsecs))
         print ('Call time = ' + str(call_time))        
 
         """
```

## am_viewer/am_viewer.py

```diff
@@ -67,15 +67,17 @@
 from pmd.pmd_const import OBJECT_CLASSES
 from am_viewer.am_xml_viewer import XML_Viewer
 from am_viewer.am_xml_viewer import isFilePmd
 from am_viewer.am_xml_viewer import isFileSADM
 import aoip_services.aoip_discovery
 import aoip_services.multicast
 
-__version__ = "3.9"
+from scapy.all import conf
+
+__version__ = "4.00"
 
 class AudioObjectHeadings:
     TYPE = 0
     NAME = 1
     DIVERGE = 2
     CH = 3
     GAIN = 4
@@ -372,43 +374,96 @@
     subprocess.run(args)
     if not os.path.exists("pmd.xml"):
         print("KLV to XML conversion failed. PMD is probably corrupted", file=sys.stderr)
         return False
     return True
 
 
-def get_sadm_xml(frame):
+def get_2127hdr_sadm_xml(frame):
+
+    # -41 defragmentation is complete.
+    # Now remove -2127 header performing appropriate checks and
+    # checking to see if decompression is required
+    byte_count = 0
+    # Extract fields in Table 1 of SMPTE ST 2127-1
+    identifier = frame.payloads[0][byte_count]
+    byte_count += 1
+    # Reject if identifier is wrong or too small for a 1 byte payload
+    if not identifier == 2 or len(frame.payloads[0]) < 11:
+        return None
+    # length from Table 1 of SMPTE ST 2127-1
+    length1 = int.from_bytes(frame.payloads[0][byte_count:byte_count+4], 'big', signed=False)
+    # shorten payload by length and shave any excess,
+    frame.payloads[0] = frame.payloads[0][0:length1 + 5]
+    byte_count += 4
+    payload_tag = frame.payloads[0][byte_count]
+    byte_count += 1
+    if not payload_tag == 0x12: # payload tag value from SMPTE ST 2127-10 Table 1
+        return None
+    length2 = frame.payloads[0][byte_count] & 0x7f
+    length2_size = 1
+    if frame.payloads[0][byte_count] & 0x80 == 0x80:
+        length2_size = 1 + length2
+        length2 = int.from_bytes(frame.payloads[0][byte_count+1:(byte_count+length2_size)], 'big', signed=False)
+    # shorten payload by length and shave any excess
+    # add 2 because length doesn not include version or format
+    frame.payloads[0] = frame.payloads[0][0:byte_count + 2 + length2_size + length2]
+    byte_count += length2_size
+    version = frame.payloads[0][byte_count]
+    if not version == 0:
+        return None # unknown version
+    byte_count += 1
+    format = frame.payloads[0][byte_count]
+    if format > 1:
+        return None # unknown format
+    byte_count += 1
+    if format == 1:
+        gzip_data = frame.payloads[0][byte_count:]
+        try:
+            adm_xml = zlib.decompress(gzip_data, 15 + 32)
+        except:
+            adm_xml = None
+    else:
+        adm_xml = frame.payloads[0][byte_count:]
+    return adm_xml
+
+def get_2116hdr_sadm_xml(frame):
     index = 0
     if frame.sADM_assemble_flag == 1:
         assemble_info = get_word(frame.payloads[0], index, frame.bit_depth)
         in_timeline_flag = (assemble_info >> 4) & 0x3
         # Only support full frame mode so this must be 0
         if (in_timeline_flag != 0):
-            return(None)
+            return None
         #Commenting the next two elements out for speed as they are ignored
         #track_numbers = (assemble_info >> 6) & 0x3f
         #track_ID = (assemble_info >> 12) & 0x3f
-        index = index + 3
+        index = index + math.ceil(frame.bit_depth / 8)
     if frame.sADM_format_flag == 1:
         format_info = get_word(frame.payloads[0], index, frame.bit_depth)
         format_type = format_info >> (frame.bit_depth - 16) & 0xf
-        index = index + 3
+        index = index + math.ceil(frame.bit_depth / 8)
     else:
         format_type = 0
     if format_type == 1:
         if frame.bit_depth == 20:
             gzip_data = pack_20bits(frame.payloads[0][index:])
         else:
             gzip_data = frame.payloads[0][index:]
         try:
             adm_xml = zlib.decompress(gzip_data, 15 + 32)
         except:
             adm_xml = None
     else:
         adm_xml = frame.payloads[0][index:]
+        # Strip trailing zeros that might exist to round out to whole sample
+        #
+        while len(adm_xml) > 0 and adm_xml[-1] == 0:
+            adm_xml = adm_xml[:-1]
+
     return adm_xml
 
 class State:
     IDLE = 16
     GOT_LEFT_BLANKING = 32
     GOT_RIGHT_BLANKING = 64
     GOT_FRAME_MODE_BLANKING = 128
@@ -438,23 +493,25 @@
 
     zero_threshold = 350
     intraframe_zero_threshold = 160
 
     class NewFrame:
         payloads = []
         format = None
+        container = None
         bit_depth = None
         subframe_mode = None
         right_not_left = None
         sADM_assemble_flag = None
         sADM_format_flag = None
 
         def __init__(self):
             self.payloads = []
             self.format = None
+            self.container = None
             self.bit_depth = None
             self.subframe_mode = None
             self.right_not_left = None
             self.sADM_assemble_flag = None
             self.sADM_format_flag = None
 
         def is_sADM(self):
@@ -465,16 +522,22 @@
 
         def is_pmd(self):
             if self.format == "PMD":
                 return True
             else:
                 return False
 
-        def is_AESX242(self):
-            if self.format == "AESX242":
+        def is_SMPTE2110_31(self):
+            if self.container == "AM824":
+                return True
+            else:
+                return False
+
+        def is_SMPTE2110_41(self):
+            if self.container == "ST2110-41":
                 return True
             else:
                 return False
 
         def get_sADM_assemble_flag(self):
             return self.sADM_assemble_flag
 
@@ -543,37 +606,85 @@
             return True
         else:
             self.bit_depth = 0
             return False
 
     def receivePacket(self, packet, codec):
         if codec == "AM824":
-            self.receiveSMPTEPacket(packet)
-        elif codec == "smpte336m":
-            self.receiveAESX242Packet(packet)
+            self.receive337Packet(packet)
+        elif codec == "ST2110-41":
+            self.receive2110_41Packet(packet)
         else:
             raise("Unknown format")
 
-    def receiveAESX242Packet(self, packet):
+    def receive2110_41Packet(self, packet):
         packet["UDP"].payload = scapy.RTP(packet["Raw"].load)
         # detect marker bit to see if this is the first packet of the KLVunit
-        if packet["RTP"].marker:
-            # See if we already have a payload, if so then we can process it
-            if len(self.payloads) > 0:
+
+        payload = bytes(packet["RTP"].payload)
+        # check we have enough bytes to check -41 header
+        if len(payload) < 8:
+            # if then discard
+            return
+        data_item_type = int.from_bytes(payload[0:4], byteorder='big')
+        data_item_type = data_item_type >> 10
+        data_item_length_words = int.from_bytes(payload[2:4], byteorder='big') & 0x1ff
+        data_item_length_bytes = data_item_length_words * 4
+        last_packet = ((int.from_bytes(payload[2:3], byteorder='big') & 0x2) >> 1) == 1
+        segment_data_offset = int.from_bytes(payload[4:8], byteorder='big')
+        first_packet = (segment_data_offset == 0)
+
+        # check we have a recognizable DIT i.e. sADM or PMD
+        if (data_item_type != 0x3ff000) and (data_item_type != 0x3ff001):
+            # if not then discard
+            return
+
+        # check to see if payload is big enough according to signaled length
+        if len(payload) < (data_item_length_bytes + 8):
+            # if not then shorten length
+            data_item_length_bytes = len(payload) - 8
+        if first_packet:
+            # Strip 2110-41 header
+            self.length_bytes = 0
+        new_payloads = bytearray(self.payloads)
+        new_payloads[(4 * segment_data_offset):(segment_data_offset * 4) + data_item_length_bytes] = bytearray(payload[8: 8 + data_item_length_bytes])
+        self.payloads = bytes(new_payloads)
+        self.length_bytes = self.length_bytes + data_item_length_bytes
+        if last_packet:
+            # last packet
+            # only sADM supported
+            if data_item_type == 0x3ff000:
+                format = "SADM"
+            else:
+                # unknown frame format
+                # this is theoretically unreachable unless DIT is corrupted
+                # This is assuming only fed by PMD Studio application at https://github.com/DolbyLaboratories/pmd_tool
+                format = "UNKNOWN"
+
+            if (format == "SADM") and (self.length_bytes == len(self.payloads)):
+                # always include assemble and format words in -41
                 next_frame = self.NewFrame()
-                next_frame.bit_depth = 24 # no unpacking required
-                next_frame.format = "AESX242"
+                next_frame.sADM_assemble_flag = 1
+                next_frame.sADM_format_flag = 1
+                next_frame.bit_depth = 16
+                next_frame.format = format
                 next_frame.payloads = [self.payloads]
+                next_frame.container = "ST2110-41"
+                next_frame.subframe_mode = None
                 self.new_frames.append(next_frame)
-            self.payloads = bytes(packet["RTP"].payload)
-        else:
-            self.payloads = self.payloads + bytes(packet["RTP"].payload)
+            else:
+                # Add PMD support here
+                # discard for now as not supported
+                # or incomplete
+                self.payloads = b''
+                self.length_bytes = 0
+
 
     # Receive raw packets as they are received
-    def receiveSMPTEPacket(self, packet):
+    def receive337Packet(self, packet):
 
         # Force packet to be interpreted as RTP
         packet["UDP"].payload = scapy.RTP(packet["Raw"].load)
         packet_payload = bytes(packet["RTP"].payload)
         right_not_left = True
         if self.last_sequnce_no is None:
             self.last_sequnce_no = packet["RTP"].sequence
@@ -692,14 +803,15 @@
                     # If subframe mode then we need twice as many samples to hold frame
                     if self.data_type == 27:
                         self.next_frame.format = "PMD"
                     if self.data_type == 32:
                         self.next_frame.format = "SADM"
                         self.next_frame.sADM_assemble_flag = (Pc >> (self.next_frame.bit_depth - 7)) & 0x1
                         self.next_frame.sADM_format_flag = (Pc >> (self.next_frame.bit_depth - 6)) & 0x1
+                    self.next_frame.container = "AM824"
                     # adjust for Pe & Pf
                     #if self.data_type > 30:
                         # adjust for Pe and Pf
                     #    self.length20 = self.length20 - 5
                     #    self.length24 = self.length24 - 6
                     self.state = State.GOT_HEADER
                     if (not (self.next_frame.is_pmd())) and (not (self.next_frame.is_sADM())):
@@ -767,15 +879,14 @@
     audioList = []
     audioNameList = []
     selectedService = None
     audioService = None
     XMLViewerRequest = False
     discoveryService = None
     start_time = 0
-    numCapturePackets = 42
     debug = False
     messageQueue = None
     multicast = None
     playbackPres = None
     playbackPresVar = None
     model = None
     audioPipeLine = None
@@ -794,39 +905,43 @@
                      "Format not recognized",
                      "Recognized file as PMD but parsing failed",
                      "Recognized file as ADM but parsing failed"]
 
     class Indicators:
         pmd = "gray"
         sadm = "gray"
-        aesx242 = "gray"
+        smpte2110_31 = "gray"
+        smpte2110_41 = "gray"
         frame = "gray"
         subframe = "gray"
         depth20 = "gray"
         depth24 = "gray"
         pmdInd = None
         sadmInd = None
         FrameInd = None
         SubFrameInd = None
         depth20Ind = None
         depth24Ind = None
         pmdIndVar = None
         sadmIndVar = None
-        aesx242IndVar = None
+        smpte2110_31IndVar = None
+        smpte2110_41IndVar = None
         gui = None
         indFrame = None
 
         def __init__(self, gui, indFrame):
             self.indFrame = indFrame
             self.pmdInd = Label(self.indFrame, text='PMD', variable=self.pmdIndVar, fg='black')
             self.pmdInd.pack(side=LEFT)
-            self.sadmInd = Label(self.indFrame, text='sADM', variable=self.sadmIndVar, fg='black')
+            self.sadmInd = Label(self.indFrame, text='S-ADM', variable=self.sadmIndVar, fg='black')
             self.sadmInd.pack(side=LEFT)
-            self.aesx242Ind = Label(self.indFrame, text='AES-X242', variable=self.aesx242IndVar, fg='black')
-            self.aesx242Ind.pack(side=LEFT)
+            self.smpte2110_31Ind = Label(self.indFrame, text='SMPTE2110-31', variable=self.smpte2110_31IndVar, fg='black')
+            self.smpte2110_31Ind.pack(side=LEFT)
+            self.smpte2110_41Ind = Label(self.indFrame, text='SMPTE2110-41', variable=self.smpte2110_41IndVar, fg='black')
+            self.smpte2110_41Ind.pack(side=LEFT)
 
             self.FrameInd = Label(self.indFrame, text='Frame', fg='black')
             self.FrameInd.pack(side=LEFT)
             self.SubFrameInd = Label(self.indFrame, text='Subframe', fg='black')
             self.SubFrameInd.pack(side=LEFT)
 
             self.depth20Ind = Label(self.indFrame, text='20 bit', fg='black')
@@ -835,80 +950,94 @@
             self.depth24Ind.pack(side=LEFT)
 
             self.gui = gui
 
         def reset(self):
             self.pmd = "gray"
             self.sadm = "gray"
-            self.aesx242 = "gray"
+            self.smpte2110_31 = "gray"
+            self.smpte2110_41 = "gray"
             self.frame = "gray"
             self.subframe = "gray"
             self.depth20 = "gray"
             self.depth24 = "gray"
             self.gui.post("updateInd", None)
 
         def update(self):
             self.pmdInd.config(bg=self.pmd)
             self.sadmInd.config(bg=self.sadm)
-            self.aesx242Ind.config(bg=self.aesx242)
+            self.smpte2110_31Ind.config(bg=self.smpte2110_31)
+            self.smpte2110_41Ind.config(bg=self.smpte2110_41)
             self.FrameInd.config(bg=self.frame)
             self.SubFrameInd.config(bg=self.subframe)
             self.depth20Ind.config(bg=self.depth20)
             self.depth24Ind.config(bg=self.depth24)
 
         def rxMetadata(self):
-            return self.pmd =="light green" or self.sadm =="light green" or self.aesx242 =="light green"
+            return self.pmd =="light green" or self.sadm =="light green" or self.smpte2110_41 =="light green"
 
         def pmdOn(self):
             if not self.pmd == "light green":
                 self.pmd = "light green"
                 self.sadm = "gray"
-                self.aesx242 = "gray"
                 self.gui.post("updateInd", None)
 
         def pmdError(self):
             if not self.pmd == "red":
                 self.pmd = "red"
                 self.sadm = "gray"
-                self.aesx242 = "gray"
                 self.gui.post("updateInd", None)
 
         def sadmOn(self):
             if not self.sadm == "light green":
                 self.sadm = "light green"
                 self.pmd = "gray"
-                self.aesx242 = "gray"
                 self.gui.post("updateInd", None)
 
         def sadmError(self):
             if not self.sadm == "red":
                 self.sadm = "red"
                 self.pmd = "gray"
-                self.aesx242 = "gray"
+                self.smpte2110_41 = "gray"
+                self.gui.post("updateInd", None)
+
+        def smpte2110_31On(self):
+            if not self.smpte2110_31 == "light green":
+                self.smpte2110_31 = "light green"
+                self.smpte2110_41 = "gray"
+                self.frame = "gray"
+                self.subframe = "gray"
                 self.gui.post("updateInd", None)
 
-        def aesx242On(self):
-            if not self.aesx242 == "light green":
-                self.aesx242 = "light green"
+        def smpte2110_31Error(self):
+            if not self.smpte2110_31 == "red":
+                self.smpte2110_31 = "red"
                 self.pmd = "gray"
                 self.sadm = "gray"
                 self.frame = "gray"
                 self.subframe = "gray"
                 self.gui.post("updateInd", None)
 
-        def aesx242Error(self):
-            if not self.aesx242 == "red":
-                self.aesx242 = "red"
+        def smpte2110_41On(self):
+            if not self.smpte2110_41 == "light green":
+                self.smpte2110_41 = "light green"
+                self.smpte2110_31 = "gray"
+                self.frame = "gray"
+                self.subframe = "gray"
+                self.gui.post("updateInd", None)
+
+        def smpte2110_41Error(self):
+            if not self.smpte2110_41 == "red":
+                self.smpte2110_41 = "red"
                 self.pmd = "gray"
                 self.sadm = "gray"
                 self.frame = "gray"
                 self.subframe = "gray"
                 self.gui.post("updateInd", None)
 
-
         def frameMode(self):
             if not self.frame == "light green":
                 self.frame = "light green"
                 self.subframe = "gray"
                 self.gui.post("updateInd", None)
 
         def subFrameMode(self):
@@ -936,14 +1065,32 @@
         self.debug = debug_mode
 
         self.indFrame = Frame(master, relief=self.frameRelief, borderwidth=self.frameBorderwidth)
         self.indFrame.pack(fill=BOTH, expand=True)
 
         self.indicators = self.Indicators(self, self.indFrame)
 
+        self.infoFrame = Frame(master, relief= self.frameRelief, borderwidth=self.frameBorderwidth)
+        self.infoFrame.pack(fill=X)
+
+        sadm_version_label = Label(self.infoFrame, text="S-ADM Version")
+        sadm_version_label.pack(side=LEFT)
+        self.sadmVersion = Label(self.infoFrame, text="          ", relief=SUNKEN, bg='#B3B4C8')
+        self.sadmVersion.pack(side=LEFT)
+
+        adm_version_label = Label(self.infoFrame, text="ADM Version")
+        adm_version_label.pack(side=LEFT)
+        self.admVersion = Label(self.infoFrame, text="           ", relief=SUNKEN, bg='#B3B4C8')
+        self.admVersion.pack(side=LEFT)
+
+        adm_profile_label = Label(self.infoFrame, text="ADM Profile")
+        adm_profile_label.pack(side=LEFT)
+        self.admProfile = Label(self.infoFrame, text="           ", relief=SUNKEN, bg='#B3B4C8')
+        self.admProfile.pack(side=LEFT)
+
         audio_beds_label = Label(master, text="Audio Beds")
         audio_beds_label.pack(fill=X)
 
         self.abFrame = Frame(master, relief= self.frameRelief, borderwidth=self.frameBorderwidth)
         self.abFrame.pack(fill=BOTH, expand=True)
 
         abLabels = [ "Source", "Config", "Name", "Gain(dB)", "Start", "End" ]
@@ -1050,26 +1197,29 @@
                     if self.debug:
                         traceback.print_exc(file=sys.stdout)
                     self.exitCode = self.ErrorCodes.ERR_BAD_PMD
                     self.quit()
                     return
             elif isFileSADM(xml_file):
                 try:
-                    self.model = populate_model_from_adm(xml_file, ADM_XML_MODE_FILE)
+                    a = populate_model_from_adm(xml_file, ADM_XML_MODE_FILE)
+                    self.model = a.audio_model
+                    self.update_adm_info(a.adm_info)
                 except:
                     if self.debug:
                         traceback.print_exc(file=sys.stdout)
                     self.exitCode = self.ErrorCodes.ERR_BAD_SADM
                     self.quit()
                     return
             else:
                     self.exitCode = self.ErrorCodes.ERR_FORMAT_NOT_RECOGNIZED
                     self.quit()
                     return               
             self.updateFromModel(self.model)
+
         else:
             # Create Drop down for IP Interfaces
             if platform.system() == 'Windows':
                 fullIfListNames = [x['name'] for x in scapy.get_windows_if_list()]
                 fullIfListGuids = [x['guid'] for x in scapy.get_windows_if_list()]
 #				#full_ifList = netifaces.interfaces()
             else:
@@ -1134,14 +1284,22 @@
         	if e.errno == errno.ENOENT:
         		self.haveGstreamer = False
         	else:
         		# Something else went wrong while trying to check for gstreamer
         		raise
         		self.haveGstreamer = False
 
+    def update_adm_info(self, adm_info):
+        self.sadmVersion.configure(text=adm_info["sadm_version"])
+        self.admVersion.configure(text=adm_info["adm_version"])
+        if (adm_info["sadm_advss_profile"]):
+            self.admProfile.configure(text="ITU-R AdvSS")
+        else:
+            self.admProfile.configure(text="Unknown")
+
     def post(self, command, data):
         # If the packet processor is running faster than the UI background task
         # then UI updates are dropped
         # This avoids the UI lagging behind and a memory leak with an ever increasing queue of models
         if self.messageQueue is not None:
             if self.messageQueue.qsize() < 5 or command != "updateModel":
                 self.messageQueue.put([command,data])
@@ -1247,15 +1405,15 @@
         launchstr = launchstr + '! audioconvert mix-matrix="<<'
         for outchan in [0, 1]:
             for inchan in range(self.audioService.sdp.channels):
                 launchstr = launchstr + '(float)' + str(self.mixMatrix[outchan][inchan]) + ', '
             launchstr = launchstr.rstrip(', ')
             launchstr = launchstr + '>, <'
         launchstr = launchstr.rstrip('>, <')
-        launchstr = launchstr + '>>" ! playsink volume = 5 channels = 2'
+        launchstr = launchstr + '>>" ! playsink volume = 5'
         #launchstr = 'udpsrc address=239.150.138.1 port=5004 buffer-size=1000000 caps="application/x-rtp, media=(string)audio, clock-rate=(int)48000, channels = 9, encoding-name=(string)L16" ! rtpL16depay ! audio/x-raw,channels=9,channel-mask=(bitmask)0x000000000000 ! audioconvert mix-matrix="<<(float)1.0, (float)0.0, (float)1.0, (float)0.0, (float)1.0, (float)0.0, (float)1.0, (float)0.0, (float)0.0>, <(float)0.0, (float)1.0, (float)1.0, (float)0.0, (float)0.0, (float)1.0, (float)1.0, (float)0.0, (float)0.0>>" ! playsink volume = 5 channels = 2'
         return(launchstr)
 
     def start_playback(self):
         # Create mixing matrix by first adding in beds
         # Check that beds do not exceed total number of audio channels
         # Create empty mixing matrix
@@ -1349,18 +1507,19 @@
                     launchstr = self.get_launch_str()
                     self.launch_pipeline(launchstr)
 
         # Indicate that playback started successfully
         return True
 
     def launch_pipeline(self, launchstr):
-        args = ['gst-launch-1.0', '-q']
+        args = ['gst-launch-1.0']
         args = args + launchstr.split()
         shellState = (platform.system() == "Windows")
-        newAudioPipeLine = subprocess.Popen(args, shell=shellState, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
+        print(" ".join(args))
+        newAudioPipeLine = subprocess.Popen(args, shell=shellState) # , stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
         if self.audioPipeLine is not None:
             self.stop_playback()
         self.audioPipeLine = newAudioPipeLine
 
     def playing(self):
         return self.audioPipeLine is not None
 
@@ -1370,14 +1529,20 @@
                 subprocess.call(['taskkill', '/F', '/T', '/PID', str(self.audioPipeLine.pid)], stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
             else:
                 os.kill(self.audioPipeLine.pid, signal.SIGSTOP)
                 os.kill(self.audioPipeLine.pid, signal.SIGKILL)
         self.audioPipeLine = None
 
     def reset_ui(self):
+
+        # Reset Text fields
+        self.sadmVersion.configure(text="          ")
+        self.admVersion.configure(text="           ")
+        self.admProfile.configure(text="           ")
+
         # Reset lights
         self.indicators.reset()
 
         # Reset Metadata display
 
         for ununsedBeds in range(0,self.numBeds):
                 self.bedFields[ununsedBeds][AudioBedHeadings.SOURCE].configure(text="")
@@ -1538,36 +1703,35 @@
             self.presFields[unusedPresentations][PresentationHeadings.TARGET_CFG].configure(text="")
             self.presFields[unusedPresentations][PresentationHeadings.PRES_LANG].configure(text="")
             self.presFields[unusedPresentations][PresentationHeadings.BED_ELEMENT].configure(text="")
 
             for i in range(0, self.numObjects):
                 self.oeVars[unusedPresentations][i].set(0)
 
+    def updateFromAdmModel(self, admModelObject):
+        self.updateFromModel(admModelObject.audio_model)
+        self.update_adm_info(admModelObject.adm_info)
+
     def processNextMessage(self, master):
         if self.messageWaiting():
             [command,messageData] = self.getMessage()
             if command == "newService":
                 newService = messageData
-                if newService.sdp.isAM824() or newService.sdp.isAESX242():
+                if newService.sdp.isAM824() or newService.sdp.is2110_41():
                     if self.debug:
                         print("Found ", newService.system, " Service ", newService.name)
                     self.serviceList.append(newService)
                     self.serviceNameList.append(newService.system + ':' + newService.name)
                     # Check if this is the first service, if so display it
                     if len(self.serviceNameList) == 1:
                         self.serviceSelection.set(self.serviceNameList[0])
                     # Now update GUI menu
                     self.serviceMenu['menu'].delete(0, 'end')
                     for service in self.serviceNameList:
                         self.serviceMenu['menu'].add_command(label=service, command=lambda value=service: self.serviceSelection.set(value))
-                    # Set capture period according to received service type
-                    if newService.sdp.isAESX242():
-                        self.numCapturePackets = 1
-                    else:
-                        self.numCapturePackets = 42
                 elif newService.sdp.isAES67():
                     self.audioList.append(newService)
                     self.audioNameList.append(newService.system + ':' + newService.name)
                     # Check if this is the first service, if so display it
                     if len(self.audioNameList) == 1:
                         self.audioSelection.set(self.audioNameList[0])
                     # Now update GUI menu
@@ -1591,14 +1755,17 @@
                 XMLWindow = Toplevel(master)
                 XMLWindow.geometry("1500x1000")
                 XML_Viewer(XMLWindow, messageData, heading_text=" Audio Metadata Viewer  ").pack()
                 self.XMLViewerRequest = False
             if command == "updateModel":
                 self.updateFromModel(messageData)
                 self.lastModelUpdateTime = time.time()
+            if command == "updateAdmModel":
+                self.updateFromAdmModel(messageData)
+                self.lastModelUpdateTime = time.time()
             if command == "updateInd":
                 self.indicators.update()
         # Check to see if model has timed out, Using 2 second timeout for UI
         if (self.lastModelUpdateTime > 0) and (time.time() > (self.lastModelUpdateTime + 2.0)):
             self.reset_ui()
             self.lastModelUpdateTime = 0
             
@@ -1609,28 +1776,37 @@
         while not self.mainThread.stopped():
             deframer = pmdDeframer()
             self.post("reset", None)
             self.mainThread.clear_reset()
 
             while not (self.mainThread.is_reset() or self.mainThread.stopped()):
                     try:
-                        packets = scapy.sniff(iface=self.interfaceName, filter="ip dst " + self.service.sdp.address + " and udp dst port " + str(self.service.sdp.port), count=self.numCapturePackets, timeout=1)
+                        # Set capture period according to received service type
+                        if self.service.sdp.is2110_41():
+                            numCapturePackets = 10
+                        else:
+                            numCapturePackets = 42
+                        packets = scapy.sniff(iface=self.interfaceName, filter="ip dst " + self.service.sdp.address + " and udp dst port " + str(self.service.sdp.port), count=numCapturePackets, timeout=1)
                     except RuntimeError as e:
                         print(e)
                         packets = []
                         print("Error capturing packets...Stopping Capture")
                         self.mainThread.stop();
                     if len(packets) > 0:
                         for packet in packets:
                             if packet["UDP"].dport == self.service.sdp.port:
                                 deframer.receivePacket(packet, self.service.sdp.codec)
                             if deframer.haveFrame():
                                 break
                         if deframer.haveFrame():
                             newFrame = deframer.getFrame()
+                            if newFrame.is_SMPTE2110_41():
+                                self.indicators.smpte2110_41On()
+                            if newFrame.is_SMPTE2110_31():
+                                self.indicators.smpte2110_31On()
                             try:
                                 if newFrame.is_pmd():
                                     if get_pmd_xml_from_wav(newFrame):
                                         if (check_xml_complete()):
                                             try:
                                                 self.model = parse_pmd_xml("pmd.xml", PMD_XML_MODE_FILE)
                                             except:
@@ -1640,58 +1816,51 @@
                                             self.indicators.pmdOn()
                                     else:
                                         self.indicators.pmdError()
                                         if self.debug:
                                             traceback.print_exc(file=sys.stdout)
                                         raise RuntimeError("PMD conversion to XML failed!")
                                 elif newFrame.is_sADM():
-                                    xmlText = get_sadm_xml(newFrame)
+                                    if (newFrame.container == "ST2110-41"):
+                                        xmlText = get_2127hdr_sadm_xml(newFrame)
+                                    elif (newFrame.container == "AM824"):
+                                        xmlText = get_2116hdr_sadm_xml(newFrame)
+                                    else:
+                                        raise RuntimeError("Unknown SADM format")
                                     if xmlText is not None:
                                         try:
-                                            self.model = populate_model_from_adm(xmlText, ADM_XML_MODE_STRING)
+                                            a = populate_model_from_adm(xmlText, ADM_XML_MODE_STRING)
                                         except:
                                             self.indicators.sadmError()
                                             if self.debug:
                                                 traceback.print_exc(file=sys.stdout)
                                             raise RuntimeError("SADM XML parsing failed")
-                                        self.post("updateModel", copy.deepcopy(self.model))
+                                        self.post("updateAdmModel", copy.deepcopy(a))
                                         self.indicators.sadmOn()
                                     else:
                                         self.indicators.sadmError()
                                         raise RuntimeError("SADM conversion to XML failed!")
-                                elif newFrame.is_AESX242():
-                                    if get_pmd_xml_from_klv(newFrame):
-                                        try:
-                                            self.model = parse_pmd_xml("pmd.xml", PMD_XML_MODE_FILE)
-                                        except:
-                                            self.indicators.aesx242Error()
-                                            raise RuntimeError("AESX242 XML parsing failed!")
-                                        self.post("updateModel", copy.deepcopy(self.model))
-                                        self.indicators.aesx242On()
-                                    else:
-                                        self.indicators.aesx242Error()
-                                        raise RuntimeError("AESX242 conversion to XML failed!")
                                 else:
                                     # received some unknown format
                                     self.indicators.reset()
 
                                 # Handle framing indicators for PMD & SADM
-                                if newFrame.is_pmd() or newFrame.is_sADM():
+                                if newFrame.is_SMPTE2110_31():
                                     if newFrame.subframe_mode:
                                         self.indicators.subFrameMode()
                                     else:
                                         self.indicators.frameMode()
 
                                 if newFrame.bit_depth == 20:
                                     self.indicators.depth20Mode()
                                 elif newFrame.bit_depth == 24:
                                     self.indicators.depth24Mode()
 
                                 if (self.XMLViewerRequest):
-                                    if newFrame.is_pmd() or newFrame.is_AESX242():
+                                    if newFrame.is_pmd():
                                         with open("pmd.xml", "r") as xmlFile:
                                             xmlText = xmlFile.read()
                                         self.post("PMD XML", xmlText)
                                     else:
                                         self.post("ADM XML", xmlText)
                                     self.XMLViewerRequest = False
 
@@ -1715,32 +1884,36 @@
         self.post("quit", None)
 
 # The main thread takes a single file as input. This takes a single filename
 # If a filename is provided then the UI prepolulates with that file
 # If not then the UI starts empty and waits for control input with the UI gadgets
 
 def main():
-    parser = argparse.ArgumentParser(description='Audio Metadata (AM) realtime viewer application')
+    parser = argparse.ArgumentParser(description='Audio Metadata (AM) realtime viewer application ' + __version__)
     parser.add_argument('-xml', type=argparse.FileType('r'), default=None, help='XML filename for offline display of XML')
     parser.add_argument('-sdp', type=argparse.FileType('r'), default=None, help='SDP filename to avoid requiring stream discovery')
     parser.add_argument('-debug', action='store_const', const=True, help='Enables debug mode')
+    parser.add_argument('-libpcap', action='store_const', const=True, help='Uses libpcap')
     args = parser.parse_args()
 
     if args.debug:
         global tracemalloc
         import tracemalloc
         global linecache
         import linecache
         tracemalloc.start()
 
     root = Tk()
     root['bg'] = '#B3B4D8'
     root.tk_setPalette(background='#A3A4C8', foreground='black',
                    activeBackground='#A3A4C8', activeForeground='black')
 
+    if (args.libpcap):
+        conf.use_pcap = True
+
     my_gui = PmdAdmDisplayGUI(root, args.xml, args.sdp, args.debug)
 
     if my_gui.exitCode == my_gui.ErrorCodes.ERR_OK:
         root.update()
 
     while my_gui.exitCode == my_gui.ErrorCodes.ERR_OK and my_gui.processNextMessage(root):
         root.update()
```

## aoip_services/sdp_parser.py

```diff
@@ -70,12 +70,12 @@
         print("Sampling Frequency: ", self.fs,"Hz")
         print("No of channels:", self.channels)
 
 
     def isAM824(self):
         return((self.codec == "AM824") and (self.fs == 48000) and (self.channels == 2))
 
-    def isAESX242(self):
-        return(self.codec == "smpte336m")
+    def is2110_41(self):
+        return(self.codec == "ST2110-41")
 
     def isAES67(self):
         return(self.codec == "L16" or self.codec == "L24")
```

## pmd/pmd_classes.py

```diff
@@ -46,14 +46,22 @@
 
 ****************************************************************************************************************************************************************
 ****************************************************************************************************************************************************************
 """
 
 # ************************************************************************************************************************************************************ #
 # ************************************************************************************************************************************************************ #
+from typing import List, Iterable
+import math
+
+
+class MetadataContainer():
+    def __init__(self, audio_model, adm_info):
+        self.audio_model = audio_model
+        self.adm_info = adm_info
 
 
 class ProfessionalMetadata(object):
     def __init__(self, version):
         self.version = version
         self.title = ""
         self.audio_signals = []
@@ -175,9 +183,149 @@
 
 
 class IaT(object):
     def __init__(self, content_uuid, time_stamp):
         self.content_uuid = content_uuid
         self.time_stamp = time_stamp
 
+
+class CartCoordinate(List):
+    def __init__(self, x=0.0, y=0.0, z=0.0):
+        super(CartCoordinate, self).__init__([x, y, z])
+
+    @property
+    def x(self):
+        return self[0]
+
+    @property
+    def y(self):
+        return self[1]
+
+    @property
+    def z(self):
+        return self[2]
+
+    @x.setter
+    def x(self, new_x):
+        self[0] = new_x
+
+    @y.setter
+    def y(self, new_y):
+        self[1] = new_y
+
+    @z.setter
+    def z(self, new_z):
+        self[2] = new_z
+
+    def rotate_around_x(self, deg: float):
+        r = math.sqrt(pow(self.y, 2) + pow(self.z, 2))
+        if self.y == 0:
+            theta = (math.pi/2 if self.z > 0 else 3*math.pi/2) + deg
+        else:
+            theta = math.atan(self.z/self.y) + deg
+            if self.y < 0:
+                theta = (theta + math.pi) % (2*math.pi)
+        self.z = r*math.sin(theta)
+        self.y = r*math.cos(theta)
+
+    def rotate_around_z(self, deg: float):
+        r = math.sqrt(pow(self.x, 2) + pow(self.y, 2))
+
+        if self.y == 0:
+            theta = (math.pi/2 if self.x > 0 else 3*math.pi/2) + deg
+        else:
+            theta = math.atan(self.x/self.y) + deg
+            if self.y < 0:
+                theta = (theta + math.pi) % (2*math.pi)
+        self.y = r*math.cos(theta)
+        self.x = r*math.sin(theta)
+
+    def __mul__(self, other):
+        if not issubclass(type(other), Iterable):
+            self.x *= other
+            self.y *= other
+            self.z *= other
+        else:
+            self.x *= other[0]
+            self.y *= other[1]
+            self.z *= other[2]
+
+    def to_atmos_cart(self):
+        to_ret = CartCoordinate((self.x + 1)/2, (self.y + 1)/2, (self.z + 1)/2)
+
+        to_ret.x = min(1.0, to_ret.x)
+        to_ret.x = max(0.0, to_ret.x)
+        to_ret.y = min(1.0, to_ret.y)
+        to_ret.y = max(0.0, to_ret.y)
+        to_ret.z = min(1.0, to_ret.z)
+        to_ret.z = max(0.0, to_ret.z)
+
+        return to_ret
+
+
+class Coordinate(List):
+    def __init__(self, az=0.0, el=0.0, r=0.0):
+        super(Coordinate, self).__init__([az, el, r])
+
+    def pretty(self, deg=True):
+        m = 360/(2*math.pi) if deg else 1
+        return f'az={self.az*m:+.01f}, el={self.el*m:+.01f}, r={self.r:.02f}'
+
+    @property
+    def az(self):
+        return self[0]
+
+    @property
+    def el(self):
+        return self[1]
+
+    @property
+    def r(self):
+        return self[2]
+
+    @az.setter
+    def az(self, new_az):
+        self[0] = new_az % (2*math.pi)
+
+    @el.setter
+    def el(self, new_el):
+        self[1] = new_el % (2*math.pi)
+
+    @r.setter
+    def r(self, new_r):
+        self[2] = new_r
+
+    def to_cart(self):
+        t1 = self.r * math.cos(self.el)
+        return CartCoordinate(t1 * math.sin(self.az), t1 * math.cos(self.az), self.r * math.sin(self.el))
+
+    def _update_from_cart(self, x, y, z):
+        psquared = pow(x, 2) + pow(y, 2) + pow(z, 2)
+        self.r = math.sqrt(psquared)
+        self.az = math.atan(x/y) if y != 0 else math.pi/2 if x > 0 else 3*math.pi/2
+        if y < 0:
+            self.az = (self.az + math.pi) % (2*math.pi)
+        self.el = math.asin(z/self.r) if self.r != 0 else 0
+
+    @classmethod
+    def from_cart(cls, c: CartCoordinate):
+        to_ret = cls()
+        to_ret._update_from_cart(c.x, c.y, c.z)
+        return to_ret
+
+    def __add__(self, other):
+        c1 = self.to_cart()
+        c2 = other.to_cart()
+        self._update_from_cart(c1[0] + c2[0], c1[1] + c2[1], c1[2] + c2[2])
+
+    def __mul__(self, other):
+        if not issubclass(type(other), Iterable):
+            self.az *= other
+            self.el *= other
+            self.r *= other
+        else:
+            self.az *= other[0]
+            self.el *= other[1]
+            self.r *= other[2]
+
 # ************************************************************************************************************************************************************ #
 # ************************************************************************************************************************************************************ #
```

## pmd/pmd_const.py

```diff
@@ -219,9 +219,14 @@
 PMD_XML_ROOT_SE_PMD_SE_IAT = "IAT"
 PMD_XML_ROOT_SE_PMD_SE_IAT_SE_UUI = "UUID"
 PMD_XML_ROOT_SE_PMD_SE_IAT_SE_CID = "Content_ID"
 PMD_XML_ROOT_SE_PMD_SE_IAT_SE_TST = "Timestamp"
 
 PMD_LOG_FILE = "pmd_tool.log"
 
+APID = 'audio_presentation_id'
+EITA = 'element_id_to_add'
+EITR = 'element_id_to_remove'
+AVSD = 'AVS_'
+
 # ************************************************************************************************************************************************************ #
 # ************************************************************************************************************************************************************ #
```

## pmd/pmd_tool.py

```diff
@@ -48,14 +48,16 @@
 ****************************************************************************************************************************************************************
 # """
 #
 # # ************************************************************************************************************************************************************ #
 # # ************************************************************************************************************************************************************ #
 #
 # # Consts
+import copy
+
 from pmd.pmd_const import LOUDSPEAKER_CONFIG_HORIZONTAL_SPEAKER_OUTPUT_TARGETS, OBJECT_CLASSES
 
 from pmd.pmd_const import MIN_MAX_AZIMUTH, MIN_MAX_ELEVATION, MIN_MAX_DISTANCE
 from pmd.pmd_const import MIN_MAX_XPOS, MIN_MAX_YPOS, MIN_MAX_ZPOS
 from pmd.pmd_const import MIN_SIZE, MAX_SIZE
 from pmd.pmd_const import MIN_SOURCE_GAIN_DB
 from pmd.pmd_const import MAX_SOURCE_GAIN_DB
@@ -174,36 +176,42 @@
 from pmd.pmd_const import PMD_XML_ROOT_SE_PMD_SE_APR_SE_EMT
 
 from pmd.pmd_const import PMD_XML_ROOT_SE_PMD_SE_IAT
 from pmd.pmd_const import PMD_XML_ROOT_SE_PMD_SE_IAT_SE_CID
 from pmd.pmd_const import PMD_XML_ROOT_SE_PMD_SE_IAT_SE_UUI
 from pmd.pmd_const import PMD_XML_ROOT_SE_PMD_SE_IAT_SE_TST
 
+from pmd.pmd_const import APID
+from pmd.pmd_const import EITA
+from pmd.pmd_const import EITR
+from pmd.pmd_const import AVSD
+
 # Classes
-from pmd.pmd_classes import ProfessionalMetadata, AudioPresentation, AudioBed, AudioObject, AudioSignal, OutputTarget, IaT, PresentationNameLanguage
+from pmd.pmd_classes import ProfessionalMetadata, AudioPresentation, AudioBed, AudioObject, AudioSignal
+from pmd.pmd_classes import OutputTarget, IaT, PresentationNameLanguage, Coordinate, CartCoordinate, MetadataContainer
+from adm.adm_classes import AudioPackFormat
 
 # External system
 import logging
 import uuid
 import xml.etree.ElementTree as ET
 import xml.dom.minidom as minidom
 import tracemalloc
 
 # ADM bits and pieces
 
-
-
+#from adm.adm_tool import parse_adm_xml
 from adm.adm_tool import parse_adm_xml
 from adm.adm_const import ADM_XML_MODE_FILE, ADM_XML_INT_TYP_DS, ADM_XML_INT_TYP_OB
 from adm.adm_const import NON_DIALOGUE_CONTENT, DIALOGUE_CONTENT, MIXED_CONTENT
 
 from adm.adm_const import ADM_NON_DIALOGUE_CONTENT_KIND, ADM_DIALOGUE_CONTENT_KIND, ADM_MIXED_CONTENT_KIND
 from adm.adm_const import ADM_DIALOGUE_CONTENT_KIND_UNDEFINED, ADM_DIALOGUE_CONTENT_KIND_DIALOGUE, ADM_DIALOGUE_CONTENT_KIND_VOICEOVER
 from adm.adm_const import ADM_DIALOGUE_CONTENT_KIND_SPOKEN_SUBTITLE, ADM_DIALOGUE_CONTENT_KIND_AUDIO_DESCRIPTION, ADM_DIALOGUE_CONTENT_KIND_COMMENTARY
-from adm.adm_const import ADM_DIALOGUE_CONTENT_KIND_EMERGENCY
+from adm.adm_const import ADM_DIALOGUE_CONTENT_KIND_EMERGENCY, SUPPORTED_COMMON_DEFS
 
 
 # Globals to keep track of ID allocation, lists etc.
 
 professional_metadata_list = []
 audio_presentation_list = []
 audio_element_list = []
@@ -279,31 +287,31 @@
 
 
 def create_object(name, classification, dynamic_updates, azimuth_or_x, elevation_or_y, distance_or_z,
                   size, size_3d, diverge, audio_signal, source_gain_db, original_id=0):
     global audio_element_counter, audio_object_counter, audio_signal_counter, audio_signal_list, audio_object_list, audio_element_list
 
     # Check parameter types
-    check_parameter_type(name, str, create_object)
-    check_parameter_type(classification, int, create_object)
-    check_parameter_type(dynamic_updates, bool, create_object)
-    check_parameter_type(azimuth_or_x, float, create_object)
-    check_parameter_type(elevation_or_y, float, create_object)
-    check_parameter_type(distance_or_z, float, create_object)
-    check_parameter_type(size, float, create_object)
-    check_parameter_type(size_3d, bool, create_object)
-    check_parameter_type(diverge, bool, create_object)
-    check_parameter_type(audio_signal, int, create_object)
-    check_parameter_type(source_gain_db, float, create_object)
+    #check_parameter_type(name, str, create_object)
+    #check_parameter_type(classification, int, create_object)
+    #check_parameter_type(dynamic_updates, bool, create_object)
+    #check_parameter_type(azimuth_or_x, float, create_object)
+    #check_parameter_type(elevation_or_y, float, create_object)
+    #check_parameter_type(distance_or_z, float, create_object)
+    #check_parameter_type(size, float, create_object)
+    #check_parameter_type(size_3d, bool, create_object)
+    #check_parameter_type(diverge, bool, create_object)
+    #check_parameter_type(audio_signal, int, create_object)
+    #check_parameter_type(source_gain_db, float, create_object)
 
     # Range check parameters
-    check_parameter_value_range(size, MIN_SIZE, MAX_SIZE, create_object)
-    check_parameter_value_range(audio_signal, MIN_AUDIO_SIGNAL, MAX_AUDIO_SIGNAL, create_object)
-    check_parameter_value_range(source_gain_db, MIN_SOURCE_GAIN_DB, MAX_SOURCE_GAIN_DB, create_object)
-    check_positional_coordinates_in_range(azimuth_or_x, elevation_or_y, distance_or_z, create_object)
+    #check_parameter_value_range(size, MIN_SIZE, MAX_SIZE, create_object)
+    #check_parameter_value_range(audio_signal, MIN_AUDIO_SIGNAL, MAX_AUDIO_SIGNAL, create_object)
+    #check_parameter_value_range(source_gain_db, MIN_SOURCE_GAIN_DB, MAX_SOURCE_GAIN_DB, create_object)
+    #check_positional_coordinates_in_range(azimuth_or_x, elevation_or_y, distance_or_z, create_object)
 
     # Add AudioSignal entry to audio_signal_list if it doesn't already exist, if exists save index for later
     ok_to_add = True
     replacement_counter = 0
     for i in range(0, len(audio_signal_list)):
         if audio_signal == audio_signal_list[i].id:
             ok_to_add = False
@@ -840,105 +848,14 @@
         iat_timestamp.text = str(iat_list[0].time_stamp)
 
     # Write cleaned up xml to disk
     with open(xml_file, "w") as text_file:
         text_file.write(prettify_xml(root))
     return
 
-"""
-def write_pmd_xml_from_external(xml_file, ext_audio_signal_list, ext_audio_bed_list, ext_audio_object_list, ext_audio_presentation_list, ext_iat_list):
-    # Reorder audio signals list (if need be, it looks nicer) so that id values are ascending
-    ext_audio_signal_list.sort(key=lambda x: x.id, reverse=False)
-
-    root = ET.Element(PMD_XML_ROOT)
-    root.append(ET.Comment(PMD_XML_ROOT_CMT))
-
-    container_config = ET.SubElement(root, PMD_XML_ROOT_SE_CONTAINER)
-    ET.SubElement(container_config, PMD_XML_ROOT_SE_CONTAINER_SE_SMP_OST).text = '0'
-    ET.SubElement(container_config, PMD_XML_ROOT_SE_CONTAINER_SUB_E_D_TAGS)
-
-    professional_metadata = ET.SubElement(root, PMD_XML_ROOT_SE_PMD, {PMD_XML_ROOT_SE_PMD_AT_VER: PMD_XML_ROOT_SE_PMD_AT_VER_VAL})
-
-    ET.SubElement(professional_metadata, PMD_XML_ROOT_SE_PMD_SE_TTL)
-    audio_signals = ET.SubElement(professional_metadata, PMD_XML_ROOT_SE_PMD_SE_ASG)
-    audio_elements = ET.SubElement(professional_metadata, PMD_XML_ROOT_SE_PMD_SE_AEL)
-    audio_presentations = ET.SubElement(professional_metadata, PMD_XML_ROOT_SE_PMD_SE_APR)
-    iat = ET.SubElement(professional_metadata, PMD_XML_ROOT_SE_PMD_SE_IAT)
-
-    # Copy audio_signals_list into audio_signals tree
-    for i in range(0, len(ext_audio_signal_list)):
-        audio_signal = ET.SubElement(audio_signals, PMD_XML_ROOT_SE_PMD_SE_ASG_SE_ASG, {PMD_XML_ATTRIB_ID: str(ext_audio_signal_list[i].id)})
-        audio_signal_name = ET.SubElement(audio_signal, PMD_XML_ROOT_SE_PMD_SE_ASG_SE_ASG_NME)
-        audio_signal_name.text = ext_audio_signal_list[i].name
-
-    # Copy all audio_elements_list into audio elements tree
-    # Beds
-    for i in range(0, len(ext_audio_bed_list)):
-        audio_bed = ET.SubElement(audio_elements, PMD_XML_ROOT_SE_PMD_SE_AEL_SE_AB, {PMD_XML_ATTRIB_ID: str(ext_audio_bed_list[i].id)})
-        ET.SubElement(audio_bed, PMD_XML_ROOT_SE_PMD_SE_AEL_SE_AB_SE_NME).text = ext_audio_bed_list[i].name
-        ET.SubElement(audio_bed, PMD_XML_ROOT_SE_PMD_SE_AEL_SE_AB_SE_CFG).text = ext_audio_bed_list[i].speaker_config
-        audio_bed_output_targets = ET.SubElement(audio_bed, PMD_XML_ROOT_SE_PMD_SE_AEL_SE_AB_SE_OTG)
-
-        # Loop through all output targets and populate
-        for j in range(0, len(ext_audio_bed_list[i].output_targets)):
-            audio_bed_output_target = ET.SubElement(audio_bed_output_targets, PMD_XML_ROOT_SE_PMD_SE_AEL_SE_AB_SE_OTG_SE_OTG,
-                                                    {PMD_XML_ATTRIB_ID: str(ext_audio_bed_list[i].output_targets[j].target)})
-
-            # TODO add support for output targets to have more than one audio signal + gain attribute, i.e. support beyond direct beds
-            # Loop through all audio signals for each target
-            audio_signals = ET.SubElement(audio_bed_output_target, PMD_XML_ROOT_SE_PMD_SE_AEL_SE_AB_SE_OTG_SE_OTG_SE_ASG)
-            for k in range(0, len(ext_audio_bed_list[i].output_targets[j].audio_signals)):
-                ET.SubElement(audio_signals, PMD_XML_ROOT_SE_PMD_SE_AEL_SE_AB_SE_OTG_SE_OTG_SE_ASG_SE_IDS).text\
-                    = str(ext_audio_bed_list[i].output_targets[j].audio_signals[k].id)
-
-    # Objects
-    for i in range(0, len(ext_audio_object_list)):
-        audio_object = ET.SubElement(audio_elements, PMD_XML_ROOT_SE_PMD_SE_AEL_SE_AO, {PMD_XML_ATTRIB_ID: str(ext_audio_object_list[i].id)})
-        ET.SubElement(audio_object, PMD_XML_ROOT_SE_PMD_SE_AEL_SE_AO_SE_NME).text = ext_audio_object_list[i].name
-        ET.SubElement(audio_object, PMD_XML_ROOT_SE_PMD_SE_AEL_SE_AO_SE_CLS).text = OBJECT_CLASSES[ext_audio_object_list[i].classification]
-        ET.SubElement(audio_object, PMD_XML_ROOT_SE_PMD_SE_AEL_SE_AO_SE_DUP).text = str(ext_audio_object_list[i].dynamic_updates)
-        ET.SubElement(audio_object, PMD_XML_ROOT_SE_PMD_SE_AEL_SE_AO_SE_XPS).text = str(ext_audio_object_list[i].azimuth_or_x)
-        ET.SubElement(audio_object, PMD_XML_ROOT_SE_PMD_SE_AEL_SE_AO_SE_YPS).text = str(ext_audio_object_list[i].elevation_or_y)
-        ET.SubElement(audio_object, PMD_XML_ROOT_SE_PMD_SE_AEL_SE_AO_SE_ZPS).text = str(ext_audio_object_list[i].distance_or_z)
-        ET.SubElement(audio_object, PMD_XML_ROOT_SE_PMD_SE_AEL_SE_AO_SE_SIZ).text = str(ext_audio_object_list[i].size)
-        ET.SubElement(audio_object, PMD_XML_ROOT_SE_PMD_SE_AEL_SE_AO_SE_S3D).text = str(ext_audio_object_list[i].size_3d)
-        ET.SubElement(audio_object, PMD_XML_ROOT_SE_PMD_SE_AEL_SE_AO_SE_DVG).text = str(ext_audio_object_list[i].diverge)
-        ET.SubElement(audio_object, PMD_XML_ROOT_SE_PMD_SE_AEL_SE_AO_SE_ASG).text = str(ext_audio_object_list[i].audio_signal.id)
-        ET.SubElement(audio_object, PMD_XML_ROOT_SE_PMD_SE_AEL_SE_AO_SE_SGD).text = str(ext_audio_object_list[i].source_gain_db)
-
-    # Copy presentations
-    for i in range(0, len(ext_audio_presentation_list)):
-        audio_presentation = ET.SubElement(audio_presentations, PMD_XML_ROOT_SE_PMD_SE_APR_SE_APR, {PMD_XML_ATTRIB_ID: str(ext_audio_presentation_list[i].id)})
-
-        # Loop through names list
-        for j in range(0, len(ext_audio_presentation_list[i].name_language)):
-            ET.SubElement(audio_presentation, PMD_XML_ROOT_SE_PMD_SE_APR_SE_NME, {PMD_XML_ROOT_SE_PMD_SE_APR_AT_LNG:
-                          ext_audio_presentation_list[i].name_language[j].language}).text = ext_audio_presentation_list[i].name_language[j].name
-        ET.SubElement(audio_presentation, PMD_XML_ROOT_SE_PMD_SE_APR_SE_CFG).text = ext_audio_presentation_list[i].config
-        ET.SubElement(audio_presentation, PMD_XML_ROOT_SE_PMD_SE_APR_SE_LNG).text = ext_audio_presentation_list[i].language
-
-        # Loop through elements list
-        for j in range(0, len(ext_audio_presentation_list[i].elements)):
-            ET.SubElement(audio_presentation, PMD_XML_ROOT_SE_PMD_SE_APR_SE_EMT).text = str(ext_audio_presentation_list[i].elements[j].id)
-
-    # Copy iat_list into iat tree
-    for i in range(0, len(ext_iat_list)):
-        iat_content_id = ET.SubElement(iat, PMD_XML_ROOT_SE_PMD_SE_IAT_SE_CID)
-        iat_content_id_uuid = ET.SubElement(iat_content_id, PMD_XML_ROOT_SE_PMD_SE_IAT_SE_UUI)
-        iat_content_id_uuid.text = ext_iat_list[0].content_uuid
-
-        iat_timestamp = ET.SubElement(iat, PMD_XML_ROOT_SE_PMD_SE_IAT_SE_TST)
-        iat_timestamp.text = str(ext_iat_list[0].time_stamp)
-
-    # Write cleaned up xml to disk
-    with open(xml_file, "w") as text_file:
-        text_file.write(prettify_xml(root))
-    return
-"""
-
 
 def start_logging():
     logging.basicConfig(level=logging.ERROR, format='%(asctime)s %(levelname)s %(message)s', filename=PMD_LOG_FILE, filemode='w')
     logging.info('Started')
     return
 
 
@@ -977,19 +894,99 @@
 
     # Zero counters
     audio_presentation_counter = 0
     audio_element_counter = 0
     audio_object_counter = 0
     audio_bed_counter = 0
     audio_signal_counter = 0
+    new_avs_counter = 1
 
     my_adm_metadata = parse_adm_xml(xml_struct, mode)
 
+    # Create copies of objects if they contain alternative values sets
+    new_avs_objects = []
+
     for i in range(0, len(my_adm_metadata.audio_object)):
-        if int(my_adm_metadata.audio_object[i].audio_pack_idref[0].type_label) == ADM_XML_INT_TYP_DS:
+        if len(my_adm_metadata.audio_object[i].alternative_value_set) > 0:
+            for j in range(0, len(my_adm_metadata.audio_object[i].alternative_value_set)):
+                a = copy.deepcopy(my_adm_metadata.audio_object[i])
+                a.name = a.name + ':' + my_adm_metadata.audio_object[i].alternative_value_set[j]['alternative_value_set_id']
+                new_id = a.id[:4] + str(new_avs_counter) + a.id[5:]
+                a.id = new_id
+                new_avs_counter += 1
+                # Get alternative value set gain
+                if 'gain_value' in my_adm_metadata.audio_object[i].alternative_value_set[j]:
+                    a.gain['gain_value'] = my_adm_metadata.audio_object[i].alternative_value_set[j]['gain_value']
+                # Get alternative value set positional offset
+                if 'offset' in my_adm_metadata.audio_object[i].alternative_value_set[j]:
+                    b = float(a.audio_pack_idref[0].audio_channel_idref[0].audio_block.position_coord.x_or_az)
+                    c = float(my_adm_metadata.audio_object[i].alternative_value_set[j]['offset'])
+                    a.audio_pack_idref[0].audio_channel_idref[0].audio_block.position_coord.x_or_az = str(b + c)
+                new_avs_objects.append(a)
+
+    # Add new objects to list
+    for i in range(0, len(new_avs_objects)):
+        # Clear alternative value sets in copied objects
+        new_avs_objects[i].alternative_value_set.clear()
+        my_adm_metadata.audio_object.append(new_avs_objects[i])
+
+    convert_bed = False
+    pack_object_exists = False
+
+    for i in range(0, len(my_adm_metadata.audio_object)):
+        if isinstance(my_adm_metadata.audio_object[i].audio_pack_idref, str):
+            pack_object_exists = False
+            if my_adm_metadata.audio_object[i].audio_pack_idref == 'AP_00010001':
+                a = my_adm_metadata.audio_object[i].id
+                for m in range(0, len(my_adm_metadata.audio_content)):
+                    for n in range(0, len(my_adm_metadata.audio_content[m].audio_object_idref)):
+                        if my_adm_metadata.audio_object[i].id == my_adm_metadata.audio_content[m].audio_object_idref[n].id:
+                            if my_adm_metadata.audio_content[m].dialogue.value == 1:
+                                convert_bed = True
+                            else:
+                                convert_bed = False
+        else:
+            pack_object_exists = True
+
+        if pack_object_exists is False and convert_bed is False:
+            name = ''
+            if my_adm_metadata.audio_object[i].audio_pack_idref in SUPPORTED_COMMON_DEFS:
+                name = my_adm_metadata.audio_object[i].name
+                if my_adm_metadata.audio_object[i].audio_pack_idref == 'AP_00010002':
+                    config = LOUDSPEAKER_CONFIG_COMMON_USE_2_0
+                elif my_adm_metadata.audio_object[i].audio_pack_idref == 'AP_0001000a':
+                    config = LOUDSPEAKER_CONFIG_COMMON_USE_3_0
+                elif my_adm_metadata.audio_object[i].audio_pack_idref == 'AP_00010003':
+                    config = LOUDSPEAKER_CONFIG_COMMON_USE_5_1
+                elif my_adm_metadata.audio_object[i].audio_pack_idref == 'AP_00010013':
+                    config = LOUDSPEAKER_CONFIG_COMMON_USE_5_1_2
+                elif my_adm_metadata.audio_object[i].audio_pack_idref == 'AP_00010005':
+                    config = LOUDSPEAKER_CONFIG_COMMON_USE_5_1_4
+                elif my_adm_metadata.audio_object[i].audio_pack_idref == 'AP_00010017':
+                    config = LOUDSPEAKER_CONFIG_COMMON_USE_7_1_4
+            else:
+                # Unsupported bed, find out how many channels it has and make do
+                chan_count = len(my_adm_metadata.audio_object[i].audio_track_idref)
+                name = my_adm_metadata.audio_object[i].name + ' (unsupported ' + str(chan_count) + 'ch config)'
+                if chan_count == 1:
+                    config = LOUDSPEAKER_CONFIG_COMMON_USE_2_0
+                if chan_count == 5:
+                    config = LOUDSPEAKER_CONFIG_COMMON_USE_5_1
+                elif chan_count == 8:
+                    config = LOUDSPEAKER_CONFIG_COMMON_USE_5_1_2
+                elif chan_count == 9:
+                    config = LOUDSPEAKER_CONFIG_COMMON_USE_5_1_2
+                elif chan_count >= 14:
+                    config = LOUDSPEAKER_CONFIG_COMMON_USE_7_1_4
+
+            # Create the bed
+            create_audio_bed(name, config,
+                             int(my_adm_metadata.audio_object[i].audio_track_idref[0].track_id, 10), int(my_adm_metadata.audio_object[i].id[3:], 16) - 0x1000,
+                             float(my_adm_metadata.audio_object[i].gain['gain_value']))
+        elif pack_object_exists is True and convert_bed is False and int(my_adm_metadata.audio_object[i].audio_pack_idref[0].type_label) == ADM_XML_INT_TYP_DS:
             # The number of audio_channel_idref entries in audio_pack can inform us of the bed configuration without looking that the speaker labels
             # in the corresponding audio_blocks. This works ok for fixed formats such as those used in the PMD editor 2, 3, 6, 8, 10, 12
             if len(my_adm_metadata.audio_object[i].audio_pack_idref[0].audio_channel_idref) == 2:
                 config = LOUDSPEAKER_CONFIG_COMMON_USE_2_0
             elif len(my_adm_metadata.audio_object[i].audio_pack_idref[0].audio_channel_idref) == 3:
                 config = LOUDSPEAKER_CONFIG_COMMON_USE_3_0
             elif len(my_adm_metadata.audio_object[i].audio_pack_idref[0].audio_channel_idref) == 6:
@@ -1000,22 +997,22 @@
                 config = LOUDSPEAKER_CONFIG_COMMON_USE_5_1_4
             elif len(my_adm_metadata.audio_object[i].audio_pack_idref[0].audio_channel_idref) == 12:
                 config = LOUDSPEAKER_CONFIG_COMMON_USE_7_1_4
 
             # Create the bed
             create_audio_bed(my_adm_metadata.audio_object[i].name, config,
                              int(my_adm_metadata.audio_object[i].audio_track_idref[0].track_id, 10), int(my_adm_metadata.audio_object[i].id[3:], 16) - 0x1000,
-                             float(my_adm_metadata.audio_object[i].gain))
+                             float(my_adm_metadata.audio_object[i].gain['gain_value']))
 
-        if int(my_adm_metadata.audio_object[i].audio_pack_idref[0].type_label) == ADM_XML_INT_TYP_OB:
+        elif pack_object_exists and isinstance(my_adm_metadata.audio_object[i].audio_pack_idref[0], AudioPackFormat):
             # In ADM, you can only get specifics about the nature of the essence (dialog, music, spoken subtitle etc) at the content level
             # Search all audio content buckets looking for a matching audio_object.id
             for j in range(0, len(my_adm_metadata.audio_content)):
                 for k in range(0, len(my_adm_metadata.audio_content[j].audio_object_idref)):
-                    if my_adm_metadata.audio_content[j].audio_object_idref[k].id == my_adm_metadata.audio_object[i].id:
+                    if my_adm_metadata.audio_content[j].audio_object_idref[k].id[5:] == my_adm_metadata.audio_object[i].id[5:]:
 
                         # If we are not 100% on the nature of the content then play safe with assuming GENERIC
                         if my_adm_metadata.audio_content[j].dialogue.value == ADM_NON_DIALOGUE_CONTENT_KIND:
                             classification = GENERIC
                         elif my_adm_metadata.audio_content[j].dialogue.value == ADM_DIALOGUE_CONTENT_KIND:
                             if my_adm_metadata.audio_content[j].dialogue.content_kind.classification == ADM_DIALOGUE_CONTENT_KIND_UNDEFINED:
                                 classification = GENERIC
@@ -1032,77 +1029,337 @@
                             elif my_adm_metadata.audio_content[j].dialogue.content_kind.classification == ADM_DIALOGUE_CONTENT_KIND_EMERGENCY:
                                 classification = EMERGENCY_ALERT
                         elif my_adm_metadata.audio_content[j].dialogue.value == ADM_MIXED_CONTENT_KIND:
                             classification = GENERIC
 
                         # The coordinates of the 'object' can be found in the audio_block_format entry of the associated audio_channel_format entry
                         # We only expect a single audio pack instance for each audio_object, audio_channel entry, and audio_block entry
-                        x = my_adm_metadata.audio_content[j].audio_object_idref[k].audio_pack_idref[0].audio_channel_idref[
-                            0].audio_block.position_coord.x_or_az
-                        y = my_adm_metadata.audio_content[j].audio_object_idref[k].audio_pack_idref[0].audio_channel_idref[
-                            0].audio_block.position_coord.y_or_el
-                        z = my_adm_metadata.audio_content[j].audio_object_idref[k].audio_pack_idref[0].audio_channel_idref[
-                            0].audio_block.position_coord.z_or_ds
+                        # For beds that are to be converted xyz won't exist, so we preset to center front
+                        obj_name = ''
+
+                        x = 0.0
+                        y = 1.0
+                        z = 0.0
+
+                        if convert_bed:
+                            obj_name = my_adm_metadata.audio_object[i].name + ' (cnv bed)'
+                        else:
+                            if my_adm_metadata.audio_content[j].audio_object_idref[k].audio_pack_idref[0].audio_channel_idref[0].audio_block.cartesian == CARTESIAN:
+                                x = float(my_adm_metadata.audio_content[j].audio_object_idref[k].audio_pack_idref[
+                                              0].audio_channel_idref[0].audio_block.position_coord.x_or_az)
+                                y = float(my_adm_metadata.audio_content[j].audio_object_idref[k].audio_pack_idref[
+                                              0].audio_channel_idref[0].audio_block.position_coord.y_or_el)
+                                z = my_adm_metadata.audio_content[j].audio_object_idref[k].audio_pack_idref[
+                                    0].audio_channel_idref[0].audio_block.position_coord.z_or_ds
+                                if z is None:
+                                    z = 0.0
+                                else:
+                                    z = float(z)
+                            else:
+                                # Convert polar to cartesian
+                                az = float(my_adm_metadata.audio_content[j].audio_object_idref[k].audio_pack_idref[
+                                              0].audio_channel_idref[0].audio_block.position_coord.x_or_az) * 0.0174533
+                                el = float(my_adm_metadata.audio_content[j].audio_object_idref[k].audio_pack_idref[
+                                              0].audio_channel_idref[0].audio_block.position_coord.y_or_el)
+                                ds = my_adm_metadata.audio_content[j].audio_object_idref[k].audio_pack_idref[
+                                    0].audio_channel_idref[0].audio_block.position_coord.z_or_ds
+                                if ds is None:
+                                    ds = 1.0
+                                a = Coordinate(az, el, ds)
+                                b = a.to_cart()
+
+                                x = round(b.x, 2)
+                                y = round(b.y, 2)
+                                z = round(b.z, 2)
+
+                            obj_name = my_adm_metadata.audio_object[i].name
+
+                        # create_object(my_adm_metadata.audio_object[i].name, classification, False, 0.0, 0.0, 0.0, 0.0, False, False, 1, 0)
+                        create_object(obj_name, classification, False, x, y, z, 0.0, False, False,
+                                      int(my_adm_metadata.audio_object[i].audio_track_idref[0].track_id, 10),
+                                      float(my_adm_metadata.audio_content[j].audio_object_idref[k].gain['gain_value']),
+                                      int(my_adm_metadata.audio_object[i].id[3:], 16) - 0x1000)
+
+        elif (convert_bed and pack_object_exists is False) and isinstance(my_adm_metadata.audio_object[i].audio_pack_idref, str):
+                #int(my_adm_metadata.audio_object[i].audio_pack_idref[0].type_label) == ADM_XML_INT_TYP_OB or convert_bed is True:
+            # In ADM, you can only get specifics about the nature of the essence (dialog, music, spoken subtitle etc) at the content level
+            # Search all audio content buckets looking for a matching audio_object.id
+            for j in range(0, len(my_adm_metadata.audio_content)):
+                for k in range(0, len(my_adm_metadata.audio_content[j].audio_object_idref)):
+                    if my_adm_metadata.audio_content[j].audio_object_idref[k].id[5:] == my_adm_metadata.audio_object[i].id[5:]:
+
+                        # If we are not 100% on the nature of the content then play safe with assuming GENERIC
+                        if my_adm_metadata.audio_content[j].dialogue.value == ADM_NON_DIALOGUE_CONTENT_KIND:
+                            classification = GENERIC
+                        elif my_adm_metadata.audio_content[j].dialogue.value == ADM_DIALOGUE_CONTENT_KIND:
+                            if my_adm_metadata.audio_content[j].dialogue.content_kind.classification == ADM_DIALOGUE_CONTENT_KIND_UNDEFINED:
+                                classification = GENERIC
+                            elif my_adm_metadata.audio_content[j].dialogue.content_kind.classification == ADM_DIALOGUE_CONTENT_KIND_DIALOGUE:
+                                classification = DIALOGUE
+                            elif my_adm_metadata.audio_content[j].dialogue.content_kind.classification == ADM_DIALOGUE_CONTENT_KIND_VOICEOVER:
+                                classification = VOICEOVER
+                            elif my_adm_metadata.audio_content[j].dialogue.content_kind.classification == ADM_DIALOGUE_CONTENT_KIND_SPOKEN_SUBTITLE:
+                                classification = SPOKEN_SUBTITLE
+                            elif my_adm_metadata.audio_content[j].dialogue.content_kind.classification == ADM_DIALOGUE_CONTENT_KIND_AUDIO_DESCRIPTION:
+                                classification = VDS
+                            elif my_adm_metadata.audio_content[j].dialogue.content_kind.classification == ADM_DIALOGUE_CONTENT_KIND_COMMENTARY:
+                                classification = DIALOGUE
+                            elif my_adm_metadata.audio_content[j].dialogue.content_kind.classification == ADM_DIALOGUE_CONTENT_KIND_EMERGENCY:
+                                classification = EMERGENCY_ALERT
+                        elif my_adm_metadata.audio_content[j].dialogue.value == ADM_MIXED_CONTENT_KIND:
+                            classification = GENERIC
+
+                        # The coordinates of the 'object' can be found in the audio_block_format entry of the associated audio_channel_format entry
+                        # We only expect a single audio pack instance for each audio_object, audio_channel entry, and audio_block entry
+                        # For beds that are to be converted xyz won't exist, so we preset to center front
+                        obj_name = ''
+
+                        x = 0.0
+                        y = 1.0
+                        z = 0.0
+
+                        if convert_bed:
+                            obj_name = my_adm_metadata.audio_object[i].name + ' (cnv bed)'
+                        else:
+                            if my_adm_metadata.audio_content[j].audio_object_idref[k].audio_pack_idref[0].audio_channel_idref[0].audio_block.cartesian == CARTESIAN:
+                                x = float(my_adm_metadata.audio_content[j].audio_object_idref[k].audio_pack_idref[
+                                              0].audio_channel_idref[0].audio_block.position_coord.x_or_az)
+                                y = float(my_adm_metadata.audio_content[j].audio_object_idref[k].audio_pack_idref[
+                                              0].audio_channel_idref[0].audio_block.position_coord.y_or_el)
+                                z = my_adm_metadata.audio_content[j].audio_object_idref[k].audio_pack_idref[
+                                    0].audio_channel_idref[0].audio_block.position_coord.z_or_ds
+                                if z is None:
+                                    z = 0.0
+                                else:
+                                    z = float(z)
+                            else:
+                                # Convert polar to cartesian
+                                az = float(my_adm_metadata.audio_content[j].audio_object_idref[k].audio_pack_idref[
+                                              0].audio_channel_idref[0].audio_block.position_coord.x_or_az) * 0.0174533
+                                el = float(my_adm_metadata.audio_content[j].audio_object_idref[k].audio_pack_idref[
+                                              0].audio_channel_idref[0].audio_block.position_coord.y_or_el)
+                                ds = my_adm_metadata.audio_content[j].audio_object_idref[k].audio_pack_idref[
+                                    0].audio_channel_idref[0].audio_block.position_coord.z_or_ds
+                                if ds is None:
+                                    ds = 1.0
+                                a = Coordinate(az, el, ds)
+                                b = a.to_cart()
+
+                                x = round(b.x, 2)
+                                y = round(b.y, 2)
+                                z = round(b.z, 2)
+
+                            obj_name = my_adm_metadata.audio_object[i].name
 
                         # create_object(my_adm_metadata.audio_object[i].name, classification, False, 0.0, 0.0, 0.0, 0.0, False, False, 1, 0)
-                        create_object(my_adm_metadata.audio_object[i].name, classification, False,
-                                      float(my_adm_metadata.audio_content[j].audio_object_idref[k].audio_pack_idref[0].audio_channel_idref[
-                                                0].audio_block.position_coord.x_or_az),
-                                      float(my_adm_metadata.audio_content[j].audio_object_idref[k].audio_pack_idref[0].audio_channel_idref[
-                                                0].audio_block.position_coord.y_or_el),
-                                      float(my_adm_metadata.audio_content[j].audio_object_idref[k].audio_pack_idref[0].audio_channel_idref[
-                                                0].audio_block.position_coord.z_or_ds),
-                                      0.0, False, False, int(my_adm_metadata.audio_object[i].audio_track_idref[0].track_id, 10),
-                                      float(my_adm_metadata.audio_content[j].audio_object_idref[k].gain),
+                        create_object(obj_name, classification, False, x, y, z, 0.0, False, False,
+                                      int(my_adm_metadata.audio_object[i].audio_track_idref[0].track_id, 10),
+                                      float(my_adm_metadata.audio_content[j].audio_object_idref[k].gain['gain_value']),
                                       int(my_adm_metadata.audio_object[i].id[3:], 16) - 0x1000)
 
     # Create audio presentations out of audio_programme and audio_content pieces
+    # TODO this where we unroll into internal model
+
+    list = []
+    complementary_objects = []
+    label_list = []
+    id_list = []
+
     for i in range(0, len(my_adm_metadata.audio_programme)):
-        list = []
+        max_chan = 0
         name = my_adm_metadata.audio_programme[i].name
 
-        # Get id's of beds and objects
-        for j in range(0, len(my_adm_metadata.audio_programme[i].audio_content_idref)):
-            # Expect there to only be a single entry for audio_object_idref in each audioContent element
-            list.append(int(my_adm_metadata.audio_programme[i].audio_content_idref[j].audio_object_idref[0].id[3:], 16) - 0x1000)
+        # Does the programme need to be unrolled
+        if my_adm_metadata.audio_programme[i].needs_unrolling:
+            # Find object that needs to be unrolled
+            for j in range(0, len(my_adm_metadata.audio_programme[i].audio_content_idref)):
+                a = len(my_adm_metadata.audio_programme[i].audio_content_idref[j].
+                               audio_object_idref[0].audio_complementary_object_idref)
+                if a > 0:
+                    # Add complementary group leader
+                    complementary_objects.append(int(my_adm_metadata.audio_programme[i].audio_content_idref[j].
+                                                 audio_object_idref[0].id[3:], 16) - 0x1000)
+                    for k in range(0, a):
+                        complementary_objects.append(int(my_adm_metadata.audio_programme[i].audio_content_idref[j].
+                                                         audio_object_idref[0].audio_complementary_object_idref[k].
+                                                         id[3:], 16) - 0x1000)
+
+            # Add the id of the bed (it will be the id that is missing)
+            for j in range(0, len(my_adm_metadata.audio_programme[i].audio_content_idref)):
+                a = int(my_adm_metadata.audio_programme[i].audio_content_idref[j].audio_object_idref[0].id[3:], 16) - 0x1000
+                if a not in complementary_objects:
+                    list.append(a)
+        else:
+            # Get id's of beds and objects
+            for j in range(0, len(my_adm_metadata.audio_programme[i].audio_content_idref)):
+                # Expect there to only be a single entry for audio_object_idref in each audioContent element
+                list.append(int(my_adm_metadata.audio_programme[i].audio_content_idref[j].audio_object_idref[0].id[3:], 16) - 0x1000)
+
+        # Find biggest bed size in programme to set presentation config
+        for j in range(0, len(list)):
+            for k in range(0, len(audio_bed_list)):
+                if list[j] == audio_bed_list[k].id:
+                    if len(audio_bed_list[k].output_targets) > max_chan:
+                        max_chan = len(audio_bed_list[k].output_targets)
+
+        # Based upon max_chan, get config
+            # If no bed found in this programme then max_chan will be 0, so default to 5.1.4
+            if max_chan == 0:
+                config = LOUDSPEAKER_CONFIG_COMMON_USE_5_1_4
+            elif max_chan == 2:
+                config = LOUDSPEAKER_CONFIG_COMMON_USE_2_0
+            elif max_chan == 3:
+                config = LOUDSPEAKER_CONFIG_COMMON_USE_3_0
+            elif max_chan == 6:
+                config = LOUDSPEAKER_CONFIG_COMMON_USE_5_1
+            elif max_chan == 8:
+                config = LOUDSPEAKER_CONFIG_COMMON_USE_5_1_2
+            elif max_chan == 10:
+                config = LOUDSPEAKER_CONFIG_COMMON_USE_5_1_4
+            elif max_chan == 12:
+                config = LOUDSPEAKER_CONFIG_COMMON_USE_7_1_4
 
         # Create presentation
-        # z = int(my_adm_metadata.audio_programme[i].id[4:], 16) - 0x1000
-        create_audio_presentation("P" + str(i), my_adm_metadata.audio_programme[i].language, config, list,
-                                  int(my_adm_metadata.audio_programme[i].id[4:], 16) - 0x1000)
-
-        del list[:]
-        for j in range(0, len(my_adm_metadata.audio_programme[i].audio_programme_label)):
-            list.append(my_adm_metadata.audio_programme[i].audio_programme_label[j].name)
-            list.append(my_adm_metadata.audio_programme[i].audio_programme_label[j].language)
+        if len(complementary_objects) == 0:
+            create_audio_presentation("P" + str(i), my_adm_metadata.audio_programme[i].language, config, list,
+                                      int(my_adm_metadata.audio_programme[i].id[4:], 16) - 0x1000)
+            list.clear()
+            for j in range(0, len(my_adm_metadata.audio_programme[i].audio_programme_label)):
+                list.append(my_adm_metadata.audio_programme[i].audio_programme_label[j].name)
+                list.append(my_adm_metadata.audio_programme[i].audio_programme_label[j].language)
+
+            add_audio_presentation_names_by_name(find_list_reference_by_name(audio_presentation_list, 'P' + str(i)), list)
+        else:
+
+            for j in range(0, len(my_adm_metadata.audio_programme[i].audio_programme_label)):
+                label_list.append(my_adm_metadata.audio_programme[i].audio_programme_label[j].name)
+                label_list.append(my_adm_metadata.audio_programme[i].audio_programme_label[j].language)
+
+            for j in range(0, len(complementary_objects)):
+                id_list.clear()
+                id_list.append(list[0])
+                id_list.append(complementary_objects[j])
+                new_id = int(my_adm_metadata.audio_programme[i].id[4:], 16) - 0x1000
+                new_id = new_id * 10
+                new_id = new_id + j
+                create_audio_presentation("P" + str(j), my_adm_metadata.audio_programme[i].language, config, id_list, new_id)
+                add_audio_presentation_names_by_name(find_list_reference_by_name(audio_presentation_list, 'P' + str(j)), label_list)
+
+    # Append presentation names that reference alternative value set derived elements
+    for i in range(0, len(my_adm_metadata.audio_programme)):
+        if len(my_adm_metadata.audio_programme[i].alternative_value_set_idref) > 0:
+            for j in range(0, len(audio_presentation_list)):
+                if audio_presentation_list[j].id == int(my_adm_metadata.audio_programme[i].id[4:], 16) - 0x1000:
+                    b = audio_presentation_list[j].name
+                    for k in range (0, len(my_adm_metadata.audio_programme[i].alternative_value_set_idref)):
+                        b = b + ':' + my_adm_metadata.audio_programme[i].alternative_value_set_idref[k]
+                    audio_presentation_list[j].name = b
 
-        add_audio_presentation_names_by_name(find_list_reference_by_name(audio_presentation_list, 'P' + str(i)), list)
+    # Go through the appended presentation list, note presentations/elements that need removing
+    element_ids_to_remove = []
+    for i in range(0, len(audio_presentation_list)):
+        a = 0
+        b = []
+        while True:
+            a = audio_presentation_list[i].name.find(AVSD, a)
+            if a == -1:
+                break
+            b.append(a)
+            a += len(AVSD)
+
+        for j in range(0, len(b)):
+            # Get id of original element from appended name
+            c = int(audio_presentation_list[i].name[b[j] + 6:b[j] + 8])
+            element_ids_to_remove.append({APID: audio_presentation_list[i].id, EITR: c})
+
+    element_ids_to_add = []
+    # Go through the appended presentation list, note presentations/elements that need adding
+    for i in range(0, len(audio_presentation_list)):
+        a = 0
+        b = []
+        while True:
+            a = audio_presentation_list[i].name.find(AVSD, a)
+            if a == -1:
+                break
+            b.append(audio_presentation_list[i].name[a:a + 13])
+            a += len(AVSD)
+
+        for j in range(0, len(b)):
+            for k in range(0,len(audio_element_list)):
+                if b[j] in audio_element_list[k].name:
+                    element_ids_to_add.append({APID: audio_presentation_list[i].id,
+                                               EITA: audio_element_list[k].id})
+
+    # Remove elements from presentation elements list
+    for i in range(0, len(element_ids_to_remove)):
+        for j in range(0, len(audio_presentation_list)):
+            if element_ids_to_remove[i][APID] == audio_presentation_list[j].id:
+                for k in range(0, len(audio_presentation_list[j].elements)):
+                    if element_ids_to_remove[i][EITR] == audio_presentation_list[j].elements[k].id:
+                        del audio_presentation_list[j].elements[k]
+                        break
+
+    # Add elements to presentation elements list
+    for i in range(0, len(element_ids_to_add)):
+        for j in range(0, len(audio_presentation_list)):
+            if element_ids_to_add[i][APID] == audio_presentation_list[j].id:
+                # Search element list for reference
+                for k in range(0, len(audio_element_list)):
+                    if element_ids_to_add[i][EITA] == audio_element_list[k].id:
+                        audio_presentation_list[j].elements.append(audio_element_list[k])
+
+    # Update any AVS created objects with the correct gain
+    for i in range(0,len(audio_element_list)):
+        if isinstance(audio_element_list[i], AudioObject):
+            if AVSD in audio_element_list[i].name:
+                for j in range(0,len(my_adm_metadata.audio_object)):
+                    if audio_element_list[i].name == my_adm_metadata.audio_object[j].name:
+                        audio_element_list[i].source_gain_db = float(my_adm_metadata.audio_object[j].gain['gain_value'])
+
+    # Update any AVS created objects with the correct positional offset
+    for i in range(0,len(audio_element_list)):
+        if isinstance(audio_element_list[i], AudioObject):
+            if AVSD in audio_element_list[i].name:
+                for j in range(0,len(my_adm_metadata.audio_object)):
+                    if audio_element_list[i].name == my_adm_metadata.audio_object[j].name:
+                        audio_element_list[i].azimuth_or_x = float(my_adm_metadata.audio_object[j].
+                                                                   audio_pack_idref[0].audio_channel_idref[0].
+                                                                   audio_block.position_coord.x_or_az)
+
+    del complementary_objects[:]
+    del label_list[:]
+    del id_list[:]
+    del list[:]
+    del new_avs_objects[:]
+    del element_ids_to_remove[:]
+    del element_ids_to_add[:]
 
     # Lastly, create an IaT entry
     add_iat(str(uuid.uuid4()), 12345678)
 
     # Package all the data together into a professional metadata container
+
     k = ProfessionalMetadata(PMD_XML_ROOT_SE_PMD_AT_VER_VAL)
     k.audio_signals = audio_signal_list
     k.audio_elements = audio_element_list
     k.audio_presentations = audio_presentation_list
     k.iat = iat_list
-    return k
+    return MetadataContainer(k, my_adm_metadata.composition_details)
+    #return k #, my_adm_metadata.composition_details
 
 # ************************************************************************************************************************************************************ #
 # Create the PMD model of content
 # ************************************************************************************************************************************************************ #
 # start_logging()
 
 if __name__ == "__main__":
 
     import sys
     import argparse
 
-
     parser = argparse.ArgumentParser(description='PMD/ADM Python Model Test')
     parser.add_argument('-pmd', type=argparse.FileType('r'), default=None, help='PMD XML filename for input')
     parser.add_argument('-sadm', type=argparse.FileType('r'), default=None, help='SADM XML filename for input')
     parser.add_argument('-debug', action='store_const', const=True, help='Enables debug mode')
     parser.add_argument('-loop', type=int, default=1, help='Loop Counter')
     args = parser.parse_args()
 
@@ -1111,59 +1368,68 @@
     # Example section for API calls, i.e. model not driven by xml reader but UI or command line
     # ******************************************************************************************************************************************************** #
     if args.sadm is not None:
         import os
         import linecache
         import time
         if args.debug:
-        	tracemalloc.start()
+            tracemalloc.start()
 
         startsecs = time.time()
 
-        for i in range(0, args.loop):
-            a = 0
+        #with open('complimentary_objects_v2.xml', "r") as xmlFile:
+            #xmlText = xmlFile.read()
+
+        #for i in range(0, 2000):
+            #me = populate_model_from_adm(xmlText, 1)
+
+        for i in range(0, 2):
             me = populate_model_from_adm(args.sadm, PMD_XML_MODE_FILE)
 
         endsecs = time.time()
         call_time = (endsecs - startsecs) / args.loop
         print('Runtime = ' + str(endsecs - startsecs))
         print ('Call time = ' + str(call_time))
 
+"""
+
         if args.debug:
-	        key_type = 'lineno'
-	        limit = 10
-	        snapshot = tracemalloc.take_snapshot()
-	        snapshot = snapshot.filter_traces((tracemalloc.Filter(False, "<frozen importlib._bootstrap>"), tracemalloc.Filter(False, "<unknown>")))
-	        top_stats = snapshot.statistics(key_type)
-	        print("Top %s lines" % limit)
-	        print('{: <10}'.format("index"), '{: <40}'.format("filename"), '{: <10}'.format("line no"), '{: <10}'.format("size kB"))
-	        for index, stat in enumerate(top_stats[:limit], 1):
-	            frame = stat.traceback[0]
-	            filename = os.sep.join(frame.filename.split(os.sep)[-2:])
-	            print('{: <10}'.format(index), '{: <40}'.format(filename), '{: <10}'.format(frame.lineno), '{:0.1f}'.format(stat.size / 1024), "kB")
-	            line = linecache.getline(frame.filename, frame.lineno).strip()
-	            if line:
-	                print('    %s' % line)
-	        other = top_stats[limit:]
-	        if other:
-	            size = sum(stat.size for stat in other)
-	            print("%s other: %.1f KiB" % (len(other), size / 1024))
-	        total = sum(stat.size for stat in top_stats)
-	        print("Total allocated size: %.1f KiB" % (total / 1024))       
+            key_type = 'lineno'
+            limit = 10
+            snapshot = tracemalloc.take_snapshot()
+            snapshot = snapshot.filter_traces((tracemalloc.Filter(False, "<frozen importlib._bootstrap>"), tracemalloc.Filter(False, "<unknown>")))
+            top_stats = snapshot.statistics(key_type)
+            print("Top %s lines" % limit)
+            print('{: <10}'.format("index"), '{: <40}'.format("filename"), '{: <10}'.format("line no"), '{: <10}'.format("size kB"))
+            frame = stat.traceback[0]
+            filename = os.sep.join(frame.filename.split(os.sep)[-2:])
+            print('{: <10}'.format(index), '{: <40}'.format(filename), '{: <10}'.format(frame.lineno), '{:0.1f}'.format(stat.size / 1024), "kB")
+            line = linecache.getline(frame.filename, frame.lineno).strip()
+            if line:
+                print('    %s' % line)
+	            other = top_stats[limit:]
+            if other:
+                size = sum(stat.size for stat in other)
+                print("%s other: %.1f KiB" % (len(other), size / 1024))
+                total = sum(stat.size for stat in top_stats)
+            print("Total allocated size: %.1f KiB" % (total / 1024))
+
+
+"""
 
     # ******************************************************************************************************************************************************** #
 
     # ******************************************************************************************************************************************************** #
     # Example section for API calls, i.e. model driven by xml reader
     # ******************************************************************************************************************************************************** #
 
-    if args.pmd is not None:
-        my_metadata = parse_pmd_xml(args.pmd, PMD_XML_MODE_FILE)
+    #if args.pmd is not None:
+        #my_metadata = parse_pmd_xml(args.pmd, PMD_XML_MODE_FILE)
     # ******************************************************************************************************************************************************** #
 
     # ******************************************************************************************************************************************************** #
     # Example section for API calls, i.e. model driven by xml writer
     # ******************************************************************************************************************************************************** #
 
     # !!!!! Not finished yet !!!!!
-        write_pmd_xml("pmd_created.xml")
+        #write_pmd_xml("pmd_created.xml")
     # ******************************************************************************************************************************************************** #
```

## Comparing `am_viewer-3.9.dist-info/LICENSE` & `am_viewer-4.0.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `am_viewer-3.9.dist-info/METADATA` & `am_viewer-4.0.dist-info/METADATA`

 * *Files 7% similar despite different names*

```diff
@@ -1,32 +1,31 @@
 Metadata-Version: 2.1
 Name: am-viewer
-Version: 3.9
+Version: 4.0
 Summary: A PMD, serial ADM and AES-X242 audio metadata real-time viewer
-Home-page: UNKNOWN
 Author: James Cowdery
 Author-email: jtc@dolby.com
-License: UNKNOWN
-Platform: UNKNOWN
 Classifier: Programming Language :: Python :: 3
 Classifier: Operating System :: Microsoft :: Windows
 Classifier: Operating System :: POSIX :: Linux
 Classifier: Operating System :: MacOS :: MacOS X
 Requires-Python: >=3
 Description-Content-Type: text/markdown
+License-File: LICENSE
 Requires-Dist: netifaces
 Requires-Dist: zeroconf (<=0.26.3)
 Requires-Dist: scapy (==2.4.3)
 
 # Audio Metadata (AM) Viewer
 
 
 ## Overview
 
-This is a python based realtime viewer for PMD, Serial ADM and AES-X242. Once running the viewer can detect real-time changes in the metadata and display them in real-time. The purpose of the viewer is to be able to demonstrate the real-time capabilities of the various formats by allowing the dynamic behaviour to be viewed. The viewer also supports static display of the underlying XML representation.
+This is a python based realtime viewer for Serialized ADM insde a SMPTE ST 2110 container. Two flavours of SMPTE ST 2110 are supported: SMPTE ST 2110-31 and -41. The is designed to view the Serialized ADM metadata produced by PMD Studio available at https://github.com/DolbyLaboratories/pmd_tool.
+Once running the viewer can detect real-time changes in the metadata and display them in real-time. The purpose of the viewer is to be able to demonstrate the real-time capabilities of the various formats by allowing the dynamic behaviour to be viewed. The viewer also supports static display of the underlying XML representation.
 
 The User interface has three main sections:
 - Audio Beds
 - Audio Objects
 - Presentations
 
 The audio beds section provides a list of the main audio scenes available. These will normally be channel based and will have a configuration such as 5.1 or 5.1.4 for 5.1 with 4 overhead channels. Normally there will only be a single bed but certain use-cases make use of two beds such as home and away crowd sounds for a live sports broadcast.
@@ -48,16 +47,15 @@
 
 ## Windows Requirements
 
 NPcap (https://nmap.org/npcap/)
 
 ## Mac OS Requirements
 
-See https://scapy.readthedocs.io/en/latest/installation.html
-Use python from python.org, not Homebrew.
+May require the use of the "-libpcap" switch. If using homebrew then Tkinter must be install via `brew install python-tk`
 
 ## Linux Requirements
 
 As well as Python, some distros may require Tkinter to be installed e.g. on Ubuntu: `sudo apt-get install python3-tk`
 
 Before running allow python and tcpdump to open raw sockets. Failure to do this will result in permission problems when packet reception is attempted.
 
@@ -95,37 +93,35 @@
 
 The stream mode is used then a list of interfaces and a list of available services will be provided on the bottom option bar. Once the appropriate interface and service has been selected then the 'Run' button can be pressed to start the monitoring of the stream. If more than one service is available then the service list can be used to switch between services. If the '-sdp' option was used then one option in the service list should correspond to the sdp file.
 
 When receiving a stream the 'XML' can be pressed at anytime to yield a static XMl snapshot. The XML tree can be explored by expand the various levels of the tree in the XML viewer windows.
 
 Several indicators on the bottom bar show status. The PMD indicator will be green when receiving PMD and grey when not. If an error is received the PMD indicator will flash or stay red for continuous errors. The SADM and AES-X242 indicators work in the same way. The subframe-mode / frame mode indicators indicate whether the received stream is using the frame mode or subframe mode of the SMPTE ST 337 container format inside the SMPTE 2110-31 stream. This indicator is not applicable for AES-X242 streams which do not use SMPTE frames.
 
-## Known Limitations
+If receiving the 
 
-Only a bit depth of 20 bits is supported for ST 2110-31 based streams. As it is known that 24 bit is being used for sADM, this is planned to be added in the next release.  
+## Known Limitations
 
 Only sADM full frame mode is supported. Both gzip and plain XML sADM modes are supported but only gzip has been thoroughly tested.
 
 When playing back presentations that include VDS (Audio Description) dialogue objects. The main audio is not ducked as it should be but rather everything is statically mixed. To add the ducking requires a new custom gstreamer plug-in so this is unlikely to fixed in the next version.
 
 
 ## License
 
  AM Viewer
- Copyright (c) 2020, Dolby Laboratories Inc.
+ Copyright (c) 2023, Dolby Laboratories Inc.
  All rights reserved.
-
+ 
  Redistribution and use in source and binary forms, with or without modification, are permitted
  provided that the following conditions are met:
-
+ 
  1. Redistributions of source code must retain the above copyright notice,
  this list of conditions and the following disclaimer.
-
+    
  2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions
     and the following disclaimer in the documentation and/or other materials provided with the distribution.
-
+    
  3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or
     promote products derived from this software without specific prior written permission.
-
+ 
  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR APARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-
```

## Comparing `am_viewer-3.9.dist-info/RECORD` & `am_viewer-4.0.dist-info/RECORD`

 * *Files 22% similar despite different names*

```diff
@@ -1,26 +1,26 @@
 adm/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-adm/adm_classes.py,sha256=rgQX9dcgyhH-HK4gjr8HbAKFhY5U_HGlwW63LPsmny0,24641
-adm/adm_const.py,sha256=jOH2b2Tj0uNus_b-A6F7KRWmr19EgaM1EczixgpZObg,11741
-adm/adm_tool.py,sha256=g8R3QelOYaQ2Ho_M1kRmA50r2FsR18OgcskAIuIYbcI,41926
+adm/adm_classes.py,sha256=_HCEl614CWykZau00y88joY4wjua-WJz-wpCGnioThE,25731
+adm/adm_const.py,sha256=rLLB1saKETuR6yy3Gs8YDG1smwssjJvQJ6L9fHw2SWA,12258
+adm/adm_tool.py,sha256=sqKadDCQ9s_u-lu5QxC0qBEeOcHBHOqWgekMRPpSjf0,52280
 adm/limits.txt,sha256=fFYA00fY3Aht3TifXTMtJy6xHnFWvV5zOdjvswErTEc,381
 am_viewer/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-am_viewer/am_viewer.py,sha256=FIwW5eJadslPWNMrkwc30OWCYdDsidzRAPew0k5EUjo,78208
+am_viewer/am_viewer.py,sha256=X0uMPXJVVlfb8PrZfREfPLNxby-txytKXd1OGR3bD_M,85448
 am_viewer/am_xml_viewer.py,sha256=06MQbE6qrfRKN-7k82IoDhSdzQ_x6FDhX9p90IPJLKM,7594
 am_viewer/pmd_tool.Darwin,sha256=xEcWln-x1ak_CwC_Vdr2alpi0FvYWftMDgoCBRiG04M,443892
 am_viewer/pmd_tool.Linux,sha256=93NFFOI6OFLSVC4faPfahjz0dzJDyYmDNQXhxrqv9yo,490960
 am_viewer/pmd_tool.Windows.exe,sha256=U05SdVRGge2idAexnEipBp-oOTsxcczQWWX3XEEeC4c,515584
-am_viewer-3.9.data/scripts/am_viewer,sha256=PXtIke0eAYcu4EgJXLwJ-PO7iAbyAFojB_Chj55baO4,62
+am_viewer-4.0.data/scripts/am_viewer,sha256=PXtIke0eAYcu4EgJXLwJ-PO7iAbyAFojB_Chj55baO4,62
 aoip_services/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 aoip_services/aoip_discovery.py,sha256=diZE_vGb5SUGEiNzIs6qhJF830djBb4JA-dnaNvzKIA,12610
 aoip_services/multicast.py,sha256=OeNw6Bgk81xwiLLiFJQVL32A1IdLZgpKfVt9pQgxRa0,3729
-aoip_services/sdp_parser.py,sha256=Mt5T8KN_7ZCeH97k_rLM5vNhf9BYyXZtgbzKaiNi2Ec,3455
+aoip_services/sdp_parser.py,sha256=s5DMO4L85nRWFZ0i9zSJSyXKJWfrHtJTfN1KUkJXEP4,3455
 pmd/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-pmd/pmd_classes.py,sha256=ASsk3IxvSzLvvwNIBxAqHKq5Wp_h_4Hlq4ubeb_D49w,6993
-pmd/pmd_const.py,sha256=T7YsjPSxy8hAJdepfZa28nof8tHJJDbkLu-9KWSkuvc,10146
-pmd/pmd_tool.py,sha256=B72BHs5MuiPRiObk5srEkrGQQaGh6huEdmMEFJZWRLA,64327
-am_viewer-3.9.dist-info/LICENSE,sha256=DohLE3SsjQF6WQcxwVny7NL-lstBK8V0SsX6_hrAtI0,1531
-am_viewer-3.9.dist-info/METADATA,sha256=Za6wt-cwUKe7V6M-Zj1SzijGNYOZCO0CcjyfqXOHvH8,8484
-am_viewer-3.9.dist-info/WHEEL,sha256=g4nMs7d-Xl9-xC9XovUrsDHGXt-FT0E17Yqo92DEfvY,92
-am_viewer-3.9.dist-info/entry_points.txt,sha256=_rqFv6fjDM3968VPJkR33yUiDwNtlyXggRtoJLDDFxs,54
-am_viewer-3.9.dist-info/top_level.txt,sha256=LI-8moOgh20lXFFmmybtQ977IOqL1J0mEjo5txJSJS8,32
-am_viewer-3.9.dist-info/RECORD,,
+pmd/pmd_classes.py,sha256=DPeJlC6qeWoLhQbN0cFzw0vc1b0YXJWCSO8ZX53gYZM,10914
+pmd/pmd_const.py,sha256=95VXywLtQQsdCxHmG1EMGDpp_WJdENeRo8wb26CWtSY,10249
+pmd/pmd_tool.py,sha256=pa4eYYUGKde0zBTcZN5Uew3gkIqhKOihiFoN3O03Z1s,79111
+am_viewer-4.0.dist-info/LICENSE,sha256=DohLE3SsjQF6WQcxwVny7NL-lstBK8V0SsX6_hrAtI0,1531
+am_viewer-4.0.dist-info/METADATA,sha256=ZAPauJT3qYBmlUOdmpt3JGh5hK5r5HVs4fBlnfsqSWo,8549
+am_viewer-4.0.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+am_viewer-4.0.dist-info/entry_points.txt,sha256=BLdVKoC8COyXlKSzG5coHm-HXbcPdmgkhHIzQkDPIPI,55
+am_viewer-4.0.dist-info/top_level.txt,sha256=LI-8moOgh20lXFFmmybtQ977IOqL1J0mEjo5txJSJS8,32
+am_viewer-4.0.dist-info/RECORD,,
```

