# Comparing `tmp/austrakka-0.31.0-py3-none-any.whl.zip` & `tmp/austrakka-0.32.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,89 +1,89 @@
-Zip file size: 67121 bytes, number of entries: 87
--rw-r--r--  2.0 unx      128 b- defN 23-Jul-10 11:32 austrakka/__init__.py
--rw-r--r--  2.0 unx     4066 b- defN 23-Jul-10 11:32 austrakka/main.py
--rw-r--r--  2.0 unx        0 b- defN 23-Jul-10 11:32 austrakka/components/__init__.py
--rw-r--r--  2.0 unx     2526 b- defN 23-Jul-10 11:32 austrakka/components/analysis/__init__.py
--rw-r--r--  2.0 unx     1851 b- defN 23-Jul-10 11:32 austrakka/components/analysis/funcs.py
--rw-r--r--  2.0 unx     1449 b- defN 23-Jul-10 11:32 austrakka/components/analysis/definition/__init__.py
--rw-r--r--  2.0 unx     1165 b- defN 23-Jul-10 11:32 austrakka/components/analysis/definition/funcs.py
--rw-r--r--  2.0 unx      721 b- defN 23-Jul-10 11:32 austrakka/components/auth/__init__.py
--rw-r--r--  2.0 unx      273 b- defN 23-Jul-10 11:32 austrakka/components/auth/enums.py
--rw-r--r--  2.0 unx     1285 b- defN 23-Jul-10 11:32 austrakka/components/auth/funcs.py
--rw-r--r--  2.0 unx      380 b- defN 23-Jul-10 11:32 austrakka/components/dashboard/__init__.py
--rw-r--r--  2.0 unx     1848 b- defN 23-Jul-10 11:32 austrakka/components/dashboard/project/__init__.py
--rw-r--r--  2.0 unx     1830 b- defN 23-Jul-10 11:32 austrakka/components/dashboard/project/funcs.py
--rw-r--r--  2.0 unx     3628 b- defN 23-Jul-10 11:32 austrakka/components/field/__init__.py
--rw-r--r--  2.0 unx     4504 b- defN 23-Jul-10 11:32 austrakka/components/field/funcs.py
--rw-r--r--  2.0 unx     1745 b- defN 23-Jul-10 11:32 austrakka/components/fieldtype/__init__.py
--rw-r--r--  2.0 unx     1720 b- defN 23-Jul-10 11:32 austrakka/components/fieldtype/funcs.py
--rw-r--r--  2.0 unx      945 b- defN 23-Jul-10 11:32 austrakka/components/fieldtype/value/__init__.py
--rw-r--r--  2.0 unx      562 b- defN 23-Jul-10 11:32 austrakka/components/fieldtype/value/funcs.py
--rw-r--r--  2.0 unx     2317 b- defN 23-Jul-10 11:32 austrakka/components/group/__init__.py
--rw-r--r--  2.0 unx     2369 b- defN 23-Jul-10 11:32 austrakka/components/group/funcs.py
--rw-r--r--  2.0 unx     1185 b- defN 23-Jul-10 11:32 austrakka/components/group/field/__init__.py
--rw-r--r--  2.0 unx     1322 b- defN 23-Jul-10 11:32 austrakka/components/group/field/funcs.py
--rw-r--r--  2.0 unx     1937 b- defN 23-Jul-10 11:32 austrakka/components/metadata/__init__.py
--rw-r--r--  2.0 unx     1828 b- defN 23-Jul-10 11:32 austrakka/components/metadata/funcs.py
--rw-r--r--  2.0 unx     1575 b- defN 23-Jul-10 11:32 austrakka/components/org/__init__.py
--rw-r--r--  2.0 unx     1481 b- defN 23-Jul-10 11:32 austrakka/components/org/funcs.py
--rw-r--r--  2.0 unx     2776 b- defN 23-Jul-10 11:32 austrakka/components/plot/__init__.py
--rw-r--r--  2.0 unx     2922 b- defN 23-Jul-10 11:32 austrakka/components/plot/funcs.py
--rw-r--r--  2.0 unx     5413 b- defN 23-Jul-10 11:32 austrakka/components/proforma/__init__.py
--rw-r--r--  2.0 unx     6100 b- defN 23-Jul-10 11:32 austrakka/components/proforma/funcs.py
--rw-r--r--  2.0 unx     1888 b- defN 23-Jul-10 11:32 austrakka/components/project/__init__.py
--rw-r--r--  2.0 unx     1396 b- defN 23-Jul-10 11:32 austrakka/components/project/funcs.py
--rw-r--r--  2.0 unx     1802 b- defN 23-Jul-10 11:32 austrakka/components/sample/__init__.py
--rw-r--r--  2.0 unx     1103 b- defN 23-Jul-10 11:32 austrakka/components/sample/funcs.py
--rw-r--r--  2.0 unx     1764 b- defN 23-Jul-10 11:32 austrakka/components/sequence/__init__.py
--rw-r--r--  2.0 unx    14733 b- defN 23-Jul-10 11:32 austrakka/components/sequence/funcs.py
--rw-r--r--  2.0 unx     1824 b- defN 23-Jul-10 11:32 austrakka/components/sequence/add/__init__.py
--rw-r--r--  2.0 unx      852 b- defN 23-Jul-10 11:32 austrakka/components/sequence/sync/__init__.py
--rw-r--r--  2.0 unx     1431 b- defN 23-Jul-10 11:32 austrakka/components/sequence/sync/constant.py
--rw-r--r--  2.0 unx      127 b- defN 23-Jul-10 11:32 austrakka/components/sequence/sync/errors.py
--rw-r--r--  2.0 unx     2128 b- defN 23-Jul-10 11:32 austrakka/components/sequence/sync/funcs.py
--rw-r--r--  2.0 unx     3802 b- defN 23-Jul-10 11:32 austrakka/components/sequence/sync/state_machine.py
--rw-r--r--  2.0 unx     1683 b- defN 23-Jul-10 11:32 austrakka/components/sequence/sync/sync_io.py
--rw-r--r--  2.0 unx     2188 b- defN 23-Jul-10 11:32 austrakka/components/sequence/sync/sync_state.py
--rw-r--r--  2.0 unx     2437 b- defN 23-Jul-10 11:32 austrakka/components/sequence/sync/sync_validator.py
--rw-r--r--  2.0 unx    17606 b- defN 23-Jul-10 11:32 austrakka/components/sequence/sync/sync_workflow.py
--rw-r--r--  2.0 unx      744 b- defN 23-Jul-10 11:32 austrakka/components/tree/__init__.py
--rw-r--r--  2.0 unx      876 b- defN 23-Jul-10 11:32 austrakka/components/tree/funcs.py
--rw-r--r--  2.0 unx     1291 b- defN 23-Jul-10 11:32 austrakka/components/user/__init__.py
--rw-r--r--  2.0 unx     2342 b- defN 23-Jul-10 11:32 austrakka/components/user/funcs.py
--rw-r--r--  2.0 unx     1295 b- defN 23-Jul-10 11:32 austrakka/components/widget/__init__.py
--rw-r--r--  2.0 unx     1099 b- defN 23-Jul-10 11:32 austrakka/components/widget/funcs.py
--rw-r--r--  2.0 unx        0 b- defN 23-Jul-10 11:32 austrakka/utils/__init__.py
--rw-r--r--  2.0 unx     5227 b- defN 23-Jul-10 11:32 austrakka/utils/api.py
--rw-r--r--  2.0 unx      226 b- defN 23-Jul-10 11:32 austrakka/utils/cmd_filter.py
--rw-r--r--  2.0 unx      296 b- defN 23-Jul-10 11:32 austrakka/utils/context.py
--rw-r--r--  2.0 unx     1161 b- defN 23-Jul-10 11:32 austrakka/utils/exceptions.py
--rw-r--r--  2.0 unx      277 b- defN 23-Jul-10 11:32 austrakka/utils/fs.py
--rw-r--r--  2.0 unx      864 b- defN 23-Jul-10 11:32 austrakka/utils/logger.py
--rw-r--r--  2.0 unx     3069 b- defN 23-Jul-10 11:32 austrakka/utils/misc.py
--rw-r--r--  2.0 unx    11587 b- defN 23-Jul-10 11:32 austrakka/utils/options.py
--rw-r--r--  2.0 unx     5327 b- defN 23-Jul-10 11:32 austrakka/utils/output.py
--rw-r--r--  2.0 unx      674 b- defN 23-Jul-10 11:32 austrakka/utils/paths.py
--rw-r--r--  2.0 unx      646 b- defN 23-Jul-10 11:32 austrakka/utils/retry.py
--rw-r--r--  2.0 unx     1227 b- defN 23-Jul-10 11:32 austrakka/utils/version.py
--rw-r--r--  2.0 unx        0 b- defN 23-Jul-10 11:32 austrakka/utils/enums/__init__.py
--rw-r--r--  2.0 unx      255 b- defN 23-Jul-10 11:32 austrakka/utils/enums/api.py
--rw-r--r--  2.0 unx       80 b- defN 23-Jul-10 11:32 austrakka/utils/enums/countries.py
--rw-r--r--  2.0 unx      377 b- defN 23-Jul-10 11:32 austrakka/utils/enums/seq.py
--rw-r--r--  2.0 unx      188 b- defN 23-Jul-10 11:32 austrakka/utils/enums/states.py
--rw-r--r--  2.0 unx        0 b- defN 23-Jul-10 11:32 austrakka/utils/helpers/__init__.py
--rw-r--r--  2.0 unx      199 b- defN 23-Jul-10 11:32 austrakka/utils/helpers/analysis.py
--rw-r--r--  2.0 unx      200 b- defN 23-Jul-10 11:32 austrakka/utils/helpers/definition.py
--rw-r--r--  2.0 unx      468 b- defN 23-Jul-10 11:32 austrakka/utils/helpers/fields.py
--rw-r--r--  2.0 unx      212 b- defN 23-Jul-10 11:32 austrakka/utils/helpers/fieldtype.py
--rw-r--r--  2.0 unx      177 b- defN 23-Jul-10 11:32 austrakka/utils/helpers/groups.py
--rw-r--r--  2.0 unx      177 b- defN 23-Jul-10 11:32 austrakka/utils/helpers/orgs.py
--rw-r--r--  2.0 unx      575 b- defN 23-Jul-10 11:32 austrakka/utils/helpers/output.py
--rw-r--r--  2.0 unx      187 b- defN 23-Jul-10 11:32 austrakka/utils/helpers/plots.py
--rw-r--r--  2.0 unx      196 b- defN 23-Jul-10 11:32 austrakka/utils/helpers/project.py
--rw-r--r--  2.0 unx      727 b- defN 23-Jul-10 11:32 austrakka/utils/helpers/upload.py
--rw-r--r--  2.0 unx     7897 b- defN 23-Jul-10 11:33 austrakka-0.31.0.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Jul-10 11:33 austrakka-0.31.0.dist-info/WHEEL
--rw-r--r--  2.0 unx       50 b- defN 23-Jul-10 11:33 austrakka-0.31.0.dist-info/entry_points.txt
--rw-r--r--  2.0 unx       10 b- defN 23-Jul-10 11:33 austrakka-0.31.0.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     8011 b- defN 23-Jul-10 11:33 austrakka-0.31.0.dist-info/RECORD
-87 files, 176921 bytes uncompressed, 54183 bytes compressed:  69.4%
+Zip file size: 68743 bytes, number of entries: 87
+-rw-r--r--  2.0 unx      128 b- defN 23-Jul-17 00:20 austrakka/__init__.py
+-rw-r--r--  2.0 unx     4066 b- defN 23-Jul-17 00:20 austrakka/main.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jul-17 00:20 austrakka/components/__init__.py
+-rw-r--r--  2.0 unx     2526 b- defN 23-Jul-17 00:20 austrakka/components/analysis/__init__.py
+-rw-r--r--  2.0 unx     1851 b- defN 23-Jul-17 00:20 austrakka/components/analysis/funcs.py
+-rw-r--r--  2.0 unx     1449 b- defN 23-Jul-17 00:20 austrakka/components/analysis/definition/__init__.py
+-rw-r--r--  2.0 unx     1165 b- defN 23-Jul-17 00:20 austrakka/components/analysis/definition/funcs.py
+-rw-r--r--  2.0 unx      721 b- defN 23-Jul-17 00:20 austrakka/components/auth/__init__.py
+-rw-r--r--  2.0 unx      273 b- defN 23-Jul-17 00:20 austrakka/components/auth/enums.py
+-rw-r--r--  2.0 unx     1285 b- defN 23-Jul-17 00:20 austrakka/components/auth/funcs.py
+-rw-r--r--  2.0 unx      380 b- defN 23-Jul-17 00:20 austrakka/components/dashboard/__init__.py
+-rw-r--r--  2.0 unx     1848 b- defN 23-Jul-17 00:20 austrakka/components/dashboard/project/__init__.py
+-rw-r--r--  2.0 unx     1830 b- defN 23-Jul-17 00:20 austrakka/components/dashboard/project/funcs.py
+-rw-r--r--  2.0 unx     3628 b- defN 23-Jul-17 00:20 austrakka/components/field/__init__.py
+-rw-r--r--  2.0 unx     4504 b- defN 23-Jul-17 00:20 austrakka/components/field/funcs.py
+-rw-r--r--  2.0 unx     1745 b- defN 23-Jul-17 00:20 austrakka/components/fieldtype/__init__.py
+-rw-r--r--  2.0 unx     1720 b- defN 23-Jul-17 00:20 austrakka/components/fieldtype/funcs.py
+-rw-r--r--  2.0 unx      945 b- defN 23-Jul-17 00:20 austrakka/components/fieldtype/value/__init__.py
+-rw-r--r--  2.0 unx      562 b- defN 23-Jul-17 00:20 austrakka/components/fieldtype/value/funcs.py
+-rw-r--r--  2.0 unx     2317 b- defN 23-Jul-17 00:20 austrakka/components/group/__init__.py
+-rw-r--r--  2.0 unx     2369 b- defN 23-Jul-17 00:20 austrakka/components/group/funcs.py
+-rw-r--r--  2.0 unx     1185 b- defN 23-Jul-17 00:20 austrakka/components/group/field/__init__.py
+-rw-r--r--  2.0 unx     1322 b- defN 23-Jul-17 00:20 austrakka/components/group/field/funcs.py
+-rw-r--r--  2.0 unx     2141 b- defN 23-Jul-17 00:20 austrakka/components/metadata/__init__.py
+-rw-r--r--  2.0 unx     2095 b- defN 23-Jul-17 00:20 austrakka/components/metadata/funcs.py
+-rw-r--r--  2.0 unx     1575 b- defN 23-Jul-17 00:20 austrakka/components/org/__init__.py
+-rw-r--r--  2.0 unx     1481 b- defN 23-Jul-17 00:20 austrakka/components/org/funcs.py
+-rw-r--r--  2.0 unx     2776 b- defN 23-Jul-17 00:20 austrakka/components/plot/__init__.py
+-rw-r--r--  2.0 unx     2922 b- defN 23-Jul-17 00:20 austrakka/components/plot/funcs.py
+-rw-r--r--  2.0 unx     5413 b- defN 23-Jul-17 00:20 austrakka/components/proforma/__init__.py
+-rw-r--r--  2.0 unx     6100 b- defN 23-Jul-17 00:20 austrakka/components/proforma/funcs.py
+-rw-r--r--  2.0 unx     1888 b- defN 23-Jul-17 00:20 austrakka/components/project/__init__.py
+-rw-r--r--  2.0 unx     1396 b- defN 23-Jul-17 00:20 austrakka/components/project/funcs.py
+-rw-r--r--  2.0 unx     1802 b- defN 23-Jul-17 00:20 austrakka/components/sample/__init__.py
+-rw-r--r--  2.0 unx     1103 b- defN 23-Jul-17 00:20 austrakka/components/sample/funcs.py
+-rw-r--r--  2.0 unx     1764 b- defN 23-Jul-17 00:20 austrakka/components/sequence/__init__.py
+-rw-r--r--  2.0 unx    14992 b- defN 23-Jul-17 00:20 austrakka/components/sequence/funcs.py
+-rw-r--r--  2.0 unx     2261 b- defN 23-Jul-17 00:20 austrakka/components/sequence/add/__init__.py
+-rw-r--r--  2.0 unx     1124 b- defN 23-Jul-17 00:20 austrakka/components/sequence/sync/__init__.py
+-rw-r--r--  2.0 unx     1557 b- defN 23-Jul-17 00:20 austrakka/components/sequence/sync/constant.py
+-rw-r--r--  2.0 unx      127 b- defN 23-Jul-17 00:20 austrakka/components/sequence/sync/errors.py
+-rw-r--r--  2.0 unx     2246 b- defN 23-Jul-17 00:20 austrakka/components/sequence/sync/funcs.py
+-rw-r--r--  2.0 unx     3802 b- defN 23-Jul-17 00:20 austrakka/components/sequence/sync/state_machine.py
+-rw-r--r--  2.0 unx     2140 b- defN 23-Jul-17 00:20 austrakka/components/sequence/sync/sync_io.py
+-rw-r--r--  2.0 unx     2020 b- defN 23-Jul-17 00:20 austrakka/components/sequence/sync/sync_state.py
+-rw-r--r--  2.0 unx     2437 b- defN 23-Jul-17 00:20 austrakka/components/sequence/sync/sync_validator.py
+-rw-r--r--  2.0 unx    21993 b- defN 23-Jul-17 00:20 austrakka/components/sequence/sync/sync_workflow.py
+-rw-r--r--  2.0 unx      744 b- defN 23-Jul-17 00:20 austrakka/components/tree/__init__.py
+-rw-r--r--  2.0 unx      876 b- defN 23-Jul-17 00:20 austrakka/components/tree/funcs.py
+-rw-r--r--  2.0 unx     1754 b- defN 23-Jul-17 00:20 austrakka/components/user/__init__.py
+-rw-r--r--  2.0 unx     2564 b- defN 23-Jul-17 00:20 austrakka/components/user/funcs.py
+-rw-r--r--  2.0 unx     1295 b- defN 23-Jul-17 00:20 austrakka/components/widget/__init__.py
+-rw-r--r--  2.0 unx     1099 b- defN 23-Jul-17 00:20 austrakka/components/widget/funcs.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jul-17 00:20 austrakka/utils/__init__.py
+-rw-r--r--  2.0 unx     5227 b- defN 23-Jul-17 00:20 austrakka/utils/api.py
+-rw-r--r--  2.0 unx      226 b- defN 23-Jul-17 00:20 austrakka/utils/cmd_filter.py
+-rw-r--r--  2.0 unx      296 b- defN 23-Jul-17 00:20 austrakka/utils/context.py
+-rw-r--r--  2.0 unx     1161 b- defN 23-Jul-17 00:20 austrakka/utils/exceptions.py
+-rw-r--r--  2.0 unx      277 b- defN 23-Jul-17 00:20 austrakka/utils/fs.py
+-rw-r--r--  2.0 unx      864 b- defN 23-Jul-17 00:20 austrakka/utils/logger.py
+-rw-r--r--  2.0 unx     3069 b- defN 23-Jul-17 00:20 austrakka/utils/misc.py
+-rw-r--r--  2.0 unx    12775 b- defN 23-Jul-17 00:20 austrakka/utils/options.py
+-rw-r--r--  2.0 unx     5327 b- defN 23-Jul-17 00:20 austrakka/utils/output.py
+-rw-r--r--  2.0 unx      674 b- defN 23-Jul-17 00:20 austrakka/utils/paths.py
+-rw-r--r--  2.0 unx      646 b- defN 23-Jul-17 00:20 austrakka/utils/retry.py
+-rw-r--r--  2.0 unx     1227 b- defN 23-Jul-17 00:20 austrakka/utils/version.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jul-17 00:20 austrakka/utils/enums/__init__.py
+-rw-r--r--  2.0 unx      255 b- defN 23-Jul-17 00:20 austrakka/utils/enums/api.py
+-rw-r--r--  2.0 unx       80 b- defN 23-Jul-17 00:20 austrakka/utils/enums/countries.py
+-rw-r--r--  2.0 unx      377 b- defN 23-Jul-17 00:20 austrakka/utils/enums/seq.py
+-rw-r--r--  2.0 unx      188 b- defN 23-Jul-17 00:20 austrakka/utils/enums/states.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jul-17 00:20 austrakka/utils/helpers/__init__.py
+-rw-r--r--  2.0 unx      199 b- defN 23-Jul-17 00:20 austrakka/utils/helpers/analysis.py
+-rw-r--r--  2.0 unx      200 b- defN 23-Jul-17 00:20 austrakka/utils/helpers/definition.py
+-rw-r--r--  2.0 unx      468 b- defN 23-Jul-17 00:20 austrakka/utils/helpers/fields.py
+-rw-r--r--  2.0 unx      212 b- defN 23-Jul-17 00:20 austrakka/utils/helpers/fieldtype.py
+-rw-r--r--  2.0 unx      177 b- defN 23-Jul-17 00:20 austrakka/utils/helpers/groups.py
+-rw-r--r--  2.0 unx      177 b- defN 23-Jul-17 00:20 austrakka/utils/helpers/orgs.py
+-rw-r--r--  2.0 unx      575 b- defN 23-Jul-17 00:20 austrakka/utils/helpers/output.py
+-rw-r--r--  2.0 unx      187 b- defN 23-Jul-17 00:20 austrakka/utils/helpers/plots.py
+-rw-r--r--  2.0 unx      196 b- defN 23-Jul-17 00:20 austrakka/utils/helpers/project.py
+-rw-r--r--  2.0 unx      727 b- defN 23-Jul-17 00:20 austrakka/utils/helpers/upload.py
+-rw-r--r--  2.0 unx     7897 b- defN 23-Jul-17 00:20 austrakka-0.32.0.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Jul-17 00:20 austrakka-0.32.0.dist-info/WHEEL
+-rw-r--r--  2.0 unx       50 b- defN 23-Jul-17 00:20 austrakka-0.32.0.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx       10 b- defN 23-Jul-17 00:20 austrakka-0.32.0.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     8012 b- defN 23-Jul-17 00:20 austrakka-0.32.0.dist-info/RECORD
+87 files, 185154 bytes uncompressed, 55805 bytes compressed:  69.9%
```

## zipnote {}

```diff
@@ -240,23 +240,23 @@
 
 Filename: austrakka/utils/helpers/project.py
 Comment: 
 
 Filename: austrakka/utils/helpers/upload.py
 Comment: 
 
-Filename: austrakka-0.31.0.dist-info/METADATA
+Filename: austrakka-0.32.0.dist-info/METADATA
 Comment: 
 
-Filename: austrakka-0.31.0.dist-info/WHEEL
+Filename: austrakka-0.32.0.dist-info/WHEEL
 Comment: 
 
-Filename: austrakka-0.31.0.dist-info/entry_points.txt
+Filename: austrakka-0.32.0.dist-info/entry_points.txt
 Comment: 
 
-Filename: austrakka-0.31.0.dist-info/top_level.txt
+Filename: austrakka-0.32.0.dist-info/top_level.txt
 Comment: 
 
-Filename: austrakka-0.31.0.dist-info/RECORD
+Filename: austrakka-0.32.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## austrakka/__init__.py

```diff
@@ -1,3 +1,3 @@
 # NOTE: do not change the name of this variable or the quote type,
 # doing so will break github actions.
-__version__ = "0.31.0"
+__version__ = "0.32.0"
```

## austrakka/components/metadata/__init__.py

```diff
@@ -1,14 +1,15 @@
 # pylint: disable=redefined-outer-name
 from io import BufferedReader
 import click
 
 from austrakka.utils.options import opt_proforma
 from austrakka.utils.options import opt_is_append
 from austrakka.utils.options import opt_group_name
+from austrakka.utils.options import opt_blanks_delete
 from austrakka.components.metadata.funcs import add_metadata
 from austrakka.components.metadata.funcs import validate_metadata
 from austrakka.components.metadata.funcs import append_metadata
 from austrakka.components.metadata.funcs import list_metadata
 from austrakka.utils.output import table_format_option
 
 
@@ -18,30 +19,32 @@
     """Commands related to metadata submissions"""
     ctx.context = ctx.parent.context
 
 
 @metadata.command('add')
 @click.argument('file', type=click.File('rb'))
 @opt_proforma()
-def submission_add(file: BufferedReader, proforma: str):
+@opt_blanks_delete()
+def submission_add(file: BufferedReader, proforma: str, blanks_will_delete: bool = False):
     """Upload metadata submission to AusTrakka"""
-    add_metadata(file, proforma)
+    add_metadata(file, proforma, blanks_will_delete)
 
 
 @metadata.command('append')
 @click.argument('file', type=click.File('rb'))
 @opt_proforma()
-def submission_append(file: BufferedReader, proforma: str):
+@opt_blanks_delete()
+def submission_append(file: BufferedReader, proforma: str, blanks_will_delete: bool = False):
     """
     Upload metadata to be appended to existing samples.
     The append operation does not require (or accept) Owner_group.
     The specified pro forma must contain Seq_ID and metadata fields
     to be updated. All samples must already exist in AusTrakka.
     """
-    append_metadata(file, proforma)
+    append_metadata(file, proforma, blanks_will_delete)
 
 
 @metadata.command('validate')
 @click.argument('file', type=click.File('rb'))
 @opt_proforma()
 @opt_is_append()
 def submission_validate(file: BufferedReader, proforma: str, is_append: bool):
```

## austrakka/components/metadata/funcs.py

```diff
@@ -7,31 +7,38 @@
 from austrakka.utils.helpers.groups import get_group_by_name
 from austrakka.utils.helpers.output import call_get_and_print_table
 
 SUBMISSION_UPLOAD = 'UploadSubmissions'
 SUBMISSION_UPLOAD_APPEND = 'UploadSubmissions?appendMode=True'
 SUBMISSION_VALIDATE = 'ValidateSubmissions'
 SUBMISSION_VALIDATE_APPEND = 'ValidateSubmissions?appendMode=True'
+DELETE_ON_BLANK_PARAM = 'deleteOnBlank=True'
 
 
 @logger_wraps()
 def add_metadata(
     file: BufferedReader,
-    proforma_abbrev: str
+    proforma_abbrev: str,
+        blanks_will_delete: bool,
 ):
     path = "/".join([SUBMISSION_PATH, SUBMISSION_UPLOAD])
+    if blanks_will_delete:
+        path = f"{path}?{DELETE_ON_BLANK_PARAM}"
     _call_submission(path, file, proforma_abbrev)
 
 
 @logger_wraps()
 def append_metadata(
     file: BufferedReader,
-    proforma_abbrev: str
+    proforma_abbrev: str,
+        blanks_will_delete: bool,
 ):
     path = "/".join([SUBMISSION_PATH, SUBMISSION_UPLOAD_APPEND])
+    if blanks_will_delete:
+        path = f"{path}&{DELETE_ON_BLANK_PARAM}"
     _call_submission(path, file, proforma_abbrev)
 
 
 @logger_wraps()
 def validate_metadata(
     file: BufferedReader,
     proforma_abbrev: str,
```

## austrakka/components/sequence/funcs.py

```diff
@@ -15,15 +15,14 @@
 from httpx import HTTPStatusError
 from Bio import SeqIO
 
 from austrakka.utils.exceptions import FailedResponseException
 from austrakka.utils.exceptions import UnknownResponseException
 from austrakka.utils.exceptions import IncorrectHashException
 from austrakka.utils.misc import logger_wraps
-from austrakka.utils.api import api_post_multipart
 from austrakka.utils.api import api_post_multipart_raw
 from austrakka.utils.api import api_get
 from austrakka.utils.api import get_response
 from austrakka.utils.api import api_get_stream
 from austrakka.utils.enums.api import RESPONSE_TYPE_ERROR
 from austrakka.utils.paths import SEQUENCE_PATH
 from austrakka.utils.paths import SEQUENCE_BY_GROUP_PATH
@@ -69,15 +68,19 @@
 @dataclass
 class FileHash:
     filename: str
     sha256: str
 
 
 @logger_wraps()
-def add_fasta_submission(fasta_file: BufferedReader):
+def add_fasta_submission(
+        fasta_file: BufferedReader,
+        skip: bool = False,
+        force: bool = False):
+
     name_prefix = _calc_name_prefix(fasta_file)
 
     for record in SeqIO.parse(TextIOWrapper(fasta_file), 'fasta'):
         seq_id = record.id
         logger.info(f"Uploading {seq_id}")
 
         csv, csv_filename, single_contig_filename = _gen_csv(
@@ -90,18 +93,21 @@
             record,
             single_contig_filename)
 
         file_hash = _fasta_hash(
             single_contig,
             single_contig_filename)
 
+        custom_headers = {}
+        set_upload_mode(custom_headers, force, skip)
+
         try:
             retry(
-                func=lambda f=files, fh=file_hash: _post_fasta(f, fh),
-                retries=2,
+                func=lambda f=files, fh=file_hash, ch=custom_headers: _post_fasta(f, fh, ch),
+                retries=1,
                 desc=f"{seq_id} at " + "/".join([SEQUENCE_PATH, FASTA_PATH]),
                 delay=0.0
             )
         except FailedResponseException as ex:
             logger.error(f'Sample {seq_id} failed upload')
             log_response(ex.parsed_resp)
         except (
@@ -202,21 +208,24 @@
                 for f in hashes
         ):
             errors.append(f'Hash for {seq["originalFileName"]} is not correct')
     if any(errors):
         raise IncorrectHashException(", ".join(errors))
 
 
-def _post_fasta(sample_files, file_hash: FileHash):
-    resp = api_post_multipart(
+def _post_fasta(sample_files, file_hash: FileHash, custom_headers: dict):
+    resp = api_post_multipart_raw(
         path="/".join([SEQUENCE_PATH, FASTA_PATH]),
-        files=sample_files
+        files=sample_files,
+        custom_headers=custom_headers,
     )
 
-    _verify_hash(list([file_hash]), resp)
+    data = get_response(resp, True)
+    if resp.status_code == 200:
+        _verify_hash(list([file_hash]), data)
 
 
 @logger_wraps()
 def add_fastq_submission(
         csv: BufferedReader,
         skip: bool = False,
         force: bool = False):
```

## austrakka/components/sequence/add/__init__.py

```diff
@@ -39,21 +39,30 @@
             filepath2: The local path of the second read to be uploaded
     """
     add_fastq_submission(csv_file, skip, force)
 
 
 @add.command('fasta')
 @click.argument('fasta_file', type=click.File('rb'))
+@option('--skip', cls=MutuallyExclusiveOption,
+        help="Skip this command if the sample has existing fasta sequences.",
+        mutually_exclusive=["force"],
+        is_flag=True)
+@option('--force',
+        cls=MutuallyExclusiveOption,
+        help="Upload fasta sequences and supersede any existing fasta sequences.",
+        mutually_exclusive=["skip"],
+        is_flag=True)
 def seq_add_fasta(
-        fasta_file: BufferedReader
+        fasta_file: BufferedReader, skip: bool = False, force: bool = False
 ):
     """
     Upload FASTA submission to AusTrakka
 
     A single FASTA file should be supplied.
     Contig names must correspond to known Seq_IDs.
 
     If no record exists for these Seq_IDs you can first add them with the
     `austrakka metadata add` command, and may use the minimal proforma if
     you wish to specify no metadata other than sample ownership.
     """
-    add_fasta_submission(fasta_file)
+    add_fasta_submission(fasta_file, skip, force)
```

## austrakka/components/sequence/sync/__init__.py

```diff
@@ -1,28 +1,41 @@
 import click
+from click import option
 
 from austrakka.utils.options import opt_output_dir
 from austrakka.utils.options import opt_group
-from austrakka.utils.options import opt_hash_check
+from austrakka.utils.options import opt_recalc_hash
 from austrakka.utils.options import opt_seq_type
 from .funcs import seq_get
 
 
 @click.group()
 @click.pass_context
 def sync(ctx):
     """Commands to sync sequences from server to disk"""
     ctx.context = ctx.parent.context
 
 
 @sync.command('get')
 @opt_output_dir()
 @opt_group(default=None, multiple=False, required=True)
-@opt_hash_check()
+@opt_recalc_hash()
 @opt_seq_type(required=True)
-def get_seq(output_dir: str, group_name: str, hash_check: bool, seq_type: str):
+@option('--reset', help="Reset sync state; do not try to resume an "
+                        "interrupted sync", is_flag=True)
+def get_seq(
+        output_dir: str,
+        group_name: str,
+        recalculate_hashes: bool,
+        seq_type: str,
+        reset: bool):
     """
     Download sequence files from server to disk. Patches any local
     files that have drifted, and soft-purge local files which are
     no longer shared with the group.
     """
-    seq_get(output_dir, group_name, hash_check, seq_type)
+    seq_get(
+        output_dir,
+        group_name,
+        recalculate_hashes,
+        seq_type,
+        reset)
```

## austrakka/components/sequence/sync/constant.py

```diff
@@ -1,15 +1,15 @@
 # Sync state key constants
 MANIFEST_KEY = 'manifest'
 INTERMEDIATE_MANIFEST_FILE_KEY = 'intermediate_manifest_file'
 GROUP_NAME_KEY = 'group_name'
 SEQ_TYPE_KEY = 'seq_type'
 OUTPUT_DIR_KEY = 'output_dir'
 SYNC_STATE_FILE_KEY = 'sync_state_file'
-HASH_CHECK_KEY = 'hash_check'
+RECALCULATE_HASH_KEY = 'recalculate_hash'
 OBSOLETE_OBJECTS_FILE_KEY = 'obsolete_objects_file'
 CURRENT_STATE_KEY = 'current_state'
 CURRENT_ACTION_KEY = 'current_action'
 TRASH_DIR_KEY = 'trash_dir'
 
 # File extensions
 FASTQ_EXTS = ['fastq', 'fq']
@@ -32,14 +32,17 @@
 SERVER_SHA_256_KEY = 'serverSha256'
 TYPE_KEY = 'type'
 
 # Manifest file keys
 SEQ_ID_KEY = 'Seq_ID'
 FASTQ_R1_KEY = 'FASTQ_R1'
 FASTQ_R2_KEY = 'FASTQ_R2'
+HASH_FASTQ_R1_KEY = 'HASH_FASTQ_R1'
+HASH_FASTQ_R2_KEY = 'HASH_FASTQ_R2'
+FASTA_R1_KEY = 'FASTA_R1'
 
 # Workflow value constants
 DOWNLOADED = 'downloaded'
 DRIFTED = 'drifted'
 FAILED = 'failed'
 MATCH = 'match'
 MISSING = 'missing'
@@ -47,8 +50,9 @@
 
 # Command level value constants
 MANIFEST_FILE_NAME = 'manifest.csv'
 INTERMEDIATE_MANIFEST_FILE = 'intermediate-manifest.csv'
 OBSOLETE_OBJECTS_FILE = 'delete-targets.csv'
 SYNC_STATE_FILE = 'sync-state.json'
 FASTQ = 'fastq'
+FASTA = 'fasta'
 TRASH_DIR = '.trash'
```

## austrakka/components/sequence/sync/funcs.py

```diff
@@ -1,29 +1,34 @@
 import os.path
 
 from loguru import logger
 
 from austrakka.utils.misc import logger_wraps
 from austrakka.utils.fs import create_dir
-from .sync_state import initialise, set_to_start_state, load_state
-from .sync_workflow import SName, configure_state_machine
+from .sync_state import initialise, load_state
+from .sync_workflow import select_start_state, configure_state_machine, reset
 
 from .constant import SYNC_STATE_FILE
 from .constant import OUTPUT_DIR_KEY
 from .constant import SYNC_STATE_FILE_KEY
 from .constant import CURRENT_STATE_KEY
 from .constant import GROUP_NAME_KEY
 from .constant import SEQ_TYPE_KEY
-from .constant import HASH_CHECK_KEY
+from .constant import RECALCULATE_HASH_KEY
 
 from .sync_io import save_json
 
 
 @logger_wraps()
-def seq_get(output_dir: str, group_name: str, hash_check: bool, seq_type: str):
+def seq_get(
+        output_dir: str,
+        group_name: str,
+        recalc_hash: bool,
+        seq_type: str,
+        reset_opt: bool):
 
     sync_state = {}
     state_file_path = os.path.join(output_dir, SYNC_STATE_FILE)
 
     if os.path.exists(state_file_path):
         sync_state = load_state(
             group_name,
@@ -33,30 +38,36 @@
 
         # We just opened the file, so it has to be set to
         # the same file name for later use. It's probably
         # already the same thing. This will guarantee that.
         sync_state[SYNC_STATE_FILE_KEY] = SYNC_STATE_FILE
 
         # Hash check setting is allowed to be overriden between runs.
-        sync_state[HASH_CHECK_KEY] = hash_check
+        sync_state[RECALCULATE_HASH_KEY] = recalc_hash
         save_json(sync_state, state_file_path)
 
     elif not os.path.exists(output_dir):
         create_dir(output_dir)
 
     if CURRENT_STATE_KEY not in sync_state:
-        sync_state = initialise(group_name, hash_check, output_dir, seq_type)
-        save_json(sync_state, state_file_path)
+        sync_state = initialise(
+            group_name,
+            recalc_hash,
+            output_dir,
+            seq_type)
 
-    if sync_state[CURRENT_STATE_KEY] == SName.UP_TO_DATE:
-        set_to_start_state(sync_state)
         save_json(sync_state, state_file_path)
 
+    if reset_opt:
+        reset(state_file_path, sync_state)
+    else:
+        select_start_state(state_file_path, sync_state)
+
     logger.info('Starting sync with args..')
     logger.info(f'{OUTPUT_DIR_KEY}: {sync_state[OUTPUT_DIR_KEY]}')
     logger.info(f'{GROUP_NAME_KEY}: {sync_state[GROUP_NAME_KEY]}')
     logger.info(f'{SEQ_TYPE_KEY}: {sync_state[SEQ_TYPE_KEY]}')
-    logger.info(f'{HASH_CHECK_KEY}: {sync_state[HASH_CHECK_KEY]}')
+    logger.info(f'{RECALCULATE_HASH_KEY}: {sync_state[RECALCULATE_HASH_KEY]}')
 
     state_machine = configure_state_machine()
     state_machine.run(sync_state)
     logger.success("Sync completed")
```

## austrakka/components/sequence/sync/sync_io.py

```diff
@@ -1,9 +1,11 @@
+# pylint: disable=broad-exception-caught
 import os
 import json
+import hashlib
 import pandas as pd
 
 from .constant import INTERMEDIATE_MANIFEST_FILE_KEY
 from .constant import OUTPUT_DIR_KEY
 from .errors import SyncError
 
 invalid_output_dir = [
@@ -26,14 +28,23 @@
 
 def read_from_csv(sync_state: dict, state_key: str):
     path = get_path(sync_state, state_key)
     data_frame = pd.read_csv(path)
     return data_frame
 
 
+def read_from_csv_or_empty(sync_state: dict, state_key: str):
+    path = get_path(sync_state, state_key)
+    try:
+        data_frame = pd.read_csv(path)
+        return data_frame
+    except Exception:
+        return pd.DataFrame()
+
+
 def save_int_manifest(data_frame, sync_state):
     path = get_path(sync_state, INTERMEDIATE_MANIFEST_FILE_KEY)
     with open(path, 'w', encoding='UTF-8') as file:
         data_frame.to_csv(file, index=False)
         file.close()
 
 
@@ -55,7 +66,14 @@
     output_dir = sync_state[OUTPUT_DIR_KEY]
     if output_dir in invalid_output_dir or f'{output_dir}/' in invalid_output_dir:
         raise SyncError("Found invalid output directory path while "
                         "building trash directory path. You should not be "
                         f"sending data to a system folder: {output_dir}.")
 
     return output_dir
+
+
+def calc_hash(path):
+    with open(path, 'rb') as file:
+        file_hash = hashlib.sha256(file.read()).hexdigest().lower()
+        file.close()
+    return file_hash
```

## austrakka/components/sequence/sync/sync_state.py

```diff
@@ -1,8 +1,7 @@
-from .sync_workflow import SName, Action
 from .sync_validator import \
     ensure_valid_state, \
     ensure_group_names_match, \
     ensure_output_dir_match, \
     ensure_seq_type_matches, \
     ensure_is_present
 
@@ -13,33 +12,36 @@
 from .constant import TRASH_DIR
 from .constant import TRASH_DIR_KEY
 from .constant import OUTPUT_DIR_KEY
 from .constant import INTERMEDIATE_MANIFEST_FILE_KEY
 from .constant import SYNC_STATE_FILE_KEY
 from .constant import MANIFEST_KEY
 from .constant import OBSOLETE_OBJECTS_FILE_KEY
-from .constant import CURRENT_STATE_KEY
-from .constant import CURRENT_ACTION_KEY
 from .constant import GROUP_NAME_KEY
 from .constant import SEQ_TYPE_KEY
-from .constant import HASH_CHECK_KEY
+from .constant import RECALCULATE_HASH_KEY
 
 from .sync_io import read_sync_state
+from .sync_workflow import set_state_pulling_manifest
 
 
-def initialise(group_name, hash_check, output_dir, seq_type) -> dict:
+def initialise(
+        group_name,
+        recalc_hash,
+        output_dir,
+        seq_type) -> dict:
     sync_state = {}
-    set_to_start_state(sync_state)
+    set_state_pulling_manifest(sync_state)
     sync_state[SYNC_STATE_FILE_KEY] = SYNC_STATE_FILE
     sync_state[MANIFEST_KEY] = MANIFEST_FILE_NAME
     sync_state[OBSOLETE_OBJECTS_FILE_KEY] = OBSOLETE_OBJECTS_FILE
     sync_state[INTERMEDIATE_MANIFEST_FILE_KEY] = INTERMEDIATE_MANIFEST_FILE
     sync_state[SEQ_TYPE_KEY] = seq_type
     sync_state[GROUP_NAME_KEY] = group_name
-    sync_state[HASH_CHECK_KEY] = hash_check
+    sync_state[RECALCULATE_HASH_KEY] = recalc_hash
     sync_state[OUTPUT_DIR_KEY] = output_dir
     sync_state[TRASH_DIR_KEY] = TRASH_DIR
     return sync_state
 
 
 def load_state(group_name, output_dir, state_file_path, seq_type):
     sync_state = read_sync_state(state_file_path)
@@ -50,12 +52,7 @@
     ensure_is_present(
         sync_state,
         TRASH_DIR_KEY,
         "No trash directory found in the current state file. "
         "The state file might be corrupt. Ask an admin for help")
 
     return sync_state
-
-
-def set_to_start_state(sync_state):
-    sync_state[CURRENT_STATE_KEY] = SName.PULLING_MANIFEST
-    sync_state[CURRENT_ACTION_KEY] = Action.pull_manifest
```

## austrakka/components/sequence/sync/sync_workflow.py

```diff
@@ -1,9 +1,8 @@
 # pylint: disable=broad-exception-caught
-import hashlib
 import os.path
 import re
 from datetime import datetime
 import shutil
 import pandas as pd
 
 from loguru import logger
@@ -14,23 +13,26 @@
 from austrakka.components.sequence.funcs import _get_seq_download_path
 from austrakka.utils.retry import retry
 
 from .errors import WorkflowError
 from .sync_io import \
     get_output_dir, \
     read_from_csv, \
+    read_from_csv_or_empty, \
     get_path, \
     save_int_manifest, \
-    save_to_csv
+    calc_hash, \
+    save_to_csv, \
+    save_json
 
 from .state_machine import StateMachine, SName, State, Action
 
 from .constant import CURRENT_STATE_KEY
 from .constant import CURRENT_ACTION_KEY
-from .constant import HASH_CHECK_KEY
+from .constant import RECALCULATE_HASH_KEY
 from .constant import STATUS_KEY
 from .constant import TRASH_DIR_KEY
 from .constant import SAMPLE_NAME_KEY
 from .constant import HOT_SWAP_NAME_KEY
 from .constant import FILE_PATH_KEY
 from .constant import DETECTION_DATE_KEY
 from .constant import OBSOLETE_OBJECTS_FILE_KEY
@@ -42,27 +44,38 @@
 from .constant import SEQ_TYPE_KEY
 from .constant import TYPE_KEY
 from .constant import READ_KEY
 from .constant import GROUP_NAME_KEY
 from .constant import BLOB_FILE_PATH_KEY
 from .constant import ORIGINAL_FILE_NAME_KEY
 from .constant import SERVER_SHA_256_KEY
+from .constant import FASTQ_R1_KEY
+from .constant import FASTQ_R2_KEY
+from .constant import FASTA_R1_KEY
+from .constant import FASTQ
+from .constant import FASTA
 
 from .constant import MATCH
 from .constant import DOWNLOADED
 from .constant import DRIFTED
 from .constant import FAILED
 from .constant import DONE
 from .constant import MISSING
 from .constant import FASTA_EXTS
 from .constant import FASTQ_EXTS
 from .constant import GZ_EXT
 
 from ..funcs import _get_seq_data
 
+USE_CACHE = "use_cache"
+CHECK_HASH = "check_hash"
+DF = "df"
+IDX = "idx"
+ROW = "row"
+
 
 def configure_state_machine() -> StateMachine:
 
     # Configure the generic state machine with a list of allowed
     # states and actions (a.k.a transitions). The state machine
     # uses this information to do a cursory check of your handler
     # implementations. E.g. if your handler declares that the next
@@ -128,35 +141,67 @@
     sync_state[CURRENT_ACTION_KEY] = Action.analyse
 
 
 def analyse(sync_state: dict):
     logger.info(f'Started: {Action.analyse}')
 
     data_frame = read_from_csv(sync_state, INTERMEDIATE_MANIFEST_FILE_KEY)
-    do_hash_check = (HASH_CHECK_KEY not in sync_state) or (
-        HASH_CHECK_KEY in sync_state and sync_state[HASH_CHECK_KEY] is True)
+    published_manifest = read_from_csv_or_empty(sync_state, MANIFEST_KEY)
+    use_hash_cache = not sync_state[RECALCULATE_HASH_KEY]
+
+    ensure_valid(published_manifest, use_hash_cache, sync_state[SEQ_TYPE_KEY])
 
     if STATUS_KEY not in data_frame.columns:
         data_frame[STATUS_KEY] = ""
 
     output_dir = get_output_dir(sync_state)
+
     for index, row in data_frame.iterrows():
         seq_path = os.path.join(
             output_dir,
             str(row[SAMPLE_NAME_KEY]),
             str(row[FILE_NAME_ON_DISK_KEY]))
 
-        analyse_status(data_frame, do_hash_check, index, row, seq_path)
+        ctx = {DF: data_frame, IDX: index, ROW: row}
+        analyse_status(ctx, use_hash_cache, seq_path, published_manifest)
 
     save_int_manifest(data_frame, sync_state)
     sync_state[CURRENT_STATE_KEY] = SName.DONE_ANALYSING
     sync_state[CURRENT_ACTION_KEY] = Action.set_state_downloading
     logger.success(f'Finished: {Action.analyse}')
 
 
+def ensure_valid(manifest, use_hash_cache, seq_type):
+    if use_hash_cache and \
+        seq_type == FASTQ and \
+        manifest is not None and \
+        len(manifest.index) > 0 and \
+        not (
+             SEQ_ID_KEY in manifest.columns and
+             manifest_column_key(FILE_NAME_ON_DISK_KEY, seq_type, "1") in manifest.columns and
+             manifest_column_key(FILE_NAME_ON_DISK_KEY, seq_type, "2") in manifest.columns and
+             manifest_column_key("", seq_type, "1") in manifest.columns and
+             manifest_column_key("", seq_type, "2") in manifest.columns):
+
+        raise WorkflowError("Cannot parse published manifest "
+                            "for fastq. It is missing some columns.")
+
+    if use_hash_cache and \
+        seq_type == FASTA and \
+        manifest is not None and \
+        len(manifest.index) > 0 and \
+        not (
+             SEQ_ID_KEY in manifest.columns and
+             manifest_column_key(FILE_NAME_ON_DISK_KEY, seq_type, "1") in manifest.columns and
+             manifest_column_key("", seq_type, "1") in manifest.columns):
+
+        raise WorkflowError("Cannot parse published manifest "
+                            "for fasta. It is missing some columns.")
+
+
 def set_state_downloading(sync_state: dict):
     sync_state[CURRENT_STATE_KEY] = SName.DOWNLOADING
     sync_state[CURRENT_ACTION_KEY] = Action.download
 
 
 def download(sync_state: dict):
     logger.info(f'Started: {Action.download}')
@@ -236,23 +281,30 @@
     move_delete_targets_to_trash(file_path, output_dir, trash_dir_path)
 
     # Remove the delete target file. It'll be recreated on the next run.
     os.remove(file_path)
 
     # Delete the intermediate manifest. It's no longer needed.
     # It'll be recreated on the next run.
-    os.remove(os.path.join(
-        output_dir,
-        sync_state[INTERMEDIATE_MANIFEST_FILE_KEY]))
+    remove_int_manifest(output_dir, sync_state)
 
     sync_state[CURRENT_STATE_KEY] = SName.DONE_PURGING
     sync_state[CURRENT_ACTION_KEY] = Action.set_state_up_to_date
     logger.success(f'Finished: {Action.purge}')
 
 
+def remove_int_manifest(output_dir, sync_state):
+    int_m_path = os.path.join(
+        output_dir,
+        sync_state[INTERMEDIATE_MANIFEST_FILE_KEY])
+
+    if os.path.exists(int_m_path):
+        os.remove(int_m_path)
+
+
 def set_state_up_to_date(sync_state: dict):
     sync_state[CURRENT_STATE_KEY] = SName.UP_TO_DATE
     sync_state[CURRENT_ACTION_KEY] = Action.set_state_pulling_manifest
 
 
 def finalise_each_file(int_med, sync_state):
     output_dir = get_output_dir(sync_state)
@@ -308,15 +360,15 @@
         f.path for f in os.scandir(
             get_output_dir(sync_state)) if f.is_dir()]
     files = sum([[f.path for f in os.scandir(subdir) if not f.is_dir()]
                  for subdir in sample_subdirectories], [])
 
     seq_ext_regexstr = '|'.join(FASTQ_EXTS + FASTA_EXTS)
     seqfile_regex = re.compile(
-        rf".+_[0-9TZ]+_[a-z0-9]{{8}}_R\d\.({seq_ext_regexstr})(\.({GZ_EXT}))?$")
+        rf".+_[0-9TZ]+_[a-z0-9]{{8}}(_R\d)?\.({seq_ext_regexstr})(\.({GZ_EXT}))?$")
 
     for path in files:
         if seqfile_regex.match(os.path.basename(path)):
             files_on_disk.append((
                 path,
                 os.path.basename(path),
                 datetime.now().strftime("%Y-%m-%d %H:%M:%S.%f")
@@ -355,29 +407,35 @@
     logger.info(f'Saving list to {path}')
 
 
 def publish_new_manifest(int_med, sync_state):
     sample_table = int_med.pivot(
         index=SAMPLE_NAME_KEY,
         columns=[TYPE_KEY, READ_KEY],
-        values=FILE_NAME_ON_DISK_KEY)
+        values=[FILE_NAME_ON_DISK_KEY, SERVER_SHA_256_KEY])
 
     # Multiindex approach ok, but this format needs changing
     # when dealing with FASTA in the same table
-    sample_table.columns = [f"{seq_type}_R{read}".upper()
-                            for (seq_type, read)
+    sample_table.columns = [manifest_column_key(file_or_hash, seq_type, read)
+                            for (file_or_hash, seq_type, read)
                             in sample_table.columns.to_flat_index()]
+
     sample_table.index.name = SEQ_ID_KEY
     sample_table.reset_index(inplace=True)
     m_path = get_path(sync_state, MANIFEST_KEY)
 
     save_to_csv(sample_table, m_path)
     logger.success(f'Published final manifest: {m_path}')
 
 
+def manifest_column_key(file_or_hash, seq_type, read):
+    return ("" if file_or_hash.casefold() == FILE_NAME_ON_DISK_KEY.casefold()
+            else "HASH_") + f"{seq_type}_R{read}".upper()
+
+
 def get_file_from_server(data_frame, index, row, sync_state):
     file_path = ""
     try:
         filename = row[FILE_NAME_ON_DISK_KEY]
         sample_name = row[SAMPLE_NAME_KEY]
         read = str(row[READ_KEY])
         seq_type = row[TYPE_KEY]
@@ -390,68 +448,116 @@
             seq_type,
             BY_IS_ACTIVE_FLAG)
 
         if row[STATUS_KEY] == DRIFTED:
             fresh_name = f'{row[FILE_NAME_ON_DISK_KEY]}.fresh'
             logger.warning(f'Drifted from server: {file_path}')
             logger.info(f'Downloading fresh copy to temp file: {fresh_name}')
-
             data_frame.at[index, HOT_SWAP_NAME_KEY] = fresh_name
             file_path = os.path.join(sample_dir, fresh_name)
 
         retry(lambda fp=file_path, fn=filename, qp=query_path, sd=sample_dir:
               _download_seq_file(fp, fn, qp, sd),
-              3,
+              1,
               query_path)
 
+        check_download_hash(data_frame, file_path, index, row)
+
         # Drifted entries are left for finalisation to hot swap.
         # Otherwise mark the entry as successfully downloaded.
-        if data_frame.at[index, STATUS_KEY] != DRIFTED:
+        if data_frame.at[index, STATUS_KEY] != DRIFTED and \
+                data_frame.at[index, STATUS_KEY] != FAILED:
+
             data_frame.at[index, STATUS_KEY] = DOWNLOADED
 
     except Exception as ex:
         data_frame.at[index, STATUS_KEY] = FAILED
         logger.error(f'Failed to download: {file_path}. Error: {ex}')
 
 
-def set_match_status(data_frame, index, row, seq_path):
+def check_download_hash(data_frame, file_path, index, row):
+    local_hash = calc_hash(file_path)
+    server_hash = row[SERVER_SHA_256_KEY]
+
+    if local_hash.casefold() != server_hash.casefold():
+        logger.error(f"Bad hash. Invalidating: {file_path}")
+        data_frame.at[index, STATUS_KEY] = FAILED
+
+
+def set_match_status(ctx, seq_path):
     azure_path = os.path.join(
-        row[BLOB_FILE_PATH_KEY],
-        row[ORIGINAL_FILE_NAME_KEY])
+        ctx[ROW][BLOB_FILE_PATH_KEY],
+        ctx[ROW][ORIGINAL_FILE_NAME_KEY])
     logger.success(f'Matched: {seq_path} ==> Azure: {azure_path}')
-    data_frame.at[index, STATUS_KEY] = MATCH
+    ctx[DF].at[ctx[IDX], STATUS_KEY] = MATCH
 
 
-def analyse_status(data_frame, do_hash_check, index, row, seq_path):
-    previously_matched = row[STATUS_KEY] == MATCH
+def analyse_status(ctx, use_hash_cache, seq_path, published_manifest):
+    previously_matched = ctx[ROW][STATUS_KEY] == MATCH
+    p_manifest = published_manifest
 
     if not os.path.exists(seq_path):
         logger.info(f'Missing: {seq_path}')
-        data_frame.at[index, STATUS_KEY] = MISSING
+        ctx[DF].at[ctx[IDX], STATUS_KEY] = MISSING
 
-    elif (do_hash_check and not previously_matched) or row[STATUS_KEY] == FAILED:
-        with open(seq_path, 'rb') as file:
-            seq_hash = hashlib.sha256(file.read()).hexdigest().lower()
-
-            if seq_hash == row[SERVER_SHA_256_KEY].lower():
-                set_match_status(data_frame, index, row, seq_path)
-            else:
-                logger.info(f'Drifted: {seq_path}')
-                data_frame.at[index, STATUS_KEY] = DRIFTED
+    elif (not previously_matched) or ctx[ROW][STATUS_KEY] == FAILED:
 
-            file.close()
+        cache_row = search_cache(ctx, p_manifest)
+        hash_col_key = build_cache_key(ctx)
+
+        # If told to use cache and there is a cache hit.
+        if use_hash_cache and len(cache_row.index):
+            logger.info("Hash cache hit.")
+            seq_hash = cache_row.iloc[0, cache_row.columns.get_loc(hash_col_key)]
+        else:
+            seq_hash = calc_hash(seq_path)
+
+        if seq_hash.casefold() == ctx[ROW][SERVER_SHA_256_KEY].casefold():
+            set_match_status(ctx, seq_path)
+        else:
+            logger.info(f'Drifted: {seq_path}')
+            ctx[DF].at[ctx[IDX], STATUS_KEY] = DRIFTED
 
     else:
         # This happens in two cases:
         # 1) The user chose to not do hash checks.
         # 2) The entry was previously matched when the analysis
         #    got interrupted. Don't want to redo the hash checks
         #    again because the process could take hours. Just check
         #    that the file is still there.
-        set_match_status(data_frame, index, row, seq_path)
+        set_match_status(ctx, seq_path)
+
+
+def search_cache(ctx, manifest):
+    if len(manifest.index) > 0 and ctx[ROW][TYPE_KEY] == FASTQ:
+        if len(manifest[FASTQ_R2_KEY].index) > 0:
+            # Pair of fastq
+            return manifest.loc[
+                (manifest[SEQ_ID_KEY] == ctx[ROW][SAMPLE_NAME_KEY]) &
+                ((manifest[FASTQ_R1_KEY] == ctx[ROW][FILE_NAME_ON_DISK_KEY]) |
+                 (manifest[FASTQ_R2_KEY] == ctx[ROW][FILE_NAME_ON_DISK_KEY]))]
+
+        # Single fastq
+        return manifest.loc[
+            (manifest[SEQ_ID_KEY] == ctx[ROW][SAMPLE_NAME_KEY]) &
+            (manifest[FASTQ_R1_KEY] == ctx[ROW][FILE_NAME_ON_DISK_KEY])]
+
+    if len(manifest.index) > 0 and ctx[ROW][TYPE_KEY] == FASTA:
+        return manifest.loc[
+            (manifest[SEQ_ID_KEY] == ctx[ROW][SAMPLE_NAME_KEY]) &
+            (manifest[FASTA_R1_KEY] == ctx[ROW][FILE_NAME_ON_DISK_KEY])]
+
+    return manifest
+
+
+def build_cache_key(ctx):
+    read = ctx[ROW][READ_KEY]
+    seq_type = ctx[ROW][TYPE_KEY]
+    hash_col_key = "HASH_" + f"{seq_type}_R{read}".upper()
+    return hash_col_key
 
 
 def move_delete_targets_to_trash(
         obsolete_objects_file_path,
         output_dir,
         trash_dir_path):
 
@@ -478,7 +584,24 @@
     if sub_paths.startswith('/'):
         sub_paths = sub_paths[1:]
 
     # Make the destination directory structure
     dest_dir = os.path.join(trash_dir_path, sub_paths)
     os.makedirs(dest_dir, exist_ok=True)
     return dest_dir
+
+
+def select_start_state(state_file_path, sync_state):
+    if sync_state[CURRENT_STATE_KEY] == SName.UP_TO_DATE:
+        set_state_pulling_manifest(sync_state)
+        save_json(sync_state, state_file_path)
+
+    elif sync_state[CURRENT_STATE_KEY] == SName.FINALISATION_FAILED:
+        set_state_analysing(sync_state)
+        save_json(sync_state, state_file_path)
+
+
+def reset(state_file_path, sync_state):
+    output_dir = get_output_dir(sync_state)
+    remove_int_manifest(output_dir, sync_state)
+    set_state_pulling_manifest(sync_state)
+    save_json(sync_state, state_file_path)
```

## austrakka/components/user/__init__.py

```diff
@@ -3,31 +3,35 @@
 import click
 
 from austrakka.utils.output import table_format_option
 from austrakka.utils.cmd_filter import hide_admin_cmds
 from austrakka.utils.options import opt_owner_group_roles
 from austrakka.utils.options import opt_user_object_id
 from austrakka.utils.options import opt_organisation
+from austrakka.utils.options import opt_show_disabled
 from .funcs import list_users
 from .funcs import add_user
 from .funcs import update_user
+from .funcs import enable_user
+from .funcs import disable_user
 
 
 @click.group()
 @click.pass_context
 def user(ctx):
     '''Commands related to users'''
     ctx.context = ctx.parent.context
 
 
 @user.command('list')
+@opt_show_disabled()
 @table_format_option()
-def user_list(out_format: str):
+def user_list(show_disabled: bool, out_format: str):
     '''List users in AusTrakka'''
-    list_users(out_format)
+    list_users(show_disabled, out_format)
 
 
 @user.command('add', hidden=hide_admin_cmds())
 @opt_user_object_id()
 @opt_organisation()
 @opt_owner_group_roles(required=False)
 def user_add(
@@ -46,7 +50,21 @@
 def user_update(
     user_id: int,
     org: str,
     owner_group_roles: List[str],
 ):
     """Add users in AusTrakka"""
     update_user(user_id, org, owner_group_roles)
+
+
+@user.command('enable')
+@opt_user_object_id()
+def user_enable(user_id: str):
+    """Re-enable a user in AusTrakka"""
+    enable_user(user_id)
+
+
+@user.command('disable')
+@opt_user_object_id()
+def user_disable(user_id: str):
+    """Disable a user in AusTrakka"""
+    disable_user(user_id)
```

## austrakka/components/user/funcs.py

```diff
@@ -1,38 +1,38 @@
 from typing import List
 import pandas as pd
 
 from austrakka.utils.api import api_get
 from austrakka.utils.api import api_post
 from austrakka.utils.api import api_put
+from austrakka.utils.api import api_patch
 from austrakka.utils.misc import logger_wraps
 from austrakka.utils.paths import USER_PATH
 from austrakka.utils.output import print_table
 
 
 @logger_wraps()
-def list_users(out_format: str):
+def list_users(show_disabled: bool, out_format: str):
     response = api_get(
         path=USER_PATH,
         params={
-            'includeall': False
+            'includeall': show_disabled
         }
     )
 
     data = response['data'] if ('data' in response) else response
     pd.set_option('display.max_rows', 500)
     urg = pd.json_normalize(data, record_path='userRoleGroup') \
         .pipe(lambda x: x.drop('role.id', axis=1)) \
         .pipe(lambda x: x.drop('group.id', axis=1))
 
     org = pd.json_normalize(data)\
         .pipe(lambda x: x.drop('lastUpdatedBy', axis=1))\
         .pipe(lambda x: x.drop('lastUpdated', axis=1))\
         .pipe(lambda x: x.drop('created', axis=1))\
-        .pipe(lambda x: x.drop('isActive', axis=1))\
         .pipe(lambda x: x.drop('userRoleGroup', axis=1))\
         .pipe(lambda x: x.drop('organisation.id', axis=1))\
         .pipe(lambda x: x.drop('createdBy', axis=1))
 
     normalized = pd.merge(
         urg,
         org,
@@ -90,7 +90,17 @@
         "ownerGroupRoles": list(owner_group_roles),
     }
 
     api_put(
         path=f'{USER_PATH}/{user_id}',
         data=user
     )
+
+
+@logger_wraps()
+def enable_user(user_id: str):
+    api_patch(path=f'{USER_PATH}/enable/{user_id}')
+
+
+@logger_wraps()
+def disable_user(user_id: str):
+    api_patch(path=f'{USER_PATH}/disable/{user_id}')
```

## austrakka/utils/options.py

```diff
@@ -412,22 +412,44 @@
         '--is-append/--not-append',
         type=bool,
         default=False,
         **{**defaults, **attrs}
     )
 
 
-def opt_hash_check(**attrs: t.Any):
+def opt_recalc_hash(**attrs: t.Any):
     defaults = {
-        'help': 'Specify whether to do a hash check when searching for files.'
+        'help': 'When comparing server file hashes to local file hashes, '
+                'recalculate local file hashes for previously-downloaded '
+                'files; do not use cached hashes. This can take a long '
+                'time to run. This option may be useful if local files or '
+                'cached hash values have been corrupted. If this option is '
+                'not specified, cached local hashes will be used for '
+                'previously-downloaded files, but hashes will still be '
+                'calculated for newly-downloaded files.'
     }
     return _create_option(
-        '--hash-check/--no-hash-check',
+        '--recalculate-hashes',
         type=bool,
-        default=True,
+        is_flag=True,
+        **{**defaults, **attrs}
+    )
+
+
+def opt_blanks_delete(**attrs: t.Any):
+    defaults = {
+        'help': "Blank cells in the CSV / Excel file will "
+                "be treated as a delete command for that cell. By "
+                "default, blank cells are ignored."
+    }
+    return _create_option(
+        '--blanks-will-delete',
+        type=bool,
+        is_flag=True,
+        default=False,
         **{**defaults, **attrs}
     )
 
 
 def opt_country(**attrs: t.Any):
     defaults = {
         'required': True,
@@ -492,14 +514,26 @@
         '-gr',
         '--group-role',
         type=click.STRING,
         **{**defaults, **attrs}
     )
 
 
+def opt_show_disabled(**attrs: t.Any):
+    defaults = {
+        'help': 'Shows or hides disabled entities [default: --hide-disabled]'
+    }
+    return _create_option(
+        '--show-disabled/--hide-disabled',
+        type=bool,
+        default=False,
+        **{**defaults, **attrs}
+    )
+
+
 def _create_option(*param_decls: str, **attrs: t.Any):
     def inner_func(func):
         return click.option(
             *param_decls,
             cls=AusTrakkaCliOption,
             **attrs)(func)
     return inner_func
```

## Comparing `austrakka-0.31.0.dist-info/METADATA` & `austrakka-0.32.0.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: austrakka
-Version: 0.31.0
+Version: 0.32.0
 Summary: A CLI to interact with AusTrakka
 Home-page: https://github.com/AusTrakka/austrakka2-cli
 Author: AusTrakka Dev Team
 Author-email: dev@austrakka.net.au
 Project-URL: Bug Reports, https://github.com/austrakka/austrakka2-cli/issues
 Project-URL: Source, https://github.com/austrakka/austrakka2-cli/
 Keywords: sample setuptools development
```

## Comparing `austrakka-0.31.0.dist-info/RECORD` & `austrakka-0.32.0.dist-info/RECORD`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-austrakka/__init__.py,sha256=3LWQWPRMHYlLMHhwA3SZn7y9GmXbCV-PyQNmVrNiJ44,128
+austrakka/__init__.py,sha256=Y-jPO51Qdft15SKpP1nvAC0NcJBTseIn5IGGHJRVRN4,128
 austrakka/main.py,sha256=TPKwITIOJwuM-A1XSdTxXJvKI-XozYbILlkz6ao8uuk,4066
 austrakka/components/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 austrakka/components/analysis/__init__.py,sha256=vCExLFjdFtTbv2qmb7vXf5ZspF2mOIh2W9Pnc_wyXwI,2526
 austrakka/components/analysis/funcs.py,sha256=XSvZo788KfB9Kn5-_3U0czNKeq43WYj6vdDCMZgSkcA,1851
 austrakka/components/analysis/definition/__init__.py,sha256=zEn2OvfxLUytwOHT93CEAkZjQtvdmeKPimYY4RMRFX8,1449
 austrakka/components/analysis/definition/funcs.py,sha256=02wLoxUWy-5LVv3M1j2SJWdevAiRl1-xopRrCC09TKg,1165
 austrakka/components/auth/__init__.py,sha256=I1HQAqZjsSZxP-6evzd7694XY4NEccOsi-X2RU-pU6E,721
@@ -17,53 +17,53 @@
 austrakka/components/fieldtype/funcs.py,sha256=BVTp11k_v5jy8X83BhWVe6KTxRgfIDzNbVrhenzbHJA,1720
 austrakka/components/fieldtype/value/__init__.py,sha256=bT9BzYHgnGTSpSoWBqz9L4EusWvbc8vcue3UNRKiBG4,945
 austrakka/components/fieldtype/value/funcs.py,sha256=UrKuW2Kdmn6uX_l3OzH-jDoXlOIZhKJcT7sGWabuuF4,562
 austrakka/components/group/__init__.py,sha256=qnGUbSmRNStdHOeyqezczwPO9TCExqaxi-SJ6KFzh80,2317
 austrakka/components/group/funcs.py,sha256=V3PXCsK_As4hkjaSSp4EhJccIYcJWX5vNVIKMZu0XLo,2369
 austrakka/components/group/field/__init__.py,sha256=nq-mSpR8SzMKYzfwPK0KUoIVfMQDzn4-JUiucx3pL58,1185
 austrakka/components/group/field/funcs.py,sha256=Qon9VRColhRZV_5c3KYTOveOONokteTg76ZZDYrFY5Q,1322
-austrakka/components/metadata/__init__.py,sha256=gcbs8KC9H_AfxW4UBJ7r2uycaH3sc8cAgfX5pseb9I0,1937
-austrakka/components/metadata/funcs.py,sha256=ofkR1pGqrnuplOS6z3bmKjTxLQnl_eIAyWyoC7BQHsc,1828
+austrakka/components/metadata/__init__.py,sha256=26zhdT7D0uY5cKG0J1glgrWSVae4b3zuYKp0FmLAwMo,2141
+austrakka/components/metadata/funcs.py,sha256=vzGq6Gq58AvqlME7Fi7yDyu6qSQa_IvRtuy2Jy6H-5M,2095
 austrakka/components/org/__init__.py,sha256=IZh7LlMI229sq0oxgJmvY07gNUjJrZ18uq94VOezG0I,1575
 austrakka/components/org/funcs.py,sha256=igBLhGecDPPYER8t59ETwq8Nc9JqSc6Z04EecuewbD8,1481
 austrakka/components/plot/__init__.py,sha256=nt8zjuszsfRgsdrjm4cxl-mRwN4-cTE9dX2411Nl6Qc,2776
 austrakka/components/plot/funcs.py,sha256=PrhslqgAHsPH4peCEhh_jgMEtyoWofTtBa4TbgNQjgc,2922
 austrakka/components/proforma/__init__.py,sha256=D8jpNZNHiTiAV3H0IW3jXWLtDeOCXgI8sIUCfpcE7lA,5413
 austrakka/components/proforma/funcs.py,sha256=ythucQHTEgGdee8tXkPAFGaORwZat7jQej2I9SfWR5E,6100
 austrakka/components/project/__init__.py,sha256=zkNBNPUm3xHCxv6Zf68IuWb15o9XHTw4REFJQpjFWWU,1888
 austrakka/components/project/funcs.py,sha256=JL9f-ESyj-TgK0DRXI_gqC-oJ4YfshQWxJHnFrS4eLQ,1396
 austrakka/components/sample/__init__.py,sha256=9g-tIifxAUBJsTBthy18vTPK3fXPvpCQOl_YpYTQu70,1802
 austrakka/components/sample/funcs.py,sha256=0QxoO4RufFUOWib09SBdufkiAEnNTq0u6AHS-mMVymw,1103
 austrakka/components/sequence/__init__.py,sha256=4CVI4yX2LQcp-9gqsx9AFhNjT7hmzoQ3h9kgD4bbs-U,1764
-austrakka/components/sequence/funcs.py,sha256=6lcNKOhA514lzyo3rGecBrrOlOHhawIExyTyFhiLP68,14733
-austrakka/components/sequence/add/__init__.py,sha256=B2gcpOEs6-hvHE8J_mPseHJqxBXIFlRSxNObJLhcqyY,1824
-austrakka/components/sequence/sync/__init__.py,sha256=ifydKbfc2vbdfC8TXJpcCewyhNQGznWwc8MHwFTGbQQ,852
-austrakka/components/sequence/sync/constant.py,sha256=a2d9uyfIstTfZ8Ym_t9DHGCBiCH_O0b6SYLH2RmFBqE,1431
+austrakka/components/sequence/funcs.py,sha256=ltWxPz6Airo-Ptslvgbj7B4PbbcqqrB5Pi4GU8kEQ1w,14992
+austrakka/components/sequence/add/__init__.py,sha256=e3FMlsGqOAbOWwKnTVIP5TYP1mrHWr-aIABUC5kq-wQ,2261
+austrakka/components/sequence/sync/__init__.py,sha256=pAFN1aQ3dda0JnJ4UmYJ5v9UJoKBeuV0YxdlpJxHX4E,1124
+austrakka/components/sequence/sync/constant.py,sha256=TsMmk877T6WWkm7lLpJMGywOYwMXYa9IQ018AjIyieI,1557
 austrakka/components/sequence/sync/errors.py,sha256=VSKJtS_Wjmzl8yZS2LCT_dhgzsOvigAduWjDz9eQi1A,127
-austrakka/components/sequence/sync/funcs.py,sha256=ielWziWb7PiZzdCC5DwgU45lGJm5IZ9nrL8BUBZu0fc,2128
+austrakka/components/sequence/sync/funcs.py,sha256=WZDy8Dve-yjdxnoTX-BZCf3WOZzBUkP68pnwWYVOnKE,2246
 austrakka/components/sequence/sync/state_machine.py,sha256=REB74aHp9qQcxuuU8SBZm15nGg_GLDFVN_F2xws5QPE,3802
-austrakka/components/sequence/sync/sync_io.py,sha256=siuhpsNrhiZ18UMSJE7ecrRCSYLOLyk_4Q7eCzPs7dk,1683
-austrakka/components/sequence/sync/sync_state.py,sha256=N3y-FnLPauyx_9r1XHTfqnhi867veMJB9A_WqiVmk9E,2188
+austrakka/components/sequence/sync/sync_io.py,sha256=tGJMvIY5PC_i1MHO86aNtkNwcGCfb1sl0LthgdmNMdE,2140
+austrakka/components/sequence/sync/sync_state.py,sha256=59YX6ke4ViOP77BbI1PexznlJwLRbgByyZMGxvYVSCI,2020
 austrakka/components/sequence/sync/sync_validator.py,sha256=keJVHMcJxAQeK9x_BM9NS3b4q8BR07F5ibse4Irafs0,2437
-austrakka/components/sequence/sync/sync_workflow.py,sha256=4a0IImt9bxTv6Q5rF7Q5OpXevrESbIFbZCV4SHvMf-o,17606
+austrakka/components/sequence/sync/sync_workflow.py,sha256=xEqsVLKUmDDE7QeeQQH2JiLlV00tBiOUNSY4AnwWDhs,21993
 austrakka/components/tree/__init__.py,sha256=NO0FcriLFgeg5yTIf4HWCij1q7MxCQ3CvM9-8YFsZ0I,744
 austrakka/components/tree/funcs.py,sha256=C780fZ0w2SWLW0d4L-b68YhesHZAxK-iF1LK63hL8M4,876
-austrakka/components/user/__init__.py,sha256=hDSIgmxc4VR9XUnGRh92VDcBfrQOoaOW-3jwIofRm2k,1291
-austrakka/components/user/funcs.py,sha256=_7xGzUAaqecf1A8XEw759g7oXXyzfn8SsLT-3nWzOuQ,2342
+austrakka/components/user/__init__.py,sha256=0DBc6kR5aHqOOlkYYMUCmPlt0m5PXsXG9szH3YEzXwE,1754
+austrakka/components/user/funcs.py,sha256=dsdEEAYRj8Cs-9sgqLEVS084_gQbvgCmO0XsVnmLQ6Q,2564
 austrakka/components/widget/__init__.py,sha256=DAApLU8uajoXzrV768YuSDAnmHfukNnZcTz-qcurfiA,1295
 austrakka/components/widget/funcs.py,sha256=D19A6y6QOLr18OhqXQUIWb9qjMtVKNkm7ydKxA5L_vA,1099
 austrakka/utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 austrakka/utils/api.py,sha256=phIwBO0hsx4Ki-8vEhuWhk_lL_b0qCJJeO1w_maHPD8,5227
 austrakka/utils/cmd_filter.py,sha256=i13LqRxTYV5iTel8SLF1YrOVV903JhbC9qtpI3Rlzx0,226
 austrakka/utils/context.py,sha256=OicaDsbsUoOB7oTWma1GopwXI0ERFG8R6Tx9m1Mxdr4,296
 austrakka/utils/exceptions.py,sha256=vZqwuaZH6BuSfAOxavrIi7F7DVeDspk3RpMHCX5Ua34,1161
 austrakka/utils/fs.py,sha256=4TBnFF88br_HPvPp0mL4q0AzbhLxEJnBYWOLUj22-Yo,277
 austrakka/utils/logger.py,sha256=UMBnEJpyzlfeoIQhmHIQCTaGEb1ET_sb4QdokxH7JVY,864
 austrakka/utils/misc.py,sha256=ZRJ7hTvRF9Xrcc55gGyd2SsiiSAJTjG-OmB-3asGL4Q,3069
-austrakka/utils/options.py,sha256=tT_C3rzSeN4kDgAjaUwewWjEciX2zxD7fq-rG0UiOhQ,11587
+austrakka/utils/options.py,sha256=R7Plfp7yf-ArJCxYQermFM2cTXS_ihPmApJsmAtcV1c,12775
 austrakka/utils/output.py,sha256=UTHcIO9kqZlLqPzxP4u_yZ9PGZHO2psTAkpYnlBLDRA,5327
 austrakka/utils/paths.py,sha256=tBH6bTLhA_OadDGOBnAEhpvzOMfbAkyJBFpjGyG8A94,674
 austrakka/utils/retry.py,sha256=chv2KjSHlnevPMFwrbcbM37_yFGev75fy3udV9EO4a8,646
 austrakka/utils/version.py,sha256=cYjU4Px8t7fUZ39Rw9GoeXGRZTTAlkVs5boYvyFtCLw,1227
 austrakka/utils/enums/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 austrakka/utils/enums/api.py,sha256=nVyqwCpGLul46AO_jL9zPTjqz1AUTmFpaxp3cB5vN2E,255
 austrakka/utils/enums/countries.py,sha256=cyizIUWvWO6zYuwYmHTKGNGSfnpvO4suvRd5RfOq5c4,80
@@ -76,12 +76,12 @@
 austrakka/utils/helpers/fieldtype.py,sha256=ys6nzvJUmRI379wIQ5snCW0nRRbKaHw4iemfICoedL4,212
 austrakka/utils/helpers/groups.py,sha256=aLkBBBOy3G-Nuk41JxXCwmHM5QDd1nTwfmb_cuTd2-4,177
 austrakka/utils/helpers/orgs.py,sha256=r-WDGPsPDI6Hb7r1YFnVHCm86YaMiWTeRVEUlNKzdFg,177
 austrakka/utils/helpers/output.py,sha256=zm6zod2odqNgkG8DRRxxvgsysG1ldqAsiIC6mRmH0E4,575
 austrakka/utils/helpers/plots.py,sha256=BU4xxL9A_L0aqTqcrkEd68TKI5ada8QVCsMXKYEiPPs,187
 austrakka/utils/helpers/project.py,sha256=7Hok-tJYHxDrhhd8r21Qx5tRq9NtotpAFAZ-B8fm85Y,196
 austrakka/utils/helpers/upload.py,sha256=HmZ1wWlMEroNipmSUn6yiDOzmVvo_HSLqLRY0RDKOdA,727
-austrakka-0.31.0.dist-info/METADATA,sha256=pBSidZ6ndrmaqNWJhcCr6IkYq6Gq8AgyRyCGB3MDF2E,7897
-austrakka-0.31.0.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-austrakka-0.31.0.dist-info/entry_points.txt,sha256=85AT8M6EE1Z5pzMxS9TqdY2V5KRScP_pWhDaypuhgYw,50
-austrakka-0.31.0.dist-info/top_level.txt,sha256=RR39aR9D6gESut5-IvflXMZ_b50-TIKYMnhWWRt9jcU,10
-austrakka-0.31.0.dist-info/RECORD,,
+austrakka-0.32.0.dist-info/METADATA,sha256=hWSEp_Vb_b9yQEFxqR226luFpFKKtGxPzQINixt38ek,7897
+austrakka-0.32.0.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+austrakka-0.32.0.dist-info/entry_points.txt,sha256=85AT8M6EE1Z5pzMxS9TqdY2V5KRScP_pWhDaypuhgYw,50
+austrakka-0.32.0.dist-info/top_level.txt,sha256=RR39aR9D6gESut5-IvflXMZ_b50-TIKYMnhWWRt9jcU,10
+austrakka-0.32.0.dist-info/RECORD,,
```

