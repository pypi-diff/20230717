# Comparing `tmp/mahaNLP-0.8-py3-none-any.whl.zip` & `tmp/mahaNLP-0.9-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,35 +1,35 @@
-Zip file size: 36760 bytes, number of entries: 33
--rw-r--r--  2.0 unx     1428 b- defN 23-Mar-18 11:17 mahaNLP/__init__.py
--rw-r--r--  2.0 unx     1883 b- defN 23-Mar-18 11:17 mahaNLP/config.py
--rw-r--r--  2.0 unx     1199 b- defN 23-Mar-18 11:17 mahaNLP/autocomplete/__init__.py
--rw-r--r--  2.0 unx     1411 b- defN 23-Mar-18 11:17 mahaNLP/autocomplete/autocomplete.py
--rw-r--r--  2.0 unx     1216 b- defN 23-Mar-18 11:17 mahaNLP/datasets/__init__.py
--rw-r--r--  2.0 unx     7675 b- defN 23-Mar-18 11:17 mahaNLP/datasets/load_data.py
--rw-r--r--  2.0 unx     1189 b- defN 23-Mar-18 11:17 mahaNLP/hate/__init__.py
--rw-r--r--  2.0 unx     1422 b- defN 23-Mar-18 11:17 mahaNLP/hate/hate.py
--rw-r--r--  2.0 unx     1204 b- defN 23-Mar-18 11:17 mahaNLP/mask_fill/__init__.py
--rw-r--r--  2.0 unx     1443 b- defN 23-Mar-18 11:17 mahaNLP/mask_fill/mask_fill.py
--rw-r--r--  2.0 unx     1450 b- defN 23-Mar-18 11:17 mahaNLP/model_repo/__init__.py
--rw-r--r--  2.0 unx     3716 b- defN 23-Mar-18 11:17 mahaNLP/model_repo/maha_fill.py
--rw-r--r--  2.0 unx     3653 b- defN 23-Mar-18 11:17 mahaNLP/model_repo/maha_gpt.py
--rw-r--r--  2.0 unx     2961 b- defN 23-Mar-18 11:17 mahaNLP/model_repo/maha_hate.py
--rw-r--r--  2.0 unx     4158 b- defN 23-Mar-18 11:17 mahaNLP/model_repo/maha_ner.py
--rw-r--r--  2.0 unx     2853 b- defN 23-Mar-18 11:17 mahaNLP/model_repo/maha_sentiment.py
--rw-r--r--  2.0 unx     3347 b- defN 23-Mar-18 11:17 mahaNLP/model_repo/maha_similarity.py
--rw-r--r--  2.0 unx     1195 b- defN 23-Mar-18 11:17 mahaNLP/preprocess/__init__.py
--rw-r--r--  2.0 unx     1307 b- defN 23-Mar-18 11:17 mahaNLP/preprocess/marathi_stopwords.txt
--rw-r--r--  2.0 unx     4133 b- defN 23-Mar-18 11:17 mahaNLP/preprocess/preprocess.py
--rw-r--r--  2.0 unx     1204 b- defN 23-Mar-18 11:17 mahaNLP/sentiment/__init__.py
--rw-r--r--  2.0 unx     1458 b- defN 23-Mar-18 11:17 mahaNLP/sentiment/sentiment.py
--rw-r--r--  2.0 unx     1206 b- defN 23-Mar-18 11:17 mahaNLP/similarity/__init__.py
--rw-r--r--  2.0 unx     1489 b- defN 23-Mar-18 11:17 mahaNLP/similarity/similarity.py
--rw-r--r--  2.0 unx     1171 b- defN 23-Mar-18 11:17 mahaNLP/tagger/__init__.py
--rw-r--r--  2.0 unx     1417 b- defN 23-Mar-18 11:17 mahaNLP/tagger/tagger.py
--rw-r--r--  2.0 unx     1156 b- defN 23-Mar-18 11:17 mahaNLP/tokenizer/__init__.py
--rw-r--r--  2.0 unx     3863 b- defN 23-Mar-18 11:17 mahaNLP/tokenizer/tokenize.py
--rw-r--r--  2.0 unx     1068 b- defN 23-Mar-21 15:12 mahaNLP-0.8.dist-info/LICENSE
--rw-r--r--  2.0 unx     6366 b- defN 23-Mar-21 15:12 mahaNLP-0.8.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Mar-21 15:12 mahaNLP-0.8.dist-info/WHEEL
--rw-r--r--  2.0 unx        8 b- defN 23-Mar-21 15:12 mahaNLP-0.8.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     2791 b- defN 23-Mar-21 15:12 mahaNLP-0.8.dist-info/RECORD
-33 files, 72132 bytes uncompressed, 32292 bytes compressed:  55.2%
+Zip file size: 38722 bytes, number of entries: 33
+-rw-r--r--  2.0 unx     1428 b- defN 23-Jul-07 08:36 mahaNLP/__init__.py
+-rw-r--r--  2.0 unx     2277 b- defN 23-Jul-07 08:36 mahaNLP/config.py
+-rw-r--r--  2.0 unx     1197 b- defN 23-Jul-07 08:36 mahaNLP/autocomplete/__init__.py
+-rw-r--r--  2.0 unx     1412 b- defN 23-Jul-07 08:36 mahaNLP/autocomplete/autocomplete.py
+-rw-r--r--  2.0 unx     1216 b- defN 23-Jul-07 08:36 mahaNLP/datasets/__init__.py
+-rw-r--r--  2.0 unx     7675 b- defN 23-Jul-07 08:36 mahaNLP/datasets/load_data.py
+-rw-r--r--  2.0 unx     1189 b- defN 23-Jul-07 08:36 mahaNLP/hate/__init__.py
+-rw-r--r--  2.0 unx     1422 b- defN 23-Jul-07 08:36 mahaNLP/hate/hate.py
+-rw-r--r--  2.0 unx     1204 b- defN 23-Jul-07 08:36 mahaNLP/mask_fill/__init__.py
+-rw-r--r--  2.0 unx     1443 b- defN 23-Jul-07 08:36 mahaNLP/mask_fill/mask_fill.py
+-rw-r--r--  2.0 unx     1450 b- defN 23-Jul-07 08:36 mahaNLP/model_repo/__init__.py
+-rw-r--r--  2.0 unx     4310 b- defN 23-Jul-07 08:36 mahaNLP/model_repo/maha_fill.py
+-rw-r--r--  2.0 unx     4371 b- defN 23-Jul-07 08:36 mahaNLP/model_repo/maha_gpt.py
+-rw-r--r--  2.0 unx     3686 b- defN 23-Jul-07 08:36 mahaNLP/model_repo/maha_hate.py
+-rw-r--r--  2.0 unx     4617 b- defN 23-Jul-07 08:36 mahaNLP/model_repo/maha_ner.py
+-rw-r--r--  2.0 unx     3591 b- defN 23-Jul-07 08:36 mahaNLP/model_repo/maha_sentiment.py
+-rw-r--r--  2.0 unx     3721 b- defN 23-Jul-07 08:36 mahaNLP/model_repo/maha_similarity.py
+-rw-r--r--  2.0 unx     1195 b- defN 23-Jul-07 08:36 mahaNLP/preprocess/__init__.py
+-rw-r--r--  2.0 unx     3686 b- defN 23-Jul-07 08:36 mahaNLP/preprocess/marathi_stopwords.txt
+-rw-r--r--  2.0 unx     4133 b- defN 23-Jul-07 08:36 mahaNLP/preprocess/preprocess.py
+-rw-r--r--  2.0 unx     1204 b- defN 23-Jul-07 08:36 mahaNLP/sentiment/__init__.py
+-rw-r--r--  2.0 unx     1458 b- defN 23-Jul-07 08:36 mahaNLP/sentiment/sentiment.py
+-rw-r--r--  2.0 unx     1206 b- defN 23-Jul-07 08:36 mahaNLP/similarity/__init__.py
+-rw-r--r--  2.0 unx     1489 b- defN 23-Jul-07 08:36 mahaNLP/similarity/similarity.py
+-rw-r--r--  2.0 unx     1188 b- defN 23-Jul-07 08:36 mahaNLP/tagger/__init__.py
+-rw-r--r--  2.0 unx     1416 b- defN 23-Jul-07 08:36 mahaNLP/tagger/tagger.py
+-rw-r--r--  2.0 unx     1156 b- defN 23-Jul-07 08:36 mahaNLP/tokenizer/__init__.py
+-rw-r--r--  2.0 unx     3863 b- defN 23-Jul-07 08:36 mahaNLP/tokenizer/tokenize.py
+-rw-r--r--  2.0 unx     1068 b- defN 23-Jul-17 15:05 mahaNLP-0.9.dist-info/LICENSE
+-rw-r--r--  2.0 unx     6638 b- defN 23-Jul-17 15:05 mahaNLP-0.9.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Jul-17 15:05 mahaNLP-0.9.dist-info/WHEEL
+-rw-r--r--  2.0 unx        8 b- defN 23-Jul-17 15:05 mahaNLP-0.9.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     2791 b- defN 23-Jul-17 15:05 mahaNLP-0.9.dist-info/RECORD
+33 files, 78800 bytes uncompressed, 34254 bytes compressed:  56.5%
```

## zipnote {}

```diff
@@ -78,23 +78,23 @@
 
 Filename: mahaNLP/tokenizer/__init__.py
 Comment: 
 
 Filename: mahaNLP/tokenizer/tokenize.py
 Comment: 
 
-Filename: mahaNLP-0.8.dist-info/LICENSE
+Filename: mahaNLP-0.9.dist-info/LICENSE
 Comment: 
 
-Filename: mahaNLP-0.8.dist-info/METADATA
+Filename: mahaNLP-0.9.dist-info/METADATA
 Comment: 
 
-Filename: mahaNLP-0.8.dist-info/WHEEL
+Filename: mahaNLP-0.9.dist-info/WHEEL
 Comment: 
 
-Filename: mahaNLP-0.8.dist-info/top_level.txt
+Filename: mahaNLP-0.9.dist-info/top_level.txt
 Comment: 
 
-Filename: mahaNLP-0.8.dist-info/RECORD
+Filename: mahaNLP-0.9.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## mahaNLP/config.py

```diff
@@ -20,22 +20,30 @@
 # OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 # SOFTWARE.
 
 """model paths"""
 paths = {
     "autocomplete": {"marathi-gpt": "l3cube-pune/marathi-gpt"},
 
-    "hate": {"mahahate-bert": "l3cube-pune/mahahate-bert",
-             "mahahate-multi-roberta": "l3cube-pune/mahahate-multi-roberta"},
-
-    "mask_fill": {"marathi-bert-v2": "l3cube-pune/marathi-bert-v2",
-                 "marathi-roberta": "l3cube-pune/marathi-roberta",
-                 "marathi-albert": "l3cube-pune/marathi-albert"},
-
-    "sentiment": {"MarathiSentiment": "l3cube-pune/MarathiSentiment"},
-
-    "similarity": {"marathi-sentence-similarity-sbert": 
-                   "l3cube-pune/marathi-sentence-similarity-sbert",
-                   "marathi-sentence-bert-nli": "l3cube-pune/marathi-sentence-bert-nli"},
+    "hate": {
+        "mahahate-bert": "l3cube-pune/mahahate-bert",
+        "mahahate-multi-roberta": "l3cube-pune/mahahate-multi-roberta"},
+
+    "mask_fill": {
+        "marathi-bert-v2": "l3cube-pune/marathi-bert-v2",
+        "marathi-roberta": "l3cube-pune/marathi-roberta",
+        "marathi-albert": "l3cube-pune/marathi-albert"},
+
+    "sentiment": {
+        "marathi-sentiment-md": "l3cube-pune/marathi-sentiment-md",
+        "marathi-sentiment-tweets": "l3cube-pune/marathi-sentiment-tweets",
+        "marathi-sentiment-movie-reviews": "l3cube-pune/marathi-sentiment-movie-reviews",
+        "marathi-sentiment-political-tweets": "l3cube-pune/marathi-sentiment-political-tweets",
+        "marathi-sentiment-subtitles": "l3cube-pune/marathi-sentiment-subtitles",
+        "MarathiSentiment": "l3cube-pune/MarathiSentiment"},
+
+    "similarity": {
+        "marathi-sentence-similarity-sbert": "l3cube-pune/marathi-sentence-similarity-sbert",
+        "marathi-sentence-bert-nli": "l3cube-pune/marathi-sentence-bert-nli"},
 
     "tagger": {"marathi-ner": "l3cube-pune/marathi-ner"}
 }
```

## mahaNLP/autocomplete/__init__.py

```diff
@@ -16,9 +16,9 @@
 # IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 # FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 # AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 # LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 # OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 # SOFTWARE.
 
-"""Text prediction module for basic programmer usage"""
+"""Autocomplete module for basic programmer usage."""
 from .autocomplete import TextGenerator
```

## mahaNLP/autocomplete/autocomplete.py

```diff
@@ -19,13 +19,14 @@
 # LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 # OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 # SOFTWARE.
 
 """Inherits methods from GPTModel class of model_repo"""
 from mahaNLP.model_repo.maha_gpt import GPTModel
 
+
 class TextGenerator(GPTModel):
     """Module uses 'marathi-gpt' model for text generation."""
 
     def __init__(self):
         self.model_name = 'marathi-gpt'
         super().__init__(self.model_name)
```

## mahaNLP/model_repo/maha_fill.py

```diff
@@ -19,69 +19,85 @@
 # LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 # OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 # SOFTWARE.
 
 """Masked token prediction module"""
 from transformers import AutoTokenizer, AutoModelForMaskedLM, BertTokenizer, BertForMaskedLM
 from transformers import pipeline
+import torch
 import pandas as pd
 from ..config import paths
 
+
 class MaskFillModel:
     """Fills masked token."""
 
-    def __init__(self, model_name='marathi-bert-v2', gpu_enabled:bool = False):
+    def __init__(self, model_name='marathi-bert-v2', gpu_enabled: bool = False):
         self.model_name = model_name
-        self.model_route = paths['mask_fill'][self.model_name]
-        self.task = "fill-mask"
+        if model_name not in list(paths["mask_fill"].keys()):
+            self.model_route = model_name  # some another model trying to load
+            print(f"[warning] the given model '{model_name}' is incompatible.")
+        else:
+            # user provide model_name that is compatible -> load that model
+            # user does not provide key -> load default model
+            self.model_route = paths["mask_fill"][model_name]
+
+        self.gpu_enabled = gpu_enabled
+        self.device = 1 if (self.gpu_enabled and torch.cuda.is_available()) else -1
 
-        if model_name == 'marathi-bert-v2':
+        print(f"trying to load '{model_name}' model...")
+        if model_name == "marathi-bert-v2":
             self.tokenizer = BertTokenizer.from_pretrained(self.model_route)
             self.model = BertForMaskedLM.from_pretrained(self.model_route)
         else:
             self.tokenizer = AutoTokenizer.from_pretrained(self.model_route)
             self.model = AutoModelForMaskedLM.from_pretrained(self.model_route)
+        print("model loaded!")
 
-        self.generator = pipeline(task = self.task,
-                                    model=self.model,
-                                    tokenizer=self.tokenizer)
+        self.generator = pipeline(
+            task="fill-mask",
+            model=self.model,
+            tokenizer=self.tokenizer,
+            device=self.device
+        )
 
     def predict_mask(self, text: str, details: str = "minimum", as_dict: bool = False):
         """Predicts a string for the masked token.
 
         Args:
             text (str): An input text
             details (str, optional): (minimum, medium, all) - Represents the detailedness
             of the result to be returned.
             as_dict (bool, optional): Used to define the print type. Defaults to False.
 
         Returns:
             pandas DataFrame: Returns a pandas dataframe
         """
         if text.find(self.tokenizer.mask_token) == -1:
-            print("Please mask your sentence first!")
+            print("The mask token not set properly.")
             return None
         predictions = pd.DataFrame(self.generator(text))
-        predictions['token_str'] = predictions['token_str'].apply(lambda word: word.replace(" ",""))
+        predictions['token_str'] = predictions['token_str'].apply(
+            lambda word: word.replace(" ", ""))
 
         if details == 'minimum':
-            custom_predict = predictions[['token_str','sequence']]
+            custom_predict = predictions[['token_str', 'sequence']]
 
         if details == "medium":
-            custom_predict = predictions[['token_str','score','sequence']]
+            custom_predict = predictions[['token_str', 'score', 'sequence']]
 
         if details == "all":
             custom_predict = predictions
 
         if as_dict:
             return custom_predict.to_dict('records')
         return custom_predict
 
     def list_models(self):
         """Lists all models supported for masked token prediction."""
         print(" mask_fill models: ")
         for model in paths['mask_fill']:
-            print("\t",model, ": ", paths['mask_fill'][model])
+            print("\t", model, ": ", paths['mask_fill'][model])
         for task in set(paths) - {'mask_fill'}:
-            print("\n",task,"models: ")
+            print("\n", task, "models: ")
             for model in paths[task]:
-                print("\t",model, ": ", paths[task][model])
+                print("\t", model, ": ", paths[task][model])
```

## mahaNLP/model_repo/maha_gpt.py

```diff
@@ -20,27 +20,45 @@
 # OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 # SOFTWARE.
 
 """Text prediction module"""
 
 from transformers import AutoTokenizer, AutoModelForCausalLM
 from transformers import pipeline
+import torch
 import pandas as pd
 from ..config import paths
 
 class GPTModel:
     """Predicts next word or generates a complete sentence"""
 
     def __init__(self, model_name = 'marathi-gpt', gpu_enabled : bool = False):
         self.model_name = model_name
-        self.model_route = paths['autocomplete'][self.model_name]
+        if model_name not in list(paths["autocomplete"].keys()):
+            self.model_route = model_name  # some another model trying to load
+            print(f"[warning] the given model '{model_name}' is incompatible.")
+        else:
+            # user provide model_name that is compatible -> load that model
+            # user does not provide key -> load default model
+            self.model_route = paths["autocomplete"][model_name]
+
+        self.gpu_enabled = gpu_enabled
+        self.device = 1 if (self.gpu_enabled and torch.cuda.is_available()) else -1
+
+
+        print(f"trying to load '{model_name}' model...")
         self.tokenizer = AutoTokenizer.from_pretrained(self.model_route)
         self.model = AutoModelForCausalLM.from_pretrained(self.model_route)
+        print("model loaded!")
+
         self.classifier = pipeline('text-generation',
-                              model=self.model, tokenizer=self.tokenizer)
+                                   model=self.model,
+                                   tokenizer=self.tokenizer,
+                                   device=self.device
+                                   )
         pd.options.display.max_colwidth = None
 
     def next_word(self, text, num_of_predictions = 1):
         """Predicts the next word in the given sentence
 
         Args:
             text (str): An input text
@@ -77,8 +95,7 @@
         print(" autocomplete models: ")
         for model in paths['autocomplete']:
             print("\t",model, ": ", paths['autocomplete'][model])
         for task in set(paths) - {'autocomplete'}:
             print("\n",task,"models: ")
             for model in paths[task]:
                 print("\t",model, ": ", paths[task][model])
-
```

## mahaNLP/model_repo/maha_hate.py

```diff
@@ -19,27 +19,44 @@
 # LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 # OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 # SOFTWARE.
 
 """Hate Analysis Module"""
 from transformers import AutoTokenizer, AutoModelForSequenceClassification
 from transformers import pipeline
+import torch
 import pandas as pd
 from ..config import paths
 
 class HateModel:
     """Labels text as hate / non-hate and provides score for the same."""
 
     def __init__(self, model_name='mahahate-bert', gpu_enabled:bool = False):
         self.model_name = model_name
-        self.model_route = paths['hate'][self.model_name]
+        if model_name not in list(paths["hate"].keys()):
+            self.model_route = model_name  # some another model trying to load
+            print(f"[warning] the given model '{model_name}' is incompatible.")
+        else:
+            # user provide model_name that is compatible -> load that model
+            # user does not provide key -> load default model
+            self.model_route = paths["hate"][model_name]
+
+        self.gpu_enabled = gpu_enabled
+        self.device = 1 if (self.gpu_enabled and torch.cuda.is_available()) else -1
+
+        print(f"trying to load '{model_name}' model...")
         self.tokenizer = AutoTokenizer.from_pretrained(self.model_route)
         self.model = AutoModelForSequenceClassification.from_pretrained(self.model_route)
+        print("model loaded!")
+
         self.classifier = pipeline('text-classification',
-                              model=self.model, tokenizer=self.tokenizer)
+                                   model=self.model,
+                                   tokenizer=self.tokenizer,
+                                   device=self.device
+                                   )
 
     def get_hate_score(self, text):
         """Gives the hate score of a sentence.
 
         Args:
             text (str): An input string
```

## mahaNLP/model_repo/maha_ner.py

```diff
@@ -27,21 +27,31 @@
 from ..config import paths
 
 class NERModel:
     """Entity recognition along with the scores."""
 
     def __init__(self, model_name='marathi-ner',gpu_enabled:bool = False):
         self.model_name = model_name
-        self.model_route = paths['tagger'][self.model_name]
+        if model_name not in list(paths["tagger"].keys()):
+            self.model_route = model_name  # some another model trying to load
+            print(f"[warning] the given model '{model_name}' is incompatible.")
+        else:
+            # user provide model_name that is compatible -> load that model
+            # user does not provide key -> load default model
+            self.model_route = paths["tagger"][model_name]
+
 
         self.gpu_enabled = gpu_enabled
         self.device = 1 if (self.gpu_enabled and torch.cuda.is_available()) else -1
 
-        self.pretrained_ner_model = BertForTokenClassification.from_pretrained(self.model_route)
+        print(f"trying to load '{model_name}' model...")
         self.ner_tokenizer = BertTokenizerFast.from_pretrained(self.model_route)
+        self.pretrained_ner_model = BertForTokenClassification.from_pretrained(self.model_route)
+        print("model loaded!")
+
         self.pipeline = TokenClassificationPipeline(
             task='marathi-ner',
             model=self.pretrained_ner_model,
             tokenizer=self.ner_tokenizer,
             framework="pt",
             aggregation_strategy='first',
             device=self.device,
```

## mahaNLP/model_repo/maha_sentiment.py

```diff
@@ -19,27 +19,47 @@
 # LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 # OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 # SOFTWARE.
 
 """Sentiment Analysis Module"""
 from transformers import AutoTokenizer, AutoModelForSequenceClassification
 from transformers import pipeline
+import torch
 import pandas as pd
 from ..config import paths
 
+
 class SentimentModel:
     """Labels text as positive / negative / neutral and provides score for the same."""
 
-    def __init__(self, model_name='MarathiSentiment', gpu_enabled:bool = False):
+    def __init__(self, model_name='marathi-sentiment-md', gpu_enabled: bool = False):
         self.model_name = model_name
-        self.model_route = paths['sentiment'][self.model_name]
+        if model_name not in list(paths["sentiment"].keys()):
+            self.model_route = model_name  # some another model trying to load
+            print(f"[warning] the given model '{model_name}' is incompatible.")
+        else:
+            # user provide model_name that is compatible -> load that model
+            # user does not provide key -> load default model
+            self.model_route = paths["sentiment"][model_name]
+
+        self.gpu_enabled = gpu_enabled
+        self.device = 1 if (self.gpu_enabled and torch.cuda.is_available()) else -1
+
+        print(f"trying to load '{model_name}' model...")
         self.tokenizer = AutoTokenizer.from_pretrained(self.model_route)
-        self.model = AutoModelForSequenceClassification.from_pretrained(self.model_route)
+        self.model = AutoModelForSequenceClassification.from_pretrained(
+            self.model_route)
+        print("model loaded!")
+
         self.classifier = pipeline('text-classification',
-                              model=self.model, tokenizer=self.tokenizer)
+                                   model=self.model,
+                                   tokenizer=self.tokenizer,
+                                   device=self.device
+                                   )
+
     def get_polarity_score(self, text):
         """Gives the sentiment score of a sentence.
 
         Args:
             text (str): An input string
 
         Returns:
@@ -54,13 +74,12 @@
         print('Supported labels: \n -Positive\n -Negative\n -Neutral\n')
 
     def list_models(self):
         """Lists all models supported for sentiment analysis."""
 
         print(" sentiment models: ")
         for model in paths['sentiment']:
-            print("\t",model, ": ", paths['sentiment'][model])
+            print("\t", model, ": ", paths['sentiment'][model])
         for task in set(paths) - {'sentiment'}:
-            print("\n",task,"models: ")
+            print("\n", task, "models: ")
             for model in paths[task]:
-                print("\t",model, ": ", paths[task][model])
-                
+                print("\t", model, ": ", paths[task][model])
```

## mahaNLP/model_repo/maha_similarity.py

```diff
@@ -25,15 +25,22 @@
 from ..config import paths
 
 class SimilarityModel:
     """Provides sentence embeddings and sentence similarity score functionalities."""
 
     def __init__(self, model_name = 'marathi-sentence-similarity-sbert', gpu_enabled:bool = False):
         self.model_name = model_name
-        self.model_route = paths['similarity'][self.model_name]
+        if model_name not in list(paths["similarity"].keys()):
+            self.model_route = model_name  # some another model trying to load
+            print(f"[warning] the given model '{model_name}' is incompatible.")
+        else:
+            # user provide model_name that is compatible -> load that model
+            # user does not provide key -> load default model
+            self.model_route = paths["similarity"][model_name]
+
         self.model = SentenceTransformer(self.model_route)
 
     def embed_sentences(self,sentences):
         """Embeds the input sentence
 
         Args:
             sentences (str): An input text
```

## mahaNLP/preprocess/marathi_stopwords.txt

```diff
@@ -1,99 +1,240 @@
-आहे
-या 
+त्याची
+यांना
+असल्याची
+साठीचे
+त्याने
+स्वतःला
+करणार
+यांचे
+चे
+साठी
+गेले
+करता
+च्या
+काही
+केलं
+याच्या
+सारखे
+शकता
+देत
+मला
+खूप
+फक्त
+त्यात
+झाल्यानंतर
 आणि
-व 
-नाही  
-आहेत 
-यानी 
-हे 
-तर
-ते 
-असे
+तुम्ही
+जाते
+इतर
+च्याबरोबर
+यास
+त्याना
+त्याचा
+असल्याचे
+च्यापेक्षा
+तिथे
+यात
 होते
-केली 
-हा 
-ही 
-पण 
-करणयात 
-काही
-केले
-एक 
-केला 
-अशी
-मात्र  
-त्यानी 
-सुरू
-करून 
-होती
-असून 
-आले 
-त्यामुळे 
-झाली
-होता 
-दोन 
-झाले
-मुबी 
-होत 
-त्या 
-आता 
-असा 
-याच्या 
+मी
+तू
+आता
+असेही
+आला
+दरम्यान
+होऊन
+येथील
+आतले
 त्याच्या
-ता
-आली 
-की
-पम
+तर
+कधीही
+सर्व
+येत
+थेट
+केल्याने
+साठीच
+ही
+आपल्या
+जातात
+यानी
+आले
+कुठे
+असल्याचा
+यांचा
+आधी
+पुढील
+करण्यात
+होईल
+करताना
+असताना
+ती
 तो
-झाला
-त्री
+हे
+की
+तुमचे
+सुमारास
+त्यानी
+कोणत्याही
+होती
+नंतर
+यांनी
+अन्य
+त्यासाठी
+आणखी
+पासून
+अशी
+सर्वाधिक
+आतापर्यंत
+असतात
+यामुळे
+आपण
+तुमचा
+आली
+असून
+शकतो
+गेल्या
+यावेळी
+होतं
+स्वतः
+तिचा
+मिळत
+तुझे
+देखील
+परंतु
+त्यांच्या
+या
+लाख
+काळात
+पेक्षा
+करण्यास
 तरी
-म्हणून
-त्याना
+असलेल्या
+आहेत
+यांच्या
+शकते
+कोण
+यासाठी
+होता
+च्याविषयी
+करून
+मग
+येते
+ज्या
+व
+त्यावेळी
+सर्वात
+पण
+आहे
+मात्र
+समावेश
+जातो
+कसे
+केल्या
+स्वतःचे
+असल्यामुळे
+येणार
+पुन्हा
+असा
+केवळ
+झालेले
+करतो
+करावी
+त्याला
+तसेच
+यांची
+असतो
+वर
+करीत
+आल्या
+असं
+होत्या
+असे
+मध्ये
+त्यांचा
+घेऊन
+म्हणाले
+त्यांचे
+येईल
+का
+मिळाली
+केली
+याचा
+काय
+आम्ही
+असणे
+अशा
+आमचे
+त्यावर
+करावे
+जे
+मिळणार
+हा
+अधिक
 अनेक
-काम
-माहिती
-हजार
-सागित्ले
-दिली
-आला
 आज
-ती 
-तसेच
-एका
-याची
-येथील
-सर्व
-न
+कोणसाठी
+झाले
+एकदा
+करत
+दिली
+अद्याप
+केला
+दिले
+कारण
+असेल
+झालेल्या
+होणार
+त्याच
+किती
+त्याचे
+यंदा
+प्रत्येक
+त्यानंतर
+आपला
+दोन्ही
+त्यांनी
+करा
+कधी
+किंवा
+त्या
 डॉ
-तीन 
-येथे
-पाटील
-असलयाचे
-त्याची
-काय
-आपल्या
+असते
+झाली
+रा
+होतो
+येत्या
+नाही
+करावा
+समोर
 म्हणजे
+त्यांना
+यामध्ये
+करण्यासाठी
+केले
+तेव्हा
+त्यानुसार
+येथे
+पाहिजे
+नाहीत
+म्हणून
+होत
+होऊ
+याच
+करू
 याना
-म्हणाले
-त्याचा
-असलेल्या
-मी
-गेल्या
-याचा
-येत
-म
-लाख 
-कमी
-जात	
-टा
-होणार
 किवा
-का
-अधिक
-घेऊन      
-परयतन
-कोटी
-झालेल्या
-निर्ण्य
-येणार
-व्यकत 
+सागित्ले
+तब्बल
+ते
+बाहेर
+सुरू
+करतात
+एका
+व्यकत
+असल्याने
+झाला
+कमी
+पर्यंत
+त्यामुळे
+त्यांची
+याची
+करणे
```

## mahaNLP/sentiment/sentiment.py

```diff
@@ -19,13 +19,14 @@
 # LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 # OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 # SOFTWARE.
 
 """Inherits methods from SentimentModel class of model_repo"""
 from mahaNLP.model_repo.maha_sentiment import SentimentModel
 
+
 class SentimentAnalyzer(SentimentModel):
-    """Module uses 'MarathiSentiment' model for sentiment score analysis."""
+    """Module uses 'mahasent-md' model for sentiment score analysis."""
 
     def __init__(self):
-        self.model_name = 'MarathiSentiment'
+        self.model_name = "marathi-sentiment-md"
         super().__init__(self.model_name)
```

## mahaNLP/similarity/similarity.py

```diff
@@ -19,13 +19,14 @@
 # LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 # OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 # SOFTWARE.
 
 """Inherits methods from SimilarityModel class of model_repo"""
 from mahaNLP.model_repo.maha_similarity import SimilarityModel
 
+
 class SimilarityAnalyzer(SimilarityModel):
     """Module uses 'marathi-sentence-similarity-sbert' model for text generation."""
 
     def __init__(self):
-        self.model_name =  'marathi-sentence-similarity-sbert'
+        self.model_name = 'marathi-sentence-similarity-sbert'
         super().__init__(self.model_name)
```

## mahaNLP/tagger/__init__.py

```diff
@@ -16,9 +16,9 @@
 # IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 # FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 # AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 # LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 # OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 # SOFTWARE.
 
-"""Entity Recognizer module"""
+"""Tagger module for basic programmer usage."""
 from .tagger import EntityRecognizer
```

## mahaNLP/tagger/tagger.py

 * *Ordering differences only*

```diff
@@ -24,8 +24,8 @@
 from mahaNLP.model_repo.maha_ner import NERModel
 
 class EntityRecognizer(NERModel):
     """Module uses 'marathi-ner' model for entity recognition."""
 
     def __init__(self):
         self.model_name = 'marathi-ner'
-        super().__init__(self.model_name)
+        super().__init__(self.model_name)
```

## Comparing `mahaNLP-0.8.dist-info/LICENSE` & `mahaNLP-0.9.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `mahaNLP-0.8.dist-info/METADATA` & `mahaNLP-0.9.dist-info/METADATA`

 * *Files 8% similar despite different names*

```diff
@@ -1,16 +1,15 @@
 Metadata-Version: 2.1
 Name: mahaNLP
-Version: 0.8
+Version: 0.9
 Summary: An NLP Library for Marathi Language
 Home-page: https://github.com/l3cube-pune/MarathiNLP.git
 Author: L3Cube
-Author-email: l3cube.pune@gmail.com
+Author-email: ravirajoshi@gmail.com
 License: MIT
-Platform: UNKNOWN
 Classifier: Programming Language :: Python :: 3
 Classifier: License :: OSI Approved :: MIT License
 Classifier: Operating System :: OS Independent
 Description-Content-Type: text/markdown
 License-File: LICENSE
 Requires-Dist: importlib-resources
 Requires-Dist: huggingface-hub (==0.11.1)
@@ -20,29 +19,26 @@
 Requires-Dist: transformers
 Requires-Dist: numpy
 Requires-Dist: torch
 Requires-Dist: IPython
 
 # **mahaNLP**
 
-  
-
 - **mahaNLP** is a python-based natural language processing library focused on the Indian language **Marathi**. It provides an easy interface for NLP features like sentiment analysis, named entity recognition, hate speech detection, etc. exclusively for Marathi text.
 
 - **L3Cube**, the author of this library aims to bring Marathi to the forefront of IndicNLP. Our vision is to make Marathi a resource-rich language and promote AI for Maharashtra!
 
 - [Github Repo](https://github.com/l3cube-pune/MarathiNLP)
 - [Demonstration with examples](https://cutt.ly/f1FYQak)
-  
 
 ## **Features:**
 
 ##### **This library is customised to be used by a basic programmer and an ML practitioner.**
 
-***
+---
 
 #### **1. Basic Usage:**
 
 This mode of access is designed from a basic programmer point of view and follow simpler way to perform the desired tasks. It provides the following features:
 
 - **Datasets:** Provides the functionality to load the dataset
 
@@ -58,132 +54,140 @@
 
 - **Hate:** Detects hate speech
 
 - **Sentiment:** Sentiment analysis
 
 - **Similarity:** Detects similarity
 
-  
-  
-
 #### **2. Advanced Usage:**
 
 This way of accessing the library is designed from an ML Practitioner's point of view and has more flexibility to choose a model for the desired task.
 
-* **MaskFill Model:** Predicts the masked tokens
-
-* **GPT Model:** Text prediction
+- **MaskFill Model:** Predicts the masked tokens
 
-* **Hate Model:** Detects hate speech
+- **GPT Model:** Text prediction
 
-* **NER Model:** Named entity recognision
+- **Hate Model:** Detects hate speech
 
-* **Sentiment Model:** Sentiment analysis
+- **NER Model:** Named entity recognision
 
-* **Similarity Model:** Detects similarity
+- **Sentiment Model:** Sentiment analysis
 
-  
+- **Similarity Model:** Detects similarity
 
 Some of the mentioned models have sub models within them that can be seen using the **listModels()** function.
 
-  
-
 ## **Installation:**
 
 - **pip install mahaNLP==[version]**
-*Eg.: pip install mahaNLP==0.6*
+  _Eg.: pip install mahaNLP==0.6_
 
 - or we can simply use:
-***pip install mahaNLP***
-  
-***
+  **_pip install mahaNLP_**
+
+---
 
 ## **Few Examples:**
 
 ### **1. Tagger (from basic usage point of view)**
 
 Stepwise execution:
 
 - import
-from mahaNLP.mask_fill import MaskPredictor
+  from mahaNLP.mask_fill import MaskPredictor
 
 - create an object
-model = MaskPredictor()
+  model = MaskPredictor()
 
 It provides one functionality
-* **predict_mask:** Predicts the masked token
 
-- **Example:**
-* *pass the string with the word to be predicted replaced with '[MASK]':*
-**text = 'मी महाराष्ट्रात [MASK].'**
-*English Translation:
-'I in Maharashtra [MASK]'*
-* **model.predict_mask(text)**
-
-* The output will contain some predictions like:
-	* मी महाराष्ट्रात **आहे**.
-	* मी महाराष्ट्रात **राहणार**.
-	* मी महाराष्ट्रात **नाही**.
-	* मी महाराष्ट्रात**च**.
-	* मी महाराष्ट्रात **राहतो**.
-
-* There are some optional parameters:
-	-   **details**  (minimum, medium, all) in string - Default: minimum
-	    -   Used to pass the detailedness to be considered
-	-   **as_dict**  (True, False) in boolean - Default: False
-	    -   Used to define the print type
-
-* Example:
-	- model.predict_mask(text9, 'all', True)
-	- Output:
-	[{'score': 0.46560075879096985, 'token': 1155, 'token_str': 'आहे', 'sequence': 'मी महाराष्ट्रात आहे.'},
-	{'score': 0.07969045639038086, 'token': 92222, 'token_str': 'राहणार', 'sequence': 'मी महाराष्ट्रात राहणार.'},
-	{'score': 0.07400081306695938, 'token': 1826, 'token_str': 'नाही', 'sequence': 'मी महाराष्ट्रात नाही.'},
-	{'score': 0.050422605127096176, 'token': 1617, 'token_str': '##च', 'sequence': 'मी महाराष्ट्रातच.'},
-	{'score': 0.04373728483915329, 'token': 62560, 'token_str': 'राहतो', 'sequence': 'मी महाराष्ट्रात राहतो.'}]
+- **predict_mask:** Predicts the masked token
+
+* **Example:**
+
+- _pass the string with the word to be predicted replaced with '[MASK]':_
+  **text = 'मी महाराष्ट्रात [MASK].'**
+  _English Translation:
+  'I in Maharashtra [MASK]'_
+- **model.predict_mask(text)**
+
+- The output will contain some predictions like:
+
+  - मी महाराष्ट्रात **आहे**.
+  - मी महाराष्ट्रात **राहणार**.
+  - मी महाराष्ट्रात **नाही**.
+  - मी महाराष्ट्रात**च**.
+  - मी महाराष्ट्रात **राहतो**.
+
+- There are some optional parameters:
+
+  - **details** (minimum, medium, all) in string - Default: minimum
+    - Used to pass the detailedness to be considered
+  - **as_dict** (True, False) in boolean - Default: False
+    - Used to define the print type
+
+- Example:
+  - model.predict_mask(text9, 'all', True)
+  - Output:
+    [{'score': 0.46560075879096985, 'token': 1155, 'token_str': 'आहे', 'sequence': 'मी महाराष्ट्रात आहे.'},
+    {'score': 0.07969045639038086, 'token': 92222, 'token_str': 'राहणार', 'sequence': 'मी महाराष्ट्रात राहणार.'},
+    {'score': 0.07400081306695938, 'token': 1826, 'token_str': 'नाही', 'sequence': 'मी महाराष्ट्रात नाही.'},
+    {'score': 0.050422605127096176, 'token': 1617, 'token_str': '##च', 'sequence': 'मी महाराष्ट्रातच.'},
+    {'score': 0.04373728483915329, 'token': 62560, 'token_str': 'राहतो', 'sequence': 'मी महाराष्ट्रात राहतो.'}]
 
 ### **2. Sentiment (from advance usage point of view)**
 
 Stepwise execution:
 
 - import
-from mahaNLP.model_repo import SentimentModel
+  from mahaNLP.model_repo import SentimentModel
 
 - list the available models
-	* modelSentiment.list_models()
-	* Output:
-		- sentiment models: MarathiSentiment : l3cube-pune/MarathiSentiment
-		- tagger models: marathi-ner : l3cube-pune/marathi-ner
-		- autocomplete models: marathi-gpt : l3cube-pune/marathi-gpt
-		- similarity models: marathi-sentence-similarity-sbert : l3cube-pune/marathi-sentence-similarity-sbert
-		marathi-sentence-bert-nli : l3cube-pune/marathi-sentence-bert-nli
-		- mask_fill models: marathi-bert-v2 : l3cube-pune/marathi-bert-v2
-		marathi-roberta : l3cube-pune/marathi-roberta marathi-albert : l3cube-pune/marathi-albert
-		- hate models: mahahate-bert : l3cube-pune/mahahate-bert
-		mahahate-multi-roberta : l3cube-pune/mahahate-multi-roberta
+  - modelSentiment.list_models()
+  - Output:
+    - sentiment models: MarathiSentiment : l3cube-pune/MarathiSentiment
+    - tagger models: marathi-ner : l3cube-pune/marathi-ner
+    - autocomplete models: marathi-gpt : l3cube-pune/marathi-gpt
+    - similarity models: marathi-sentence-similarity-sbert : l3cube-pune/marathi-sentence-similarity-sbert
+      marathi-sentence-bert-nli : l3cube-pune/marathi-sentence-bert-nli
+    - mask_fill models: marathi-bert-v2 : l3cube-pune/marathi-bert-v2
+      marathi-roberta : l3cube-pune/marathi-roberta marathi-albert : l3cube-pune/marathi-albert
+    - hate models: mahahate-bert : l3cube-pune/mahahate-bert
+      mahahate-multi-roberta : l3cube-pune/mahahate-multi-roberta
 
 The library lists down the models available for all the models. These can be changed by the user.
 
- **To change the default model:**
+**To change the default model:**
 Pass the name of the model as the argument:
 modelSentiment = SentimentModel('name of model')
 Eg.: modelSentiment = SentimentModel('MarathiSentiment')
 
-* Sentiment provides one functionality
-	- **get_polarity_score:**  Gives the polarity score of words in a sentence along with the tokens (Neutral, Positive, Negative)
-	- Example:
-	text = 'दिवाळीच्या सणादरम्यान सगळे आनंदी असतात.'
-	*English Translation:
-	'Everyone is happy during Diwali festival.'*
-	- modelSentiment.get_polarity_score(text)
-	- Output:
-	label: Positive
-	score: 0.995338
+- Sentiment provides one functionality
+  - **get_polarity_score:** Gives the polarity score of words in a sentence along with the tokens (Neutral, Positive, Negative)
+  - Example:
+    text = 'दिवाळीच्या सणादरम्यान सगळे आनंदी असतात.'
+    _English Translation:
+    'Everyone is happy during Diwali festival.'_
+  - modelSentiment.get_polarity_score(text)
+  - Output:
+    label: Positive
+    score: 0.995338
 
-***
+---
 
 **Entire working of mahaNLP is explained in this [demo file](https://cutt.ly/f1FYQak). Please have a look at it to get a better idea!**
 
-Thank you
+## Citing
+
+```
+@article{joshi2022l3cube_mahanlp,
+  title={L3Cube-MahaNLP: Marathi Natural Language Processing Datasets, Models, and Library},
+  author={Joshi, Raviraj},
+  journal={arXiv preprint arXiv:2205.14728},
+  year={2022}
+}
+```
+
+Thank you<br>
 Team L3Cube
 
-***
+---
```

## Comparing `mahaNLP-0.8.dist-info/RECORD` & `mahaNLP-0.9.dist-info/RECORD`

 * *Files 12% similar despite different names*

```diff
@@ -1,33 +1,33 @@
 mahaNLP/__init__.py,sha256=7lX_3lcZzujXq3i6EAy4PVE7ec0CvP_mHbmBfNGmdVY,1428
-mahaNLP/config.py,sha256=4wEsFk52MHJkIUpPjpDWC0JYh6BIIsru6zmg-zdE6MY,1883
-mahaNLP/autocomplete/__init__.py,sha256=94DLitPcOrooMsQXkkz92xUGv5mrNUypWdOmXQCzjOA,1199
-mahaNLP/autocomplete/autocomplete.py,sha256=cIJ0VUraO_eWmG8kP3V0icAx6bWpDeVa4qDRqR_2_So,1411
+mahaNLP/config.py,sha256=GKuEg8fLBnHqgtNVkFuc2s6ytbNLEfm_Eds_tt4qkcg,2277
+mahaNLP/autocomplete/__init__.py,sha256=nCaR-skHLYWPDjrGwtDcWX2MOtfLxuCFQtX3Vxgg6VA,1197
+mahaNLP/autocomplete/autocomplete.py,sha256=-MmF72V2vrf-MJEkB_AzWcwiZVWnyA2UqYXYSeNxZ2Q,1412
 mahaNLP/datasets/__init__.py,sha256=wpA0J1lFrImkUWTlVfG9Yk7fVL7ci_TV9KVODZaUtjY,1216
 mahaNLP/datasets/load_data.py,sha256=yuFO_KMogEVLfl7LIJFuLr9G9wMm8Bj3QhykHWcBPO8,7675
 mahaNLP/hate/__init__.py,sha256=9qsnEKCiC1BDxH94O6uP4-Z3Q6ZtgLpOMxYRSgnXKcs,1189
 mahaNLP/hate/hate.py,sha256=gh2tJHPARCq1dIwiSnK4LWHq4koXJacoKTB3sdyj7SU,1422
 mahaNLP/mask_fill/__init__.py,sha256=-_CxDr2oXfsMXdwwY7pzFnini7ZQJm9eF7n_cAwMCaA,1204
 mahaNLP/mask_fill/mask_fill.py,sha256=ktZw5C_oubQokhlURZHqGooWauvN1BKE0zKJo3l1ScM,1443
 mahaNLP/model_repo/__init__.py,sha256=x9C8rMN4vKtDcOAaXPjZs_v0WifHU24pISv6m8crVVQ,1450
-mahaNLP/model_repo/maha_fill.py,sha256=fDuXVYHV875j9UWwDcpyEu5ZP8_1abBqI7P5qleEH3s,3716
-mahaNLP/model_repo/maha_gpt.py,sha256=4xChZT9DZk-8Fei_PmuU1a2de_A8YiGYdUNqRP3ObjQ,3653
-mahaNLP/model_repo/maha_hate.py,sha256=B60ItL8IZDwakQLuVqaONYD77rDUxoCSbXIAf_hwces,2961
-mahaNLP/model_repo/maha_ner.py,sha256=Pc5wipS36Z-fVtnB_f1Gp7YB3Y9pp9I18idfJDdg7vw,4158
-mahaNLP/model_repo/maha_sentiment.py,sha256=DcjaW0c5HJo9k1JDH3eZDBiABCU-40BRkje6m3uGdTE,2853
-mahaNLP/model_repo/maha_similarity.py,sha256=HlhKOgbAE-6myIRkTOxzYHMCDlycuLDQMr--QEzu07w,3347
+mahaNLP/model_repo/maha_fill.py,sha256=GBJYDo8t1I9zkPHhCx__1UaYuwsZQVfElGuEaO8N6Rs,4310
+mahaNLP/model_repo/maha_gpt.py,sha256=jUBZIuxhoKWxcDsQxYhJBVqN4NOsWvCCznZpIueOg3c,4371
+mahaNLP/model_repo/maha_hate.py,sha256=mc_2t2aLmBeniLIB-Y4rWOl6mMjgKhEIPchtXN-REeg,3686
+mahaNLP/model_repo/maha_ner.py,sha256=Y7u-cXOG6GQeL_vUYYouSwZLYZM2rcn8GwvMt0Aeb9o,4617
+mahaNLP/model_repo/maha_sentiment.py,sha256=-AX9vYUQxi2whCDiW-tnmwk2OnwaoysecTAUWIrd1VA,3591
+mahaNLP/model_repo/maha_similarity.py,sha256=zLm9-uuM3uzAcy6sM6x9i19HI0i3778oVVsjgNGhtUI,3721
 mahaNLP/preprocess/__init__.py,sha256=XepySkgggUgiaLQTPcxeE18iVuCtDGr-o3oKDfbuj8M,1195
-mahaNLP/preprocess/marathi_stopwords.txt,sha256=Mu0xmuANLanjUAMISd3frDbdkRLNVGuSB6EMvVPxq44,1307
+mahaNLP/preprocess/marathi_stopwords.txt,sha256=ydxicPHt22ck_TT1p8RqVUMFUwWkvQO7QWzEudbCAAw,3686
 mahaNLP/preprocess/preprocess.py,sha256=xZkjntZwnqraIlIuRqxxh7nlxdkvPPAkGN-m-Jngrfo,4133
 mahaNLP/sentiment/__init__.py,sha256=i8JoN-dt_glagfZs66mJAv88z5YYcGyhPY5oSipr-hk,1204
-mahaNLP/sentiment/sentiment.py,sha256=XfUOZlQsz-ShocsqU50GjopmplGZsE9pvAhq8-CbX44,1458
+mahaNLP/sentiment/sentiment.py,sha256=kURhyrgL0TI3Lovw3Tp3ZvDeI7ofsC2_QGNBgZLzctk,1458
 mahaNLP/similarity/__init__.py,sha256=jDqznlTAbvWKDQhYLa4R9QmwU6huN3YyBeMpk6vW5AM,1206
-mahaNLP/similarity/similarity.py,sha256=QzLU6X9SY23dwl4pIXyol6YPBhZZmwhHc-HcSkin0IQ,1489
-mahaNLP/tagger/__init__.py,sha256=wqe8N4NesDgz5qf5QBZVVVGtPtX8N3axnk_IZ5f2I2E,1171
-mahaNLP/tagger/tagger.py,sha256=QxIy0HEnN5nImc_fbWO-4Viz2TBherpClcTaIZZIAfo,1417
+mahaNLP/similarity/similarity.py,sha256=IpDAlT9OtEPtPr3BCSAMzJ2F4zBH_eDZgBmuvU1N4tc,1489
+mahaNLP/tagger/__init__.py,sha256=x43r7HOuV7yBQZ1eVAtLb8r8woVWLlIg-EoC1NyjwqY,1188
+mahaNLP/tagger/tagger.py,sha256=tdvhJQ0x3OJxl5RKfWYRr5W_fgHC0-wAOjgrse9Lr6k,1416
 mahaNLP/tokenizer/__init__.py,sha256=EDq9izT3cLlVjIuRhQhbDm4fCwwP4tbAOhmg2gjzeMw,1156
 mahaNLP/tokenizer/tokenize.py,sha256=AFfsBPzt2gVtQyRW8F6Ka0enBVhv1rpnHrJmvzjQEzw,3863
-mahaNLP-0.8.dist-info/LICENSE,sha256=90dRI6IgGgdjiJBWxMbJi9DdJiMvX7lSNLJum18BXMc,1068
-mahaNLP-0.8.dist-info/METADATA,sha256=AQelwg_w9yeYHZt5SlipLwrudHs9WHwvRvtL59kaA9Q,6366
-mahaNLP-0.8.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-mahaNLP-0.8.dist-info/top_level.txt,sha256=qaI4icU9mukP--qdw9wjhinStLUxpDYOzmY8LeAdetY,8
-mahaNLP-0.8.dist-info/RECORD,,
+mahaNLP-0.9.dist-info/LICENSE,sha256=90dRI6IgGgdjiJBWxMbJi9DdJiMvX7lSNLJum18BXMc,1068
+mahaNLP-0.9.dist-info/METADATA,sha256=Y2IdQU1hiK7-bef0LT8OWCaj4uY2CNfX2JI9Ntoq2dE,6638
+mahaNLP-0.9.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+mahaNLP-0.9.dist-info/top_level.txt,sha256=qaI4icU9mukP--qdw9wjhinStLUxpDYOzmY8LeAdetY,8
+mahaNLP-0.9.dist-info/RECORD,,
```

